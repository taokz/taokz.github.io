{
  "metadata": {
    "total_datasets": 389,
    "total_source_files": 17,
    "source_files": {
      "Bio_dataset_for_NLP_json_data": {
        "Clinical Trial_0": 32,
        "Formal Clinical Trial": 14,
        "Reasoning Data": 8,
        "Sheet1": 38,
        "qa_dataset_only": 14
      },
      "VisionandLanguage_data_json_data": {
        "工作表1": 14
      },
      "biomedbank_vision_v0_json_data": {
        "BioBank": 171,
        "Kai": 3,
        "Milestone_1": 15,
        "Milestone_2": 45,
        "Yansong_tabular": 9,
        "Yansong_time series": 15,
        "Yuhan": 13,
        "Yuhan_3D_text": 28,
        "Zhengliang": 6,
        "chuanqi-tIme series（EEG）": 16
      },
      "drug_dataset_json_data": {
        "Sheet1": 5
      }
    },
    "extraction_date": "2025-12-03"
  },
  "data": [
    {
      "Name": "TREC Clinical Trials Track",
      "Type": "Corpus",
      "Task": "Clinical Trails Retrieval",
      "Composition (TODO)": "structure; processing",
      "Domain": "Clinical trials",
      "Format": "xml",
      "Description": "This site hosts the information for three of the five major medical track series that have run at the Text REtrieval Conference (TREC), with links to the other two major track series below.",
      "Download": "√",
      "Region": "Texas & Oregon & U.S.",
      "Reference": "Coordinators:Kirk Roberts (UTHealth)\nWilliam Hersh & Steven Bedrick (OHSU)\nDina Demner-Fushman (NLM)\nEllen Voorhees (NIST)",
      "Data Source": "ClinicalTrials.gov",
      "Content (Data Format)": " Some content title may be important: brife_summary, detailed_description, medical condition and intervention, eligibility (incluson and exclusion criteria), keyword,mesh_term (CAUTION:  The following MeSH terms are assigned with an imperfect algorithm )",
      "Comment/Questions": "Without preprocessing",
      "link": "https://www.trec-cds.org/2021.html",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "A Test Collection for Matching Patient to Clinical Trials",
      "Type": "Corpus",
      "Task": "Clinical Trails Retrieval",
      "Domain": "Clinical trials",
      "Format": "txt & topics & json",
      "Description": "A total of 204,855 clinical trials from ClinicalTrials.gov were analyzed across 60 topics with an average of 10.2 queries per topic, supported by 4,000 assessor-provided relevance assessments.",
      "Download": "√",
      "Region": "Australia & U.S.",
      "Reference": "Organizations：CSIRO (Australia), U.S. National Institute of Standards (United States), U.S. National Institutes of Health (United States)",
      "Data Source": "ClinicalTrials.gov",
      "Content (Data Format)": "Contains clinical trial data same as those In trec format. Also contains case descriptions for each patients.",
      "link": "https://doi.org/10.4225/08/58e2e83d92c2b",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "EBM-NLP",
      "Type": "Corpus",
      "Task": "Clinical Outcome Prediction",
      "Format": "txt & ann",
      "Description": "This corpus release contains 4,993 abstracts annotated with (P)articipants, (I)nterventions, and (O)utcomes. Training labels are sourced from AMT workers and aggregated to reduce noise. ",
      "Number": "~5000",
      "Metric": "MeSH terms and span for data set quality, other metrics (accuracy, f1, etc) as well.",
      "Label": "P/I/P",
      "Download": "√",
      "Region": "Global (PubMed and Medline abstracts from journals across US and world)",
      "Data Source": "PubMed",
      "Content (Data Format)": "Text corpus, with annotations on (P)articipants, (I)nterventions, and (O)utcomes. Each sentence is annotated. P labels include information such as age, sex, condition. I labels include various interventions including surgical, physical, drug, educational, psychological, other, or control. O lables are whether it is physical, pain, mortality, adverse effects, mental, and other.",
      "link": "https://github.com/bepnye/EBM-NLP",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "Synthetic Patient Profiles",
      "Type": "synthetic dataset",
      "Task": "Pre-screening for Clinical Trials",
      "Domain": "clinical trials",
      "Format": "cvs & xlsx & json",
      "Metric": "Accuracy(TP&FP)",
      "Download": "√",
      "Region": "Synthetic",
      "Content (Data Format)": "Contains Syntehtic profile of patients, also medical evaluation from professionals.\nColumn, condition: primary medical condition.\nCountry, Age, gender.\nMedical Profile Column: histology, previous treatment, biomarkers, tests, comorbidities(two or more disease), and other information.\nEligible Clinical Trials (those who match pateint's profile), and Ineligible (does not match)\n\n\n",
      "link": "https://github.com/myTomorrows/llm-prescreening/tree/master",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "TrialGPT",
      "Type": "Combined Dataset",
      "Task": "Patient Trial Matching",
      "Domain": "Clinical trials",
      "Format": "All 3 datasets  have been recorded in the first and second line: SIGIR TREC 2021 20222 CT",
      "Description": "Data generated via TrialGPT modules and expert-reviewed for criterion-level trial eligibility matching",
      "Number": "183 patients, 75000 trial annotations",
      "Metric": "AUROC; precision",
      "Download": "√",
      "Region": "TREC",
      "Reference": "https://www.nature.com/articles/s41467-024-53081-z#Abs1",
      "Data Source": "https://huggingface.co/datasets/ncbi/TrialGPT-Criterion-Annotations",
      "Content (Data Format)": "Contains clinical trial in the form of trec data (same column and information but in json format). \nThey also provide queries that are texts used to match records.\nThen, there is a id2queries file that has thre queries and also response from gpt4 and gpt3.5 turbo to convert the queries to a concise version, into two columns, summary and conditions identified.\n label file in the form of query_id, corpus_id, and score (for matching).",
      "link": "https://github.com/ncbi-nlp/TrialGPT",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "Trial2Vec",
      "Type": "Self created dataset",
      "Task": "Trial Similarity Search",
      "Domain": "Clinical trials",
      "Format": "xlsx & csv",
      "Description": "Self-supervised embeddings that capture trial meta-structure and UMLS-based contrastive signals for zero-shot trial retrieval",
      "Number": "240k trials",
      "Metric": "Topk Precision/Recall",
      "Download": "only demo dataset",
      "Region": "Global (US hosted clinicaltrials.gov)",
      "Reference": "https://openreview.net/pdf?id=0KsNsqhR_D0",
      "Data Source": "ClinicalTrials.gov",
      "Content (Data Format)": "nct_id,description of trial,title,intervention_name,disease,keyword,outcome_measure,criteria,reference,overall_status.\nAlso have rank data\n",
      "Comment/Questions": "Q: Simulated Data/For demo data only inlcuded in the github",
      "link": "https://github.com/RyanWangZf/Trial2Vec",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "FRAMM",
      "Type": "Reuse previous dataset",
      "Task": "Clinical trial site selection",
      "Domain": "Clinical trials",
      "Format": "pkl",
      "Description": "Handling Missing Data",
      "Number": "4392 real world trials, trial selection",
      "Metric": "Relative Error; nDCG",
      "Download": "√",
      "Region": "Alabama, MA, FL, WA, etc, US",
      "Reference": "https://arxiv.org/pdf/2305.19407",
      "Data Source": "Real Data from clinical trial database.  Provide synthetic data under similar distribution.",
      "Content (Data Format)": "Should be patient info, but the data only provdes pkl and don't know the exact format/info.",
      "Comment/Questions": "Q: pkl syntheci data provided only",
      "link": "https://github.com/btheodorou99/FRAMM",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "HINT",
      "Type": "Benchmark",
      "Task": "Clinical Outcome Prediction\n",
      "Domain": "Clinical trials",
      "Format": "xml, csv, pkl",
      "Description": "Self-supervised model that embeds multi-modal trial data and predicts outcomes before approvals using a hierarchical interaction graph",
      "Number": "~20k trials",
      "Metric": "F1; ROC-AUC; PR-AUC; p value",
      "Download": "√",
      "Region": "Global",
      "Reference": "https://www.cell.com/patterns/pdf/S2666-3899(22)00018-6.pdf",
      "Data Source": "ClinicalTrials.gov",
      "Content (Data Format)": "linical trial information, including trial identifiers (nctid), status, stop reasons (why_stop), success/failure labels (label), trial phase, associated diseases (diseases, icdcodes), drugs (drugs, SMILES), and eligibility criteria (criteria). Predicting success or fail of clinical trials",
      "link": "https://github.com/futianfan/clinical-trial-outcome-prediction?utm_source=catalyzex.com",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "ML4Trial",
      "Type": "Benchmark",
      "Task": "Clinical Trail Applications",
      "Domain": "Clinical trials",
      "Format": "csv & txt & pkl",
      "Description": "patient, trial, drug, and disease; Patient Outcome Prediction, Patient-Trial Matching, Trial Site Selection,Trial Search, Trial Outcome Prediction, and Patient Data Simulation",
      "Number": "pg4 in paper for number of data for relevant tasks",
      "Metric": "AUROC; PRAUC; precision@K;  recall@K; nDCG@K",
      "Download": "√",
      "Region": "Global Relevant",
      "Reference": "https://arxiv.org/pdf/2306.04018",
      "Content (Data Format)": "nctid,status,why_stop,label,phase,diseases,icdcodes,drugs,smiless,criteria lot more\n clinical trial information (including trial IDs, status, diseases, drugs, and eligibility criteria) that can be used for predicting trial outcomes (success/failure) and patient-trial matching, ",
      "Comment/Questions": "Q: Only demo data available.",
      "link": "https://arxiv.org/pdf/2306.04018",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "MediTab",
      "Type": "Combined Dataset",
      "Task": "Clinical Outcome Prediction",
      "Domain": "Clinical trials",
      "Format": "csv & txt & json",
      "Description": "Patient Outcome Datasets (predict the patient’s morbidity); Clinical Trial Outcome Datasets(HINT benchmark and ClinicalTrials.gov)",
      "Metric": "AUROC; PRAUC",
      "Download": "√",
      "Region": "US/NA from clinicaltrials.gov",
      "Reference": "https://www.ijcai.org/proceedings/2024/0670.pdf",
      "Content (Data Format)": "race,post-menopause,human epidermal growth factor receptor 2 is positive,treatment,tumor laterality,estrogen receptor positive,progesterone receptor positive,\ncancer histologic grade,prior hormonal therapy,prior chemotherapy,biopsy type,sentinel node biospy,axillary dissection,number of positive axillary nodes,tumor size,target_label",
      "Comment/Questions": "Q: No complete data available on the github? Only a small number of breast cancer trial.",
      "link": "https://github.com/RyanWangZf/MediTab",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "DeepEnroll",
      "Type": "Combined Dataset",
      "Task": "Patient Trial Matching",
      "Domain": "Clinical trials",
      "Description": "ClinicalTrialEC; IQVIAdataset; Rare Disease Data; Synthetic Data",
      "Metric": "F1; PRAUC",
      "Download": "√",
      "Region": "US",
      "Reference": "https://arxiv.org/pdf/2001.08179",
      "Data Source": "ClinicalTrials.gov; IQVIAdataset",
      "Content (Data Format)": "batch_idx', 'batch_l', 'label', 'label_size', 'source', 'source_l', 'source_size', 'target', 'target_l', 'target_size'",
      "Comment/Questions": "Q: The github only have vectorized synthetic data to load",
      "link": "https://github.com/xingyaoshawn/DeepEnroll?utm_source=catalyzex.com",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "COMPOSE",
      "Type": "Combined Dataset",
      "Task": "Patient Trial Matching",
      "Domain": "Clinical trials",
      "Description": "Clinical Trial Data (clinicaltrials.gov); Patient EHR Data (extract patient claims data from IQVIA)",
      "Metric": "Accuracy; AUROC",
      "Label": "Patient EHR Data match Clinical Trial Data",
      "Download": "√",
      "Reference": "https://dl.acm.org/doi/pdf/10.1145/3394486.3403123",
      "Data Source": "clinicaltrials.gov; IQVIAdataset",
      "Content (Data Format)": "Trial Number, Condition, Criteria, Gender, Phase,min_age, max_age. \nEHR data (diagnosis, medication, procedure) Input: EHR, condition, criteria, etc. Output: matching or not.",
      "link": "https://github.com/v1xerunt/COMPOSE",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "PMC-Patients",
      "Domain": "Clinical trials",
      "Metric": "BEIR",
      "Reference": "https://www.nature.com/articles/s41597-023-02814-8#Sec14 ",
      "Data Source": "PubMed Central (PMC): https://huggingface.co/datasets/ncbi/pubmed",
      "Comment/Questions": "PubMed in sheet 1",
      "link": "https://huggingface.co/zhengyun21",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "CLEF eHealth Task 2013",
      "Type": "Challenges",
      "Task": "Clinical Outcome Prediction",
      "Domain": "Clinical Trails",
      "Download": "√",
      "Data Source": "https://mimic.mit.edu/docs/gettingstarted/",
      "Comment/Questions": "Credential needed",
      "link": "https://clefehealth.imag.fr/clefehealth.imag.fr/index3fd7.html?page_id=441",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "BIOSSES",
      "Type": "Benchmark",
      "Task": "Biomedical Sentence Similarity Estimation",
      "Format": "LFS",
      "Description": "BIOSSES is a benchmark dataset for biomedical sentence similarity estimation. The dataset comprises 100 sentence pairs, in which each sentence was selected from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset ",
      "Download": "√",
      "Reference": "https://tac.nist.gov/2014/BiomedSumm/",
      "Content (Data Format)": "Contains two column, sentence 1 and sentence 2, which are sampled from the training set of TAC dataset. Then, a column for similarity score between the two sentence, ranging from 0 (not related) to 4(equivalent).",
      "Comment/Questions": "Cannot find the registeration",
      "link": "https://clefehealth.imag.fr/clefehealth.imag.fr/index3fd7.html?page_id=441",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "Currently Unavailable",
      "link": "https://huggingface.co/datasets/tabilab/biosses",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "n2c2 (National NLP Clinical Challenges)",
      "Type": "Multiple Challenges",
      "Task": "Clinical Semantic Textual Similarity; Family History Extraction; Clinical Concept Normalization...",
      "Domain": "Clinical trials",
      "Description": "Unstructured notes from the Research Patient Data Registry at Partners Healthcare (originally developed during the i2b2 project)",
      "Download": "Particially Avaliable (2019 Challenge) Need Permission",
      "Data Source": "NIH-funded National Center for Biomedical Computing (NCBC)",
      "Comment/Questions": "Currently unavailable.",
      "link": "https://n2c2.dbmi.hms.harvard.edu/data-sets",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "MIMIC-III",
      "Type": "Corpus",
      "Task": "Clinical Outcome Prediction; Semantic Analysis",
      "Composition (TODO)": "MIMIC-III",
      "Domain": "Clinical Trails",
      "Format": "CSV",
      "Description": "MIMIC-III integrates deidentified, comprehensive clinical data of patients admitted to the Beth Israel Deaconess Medical Center in Boston, Massachusetts, and makes it widely accessible to researchers internationally under a data use agreement.",
      "Download": "Registration Needed",
      "Data Source": "https://www.nature.com/articles/sdata201635",
      "Comment/Questions": "Credential needed",
      "link": "https://n2c2.dbmi.hms.harvard.edu/data-sets",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "MedSTS(MIMIC-III derived data )",
      "Type": "Corpus",
      "Task": "Clinical Semantic Textual Similarity",
      "Domain": "Clinical Trails",
      "Download": "https://portal.dbmi.hms.harvard.edu/projects/n2c2-2019-t1/",
      "Reference": "https://link.springer.com/article/10.1007/s10579-018-9431-1",
      "Data Source": "Mayo Clinic’s clinical data warehouse",
      "Comment/Questions": "Need to contact author",
      "link": "https://mayoclinic.elsevierpure.com/en/publications/medsts-a-resource-for-clinical-semantic-textual-similarity",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "MedNLI",
      "Type": "Processed from previous dataset",
      "Task": "Natural Language Inference",
      "Domain": "Clinical Trails",
      "Format": "CSV",
      "Metric": "Accuracy",
      "Download": "√",
      "Reference": "Lessons from Natural Language Inference in the Clinical Domain",
      "Data Source": "https://arxiv.org/pdf/2304.07396",
      "Comment/Questions": "Credential needed",
      "link": "https://jgc128.github.io/mednli/",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "BLUE",
      "Type": "Benchmark",
      "Task": "Sentence similarity; Named entity recognition; Relation extraction; Document multilabel classification; Inference task",
      "Domain": "Not limited to Clinical Trails",
      "Format": "csv & xml & tsv",
      "Description": "BLUE benchmark consists of five different biomedicine text-mining tasks with ten corpora. ",
      "Metric": "All of 8 datasets' metric in github",
      "Download": "√",
      "Reference": "All of 8 datasets' reference in github. (5 datasets can be accessed directly )",
      "Content (Data Format)": "Benchmarks contains multiple datasets.",
      "Comment/Questions": "BIOSSES(only hundreds of amount of data), MedSTS, BC5CDR(in sheet 1), ShARe/CLEF, DDI(about drug), ChemProt, i2b2_2010(only website link), HoC, MedNLI",
      "link": "https://physionet.org/content/mimiciii/1.4/files",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "HoC",
      "Type": "Corpus",
      "Task": "Document multilabel classification",
      "Link": "in BLUE",
      "Format": "txt",
      "Description": " consists of 1852 PubMed publication abstracts manually annotated by experts according to the Hallmarks of Cancer taxonomy. The taxonomy consists of 37 classes in a hierarchy.",
      "Metric": "F",
      "Reference": "https://academic.oup.com/bioinformatics/article/32/3/432/1743783?login=false",
      "Content (Data Format)": "Index sentence labels(Medical Subject Headings)",
      "Comment/Questions": "\nIt has already been preprocessed using the method described in: https://arxiv.org/pdf/1811.05475v2.",
      "link": "https://mayoclinic.elsevierpure.com/en/publications/medsts-a-resource-for-clinical-semantic-textual-similarity",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "ICD Coding",
      "link": "https://jgc128.github.io/mednli/",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "BioASQ",
      "Type": "QA",
      "Task": "Clinical Summarization; Clinical Coding",
      "Format": "json",
      "Description": "BioASQ Task MultiClinSum on Multilingual Clinical Summarization; BioASQ Task ElCardioCC on Clinical Coding in Cardiology",
      "Download": "challenge in 2025",
      "Reference": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0564-6 ",
      "Data Source": "U.S. National Library of Medicine",
      "link": "https://github.com/ncbi-nlp/BLUE_Benchmark",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "Deep-GDAE Corpus",
      "Type": "self generated",
      "Task": "Classification",
      "Format": "csv & txt",
      "Description": "Gene-Disease Association Extraction",
      "link": "https://github.com/EsmaeilNourani/Deep-GDAE/tree/master",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "EU-ADR-Corpus",
      "Type": "Corpus",
      "Format": "txt",
      "Description": "Annotated drugs, diseases, targets, and their relationships",
      "Metric": "Agreement relations; Agreement entities",
      "Reference": "https://www.sciencedirect.com/science/article/pii/S1532046412000573",
      "link": "https://github.com/mi-erasmusmc/EU-ADR-Corpus",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "BioCreative VI",
      "Type": "Corpus",
      "Task": "chemical-protein interactions",
      "Format": "tsv",
      "Description": "BioCreative VI — Track 5: text mining chemical-protein interactions (ChemProt)",
      "Metric": "F1-scores",
      "Reference": "https://academic.oup.com/database/article/doi/10.1093/database/baz095/5587825?login=false",
      "link": "https://github.com/ruiantunes/biocreative-vi-track-5-chemprot",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "BioCreative V",
      "Type": "Corpus",
      "Task": "Chemial-Disease Relation",
      "Format": "txt & xml",
      "Description": " Automatic detection of chemical/drugs and diseases, and their relations in PubMed abstracts. In particular, the CDR task focuses on extracting the relationship of drug-induced diseases.",
      "Metric": "Mention evaluation; Relation evaluation",
      "Reference": "Zhiyong Lu, NCBI (zhiyong.lu@nih.gov) Thomas Wiegers, North Carolina State University (tcwieger@ncsu.edu )",
      "link": "https://participants-area.bioasq.org/datasets/",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "NCBI Disease",
      "Type": "Corpus",
      "Task": "disease name and concept annotations",
      "Format": "txt",
      "Description": "This dataset contains the disease name and concept annotations of the NCBI disease corpus, a collection of 793 PubMed abstracts fully annotated at the mention and concept level to serve as a research resource for the biomedical natural language processing community.",
      "link": "https://github.com/EsmaeilNourani/Deep-GDAE/tree/master",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "JNLPBA",
      "Type": "Benchmark",
      "Task": "Bio-Entity Recognition",
      "Format": "iob",
      "Description": "the JNLPBA The BioNLP / JNLPBA Shared Task 2004 involves the identification and classification of technical terms referring to concepts of interest to biologists in the domain of molecular biology. , in English language. Containing ~2,000 in Iob file format.",
      "Metric": "F-scores(CoNLL)",
      "Reference": "https://aclanthology.org/W04-1213/",
      "link": "https://github.com/mi-erasmusmc/EU-ADR-Corpus",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "S800",
      "Type": "Corpus",
      "Task": "Identification of Taxonomic Names",
      "Format": "txt",
      "Description": "a novel abstract-based manually annotated corpus. S800 comprises 800 PubMed abstracts in which organism mentions were identified and mapped to the corresponding NCBI Taxonomy identifiers.",
      "Metric": "F1; precision; recall",
      "Reference": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0065390",
      "link": "https://github.com/ruiantunes/biocreative-vi-track-5-chemprot",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Name": "GAD",
      "Type": "Corpus",
      "Task": "associations between genes and diseases",
      "Format": "LFS",
      "Description": "A corpus identifying associations between genes and diseases by a semi-automatic annotation procedure based on the Genetic Association Database.",
      "Metric": "F-scores",
      "Reference": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0472-9",
      "link": "https://github.com/JHnlp/BioCreative-V-CDR-Corpus",
      "_source_file": "Clinical_Trial_0.json",
      "_source_sheet": "Clinical Trial_0",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "QA, Text Generation",
      "Language": "English, Chinese",
      "Name": "Medical-O1-Reasoning-SFT",
      "Domain": "Medical",
      "Format": "JSON",
      "Description": "Fine-tuning dataset for HuatuoGPT-o1, constructed using GPT-4o to generate solutions to verifiable medical problems, validated through a medical verifier. Has a prompt, cot process, and responses coumns",
      "Number": "About 90000 rows",
      "Metric": "True/False (verified), accuracy",
      "Label": "CoT, (expected) responses ",
      "Download": "Yes",
      "Region": "US/India (India MEd Exam) (GPT curated dataset from MedQA)",
      "Reference": "@misc{chen2024huatuogpto1medicalcomplexreasoning,\n      title={HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs}, \n      author={Junying Chen and Zhenyang Cai and Ke Ji and Xidong Wang and Wanlong Liu and Rongsheng Wang and Jianye Hou and Benyou Wang},\n      year={2024},\n      eprint={2412.18925},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2412.18925}, \n}",
      "Institution": "FreedomAI/CUHK Shenzhen",
      "Paper Link": "https://arxiv.org/pdf/2412.18925",
      "link": "https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "QA, Text Generation",
      "Language": "English",
      "Name": "Medical-R1-Distill-Data",
      "Domain": "Medical",
      "Format": "JSON",
      "Description": "A supervised fine-tuning (SFT) dataset distilled from DeepSeek-R1, focusing on medical verifiable problems derived from HuatuoGPT-o1.",
      "Number": "About 22000",
      "Metric": "True/False based accuracy",
      "Label": "CoT with final responses",
      "Download": "Yes",
      "link": "https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "QA, Text Generation",
      "Language": "Chinese/Translated",
      "Name": "Medical-R1-Distill-Data-Chinese",
      "Domain": "Medical",
      "Format": "JSON",
      "Description": "Same as above, just in Chinese",
      "Number": "About 17000",
      "Metric": "True/False based accuracy",
      "Label": "CoT with final responses",
      "Download": "Yes",
      "link": "https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data-Chinese",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Clinic Diagnostic Reasoning",
      "Language": "English",
      "Composition (TODO)": "MedNLI, EmrQA, SOAP, MIMIC-III, NC2C (AP), MedQA",
      "Name": "DR.BENCH Diagnostic Reasoning Benchmark for clinical natural language processing",
      "Domain": "Medical",
      "Format": "Various/Depend on raw data",
      "Description": " A benchmark suite comprising six tasks derived from ten publicly available datasets, designed to evaluate clinical NLP models on diagnostic reasoning capabilities. Does not contain reason path/reaason based data though.",
      "Download": "No",
      "Region": "US (or NA, not new dataset)",
      "Reference": "@article{Gao_2023,\n   title={DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing},\n   volume={138},\n   ISSN={1532-0464},\n   url={http://dx.doi.org/10.1016/j.jbi.2023.104286},\n   DOI={10.1016/j.jbi.2023.104286},\n   journal={Journal of Biomedical Informatics},\n   publisher={Elsevier BV},\n   author={Gao, Yanjun and Dligach, Dmitriy and Miller, Timothy and Caskey, John and Sharma, Brihat and Churpek, Matthew M. and Afshar, Majid},\n   year={2023},\n   month=feb, pages={104286} }",
      "Institution": "UWMadison",
      "Paper Link": "https://arxiv.org/pdf/2209.14901",
      "link": "https://git.doit.wisc.edu/smph-public/dom/uw-icu-data-science-lab-public/drbench/-/tree/main/Tasks?ref_type=heads",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "QA",
      "Language": "English",
      "Name": "MedReason",
      "Domain": "Medical",
      "Format": "jsonl",
      "Description": "High-quality CoT dataset using knowledge graphs to guide and verify each reasoning step for medical questions.",
      "Number": 32700,
      "Metric": "Accuracy plus CoT Preferences",
      "Label": "Answer + CoT",
      "Download": "Yes, https://huggingface.co/datasets/UCSC-VLAA/MedReason",
      "Region": "Global/Med Exam Questions, US, India",
      "Reference": "@misc{wu2025medreasonelicitingfactualmedical,\n      title={MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs}, \n      author={Juncheng Wu and Wenlong Deng and Xingxuan Li and Sheng Liu and Taomian Mi and Yifan Peng and Ziyang Xu and Yi Liu and Hyunjin Cho and Chang-In Choi and Yihan Cao and Hui Ren and Xiang Li and Xiaoxiao Li and Yuyin Zhou},\n      year={2025},\n      eprint={2504.00993},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2504.00993}, \n}",
      "Institution": "UCSC-VLAA",
      "Paper Link": "https://arxiv.org/pdf/2504.00993",
      "link": "https://huggingface.co/papers/2504.00993",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Multiple Choice",
      "Language": "English",
      "Name": "MedAgents",
      "Domain": "Mecial",
      "Format": "hf dataset/parquet",
      "Description": "A curated benchmark focusing on challenging medical questions requiring multi-step clinical reasoning, diagnosis formulation, and treatment planning. It evaluates large language models (LLMs) and agent frameworks on complex medical reasoning tasks, emphasizing collaborative problem-solving among simulated medical agents.",
      "Number": "11257, from various other source",
      "Metric": "Accuracy",
      "Label": "Choice with reasoning explanation",
      "Download": "Yes",
      "Region": "Global (PubMed, etc.) (US Hosted)",
      "Reference": "@misc{tang2025medagentsbenchbenchmarkingthinkingmodels,\n      title={MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning}, \n      author={Xiangru Tang and Daniel Shao and Jiwoong Sohn and Jiapeng Chen and Jiayi Zhang and Jinyu Xiang and Fang Wu and Yilun Zhao and Chenglin Wu and Wenqi Shi and Arman Cohan and Mark Gerstein},\n      year={2025},\n      eprint={2503.07459},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2503.07459}, \n}",
      "Institution": "Yale, UT Southwestern Medical Center",
      "Paper Link": "https://arxiv.org/pdf/2503.07459",
      "link": "https://huggingface.co/datasets/super-dainiu/medagents-benchmark",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "QA",
      "Language": "English",
      "Name": "ReasonMed",
      "Domain": "Medical",
      "Format": "json/hf",
      "Description": "Large-scale dataset of medical QA with multi-agent generated and validated step-by-step reasoning paths",
      "Number": "370,000+",
      "Metric": "Accuracy, reasoning coherence",
      "Label": "Answer with CoT",
      "Download": "Yes",
      "Region": "PubMed, MedMCQA, etc. (Global, US)",
      "Reference": "@misc{sun2025reasonmed370kmultiagentgenerated,\n      title={ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning}, \n      author={Yu Sun and Xingyu Qian and Weiwen Xu and Hao Zhang and Chenghao Xiao and Long Li and Yu Rong and Wenbing Huang and Qifeng Bai and Tingyang Xu},\n      year={2025},\n      eprint={2506.09513},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2506.09513}, \n}",
      "Institution": "SJTU, Alibaba",
      "Paper Link": "https://arxiv.org/abs/2506.09513",
      "link": "https://huggingface.co/datasets/lingshu-medical-mllm/ReasonMed",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "QA/Clinical",
      "Language": "English",
      "Name": "ClinicR",
      "Domain": "Clinical ",
      "Format": "xlsx",
      "Description": "GPT and medcial experts constructed dataset with focus on reasonings",
      "Number": "About 500",
      "Metric": "Answer Accuracy",
      "Label": "Final Answer with Step Step rationaled",
      "Download": "Yes",
      "Region": "Clinical Case from US",
      "Reference": "@misc{nachane2024shotchainofthoughtdrivenreasoning,\n      title={Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering}, \n      author={Saeel Sandeep Nachane and Ojas Gramopadhye and Prateek Chanda and Ganesh Ramakrishnan and Kshitij Sharad Jadhav and Yatin Nandwani and Dinesh Raghu and Sachindra Joshi},\n      year={2024},\n      eprint={2403.04890},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2403.04890}, \n}",
      "Paper Link": "https://arxiv.org/pdf/2403.04890",
      "link": "https://github.com/ColdSeal/ClinicR",
      "_source_file": "Reasoning_Data.json",
      "_source_sheet": "Reasoning Data",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "1. Recognition and classification of pharmacological substances.\n2. Extraction of drug-drug interactions.",
      "Name": "DDIExtraction 2013",
      "Domain": "drug-drug interactions",
      "Format": "xml",
      "Description": "The DDIExtraction 2013 task relies on the DDI corpus which contains MedLine abstracts on drug-drug interactions as well as documents describing drug-drug interactions from the DrugBank database",
      "Number": "https://aclanthology.org/S13-2056.pdf",
      "Metric": "precision, recall and F-score",
      "Label": "pharmacological substances;\ndrug-drug interactions",
      "Download": "√",
      "Region": "Global (DrugBank and MEDLINE), Hosting in US and Canada",
      "Reference": "Segura-Bedmar, Isabel, Paloma Martínez, and María Herrero-Zazo. \"Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts (ddiextraction 2013).\" In Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pp. 341-350. 2013.",
      "Group": "Bio/medical research literature",
      "Institution": "U.S. National Library of Medicine, University of Alberta (hosting), Universidad Carlos III de Madrid (DDI Corpus)",
      "link": "https://github.com/isegura/DDICorpus",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Classification",
      "Language": "English",
      "Name": "Cirrhosis Prediction Dataset",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "The data contains the information collected from the Mayo Clinic trial in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and 1984. ",
      "Number": 424,
      "Metric": "Classification Metric",
      "Label": "histologic stage of disease",
      "Download": "√",
      "Region": "Minnesota (Mayo Clinic)",
      "Reference": "Fleming, T.R. and Harrington, D.P. (1991)",
      "Group": "Other - Clinical Prediction",
      "Institution": "Mayo Clinic",
      "link": "https://www.kaggle.com/datasets/fedesoriano/cirrhosis-prediction-dataset",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Classification",
      "Language": "English",
      "Name": "Heart Failure Prediction Dataset",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease.",
      "Number": 1190,
      "Metric": "Classification Metric",
      "Label": "binary heart disease (0,1)",
      "Download": "√",
      "Region": "Cleveland, Hungary, Switzerland, Long Beach VA, ",
      "Reference": "Andras Janosi, M.D.;William Steinbrunn, M.D.;Matthias Pfisterer, M.D.;Robert Detrano, M.D., Ph.D.;",
      "Group": "Other - Clinical Prediction",
      "Institution": "Maintained by UCI",
      "link": "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Classification, Clustering",
      "Language": "English",
      "Name": "Hepatitis C Prediction Dataset",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age. ",
      "Number": 615,
      "Metric": "Classification Metric",
      "Label": "Hepatitis Diagnosis",
      "Download": "√",
      "Region": "Germany",
      "Reference": "The data was obtained from UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/HCV+data",
      "Group": "Other - Clinical Prediction",
      "Institution": "Trillium GmbH and German Heart Center,",
      "link": "https://www.kaggle.com/datasets/fedesoriano/hepatitis-c-dataset",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Database",
      "Name": "NCBI",
      "Domain": "Gene; Genome; Virus; Taxonomy",
      "Format": "jsonl\njson\nFASTA",
      "Description": "NCBI Datasets provides sequence, annotation, metadata and other biological data as an NCBI Datasets Data Package zip archive.",
      "Label": "F1",
      "Download": "√",
      "Region": "Global biological data, us hosted",
      "Reference": "O’Leary, Nuala A., Eric Cox, J. Bradley Holmes, W. Ray Anderson, Robert Falk, Vichet Hem, Mirian TN Tsuchiya et al. \"Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets.\" Scientific data 11, no. 1 (2024): 732.",
      "Group": "Bio/medical research literature",
      "Institution": " National Center for Biotechnology Information",
      "link": "https://github.com/ncbi/datasets",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Database;\nhttps://arxiv.org/pdf/2004.10706\nTable2",
      "Language": "English",
      "Name": "CORD-19",
      "Domain": "biomedical literature",
      "Format": "hf data",
      "Description": "CORD-19 is a free resource of tens of thousands of scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses for use by the global research community.",
      "Number": "Over 1,000,000 articles; ~370,000 with full text ",
      "Download": "√",
      "Region": "America, Europe, Asia (Global Coverage Research Corpus)",
      "Reference": "Wang, Lucy Lu, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Doug Burdick, Darrin Eide et al. \"Cord-19: The covid-19 open research dataset.\" arXiv preprint arXiv:2004.10706 (2020).",
      "Group": "Bio/medical research literature",
      "Institution": "Semantic Scholar team at the Allen Institute for AI t",
      "link": "https://huggingface.co/datasets/allenai/cord19",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Document Classification (Multi-class Classification)",
      "Language": "English",
      "Name": "HOC (Hallmarks of Cancer)",
      "Domain": "Cancer",
      "Format": "txt",
      "Description": "The Hallmarks of Cancer (*HOC) corpus consists of 1852 PubMed publication abstracts manually annotated by experts according to the Hallmarks of Cancer taxonomy. The taxonomy consists of 37 classes in a hierarchy. Zero or more class labels are assigned to each sentence in the corpus.",
      "Number": 1852,
      "Metric": "Accuracy;\nF1",
      "Label": "37 classes in a hierarchy. zero or more class labels are assigned to each sentence in the corpus",
      "Download": "√",
      "Region": "PubMed (Global Coverage, selected pubmed data)",
      "Reference": "https://academic.oup.com/bioinformatics/article/32/3/432/1743783?utm_source=chatgpt.com&login=false",
      "Group": "Bio/medical research literature",
      "Institution": "University of Cambridge & Karolinska Institutet",
      "link": "https://huggingface.co/datasets/qanastek/HoC",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "ECG classification",
      "Language": "English",
      "Name": "PTB-XL",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "The PTB-XL ECG dataset is a large dataset of 21799 clinical 12-lead ECGs from 18869 patients of 10 second length. ",
      "Number": 21799,
      "Metric": "NA (depends on downstream task)",
      "Label": "multi-label diagnosis",
      "Download": "via physionet",
      "Region": "Berlin Germany",
      "Group": "Other - Clinical Prediction",
      "Institution": "Physikalisch-Technische Bundesanstalt",
      "link": "https://physionet.org/content/ptb-xl/1.0.3/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Information Retrieval",
      "Language": "English",
      "Name": "TREC-COVID",
      "Domain": "COVID-19",
      "Format": "xml/json, qrels",
      "Description": "Multi-round shared task with manual relevance judgments on scientific COVID-19 articles, designed for pandemic IR evaluation",
      "Number": "50 topics (final Round 5); cumulative ~69,318 manual judgments across ~207K judged docs",
      "Metric": "trec_eval;\nhttps://github.com/usnistgov/trec_eval\nNDCG@10",
      "Label": "Relevancy 0, 1,2",
      "Download": "Website Failed\nWill figure out later",
      "Region": "Subset of CORD-19",
      "Reference": "https://ir.nist.gov/trec-covid/bib.html",
      "Group": "Bio/medical research literature",
      "Institution": "National Institute of Standards and Technology ",
      "link": "https://ir.nist.gov/trec-covid/index.html",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Information Retrieval",
      "Language": "English",
      "Name": "NFCorpus",
      "Domain": "http://nutritionfacts.org/",
      "Format": "queries files\ndocs files\nqrel files",
      "Description": "NFCorpus is a full-text English retrieval data set for Medical Information Retrieval. It contains a total of 3,244 natural language queries (written in non-technical English, harvested from the NutritionFacts.org site) with 169,756 automatically extracted relevance judgments for 9,964 medical documents (written in a complex terminology-heavy language), mostly from PubMed.",
      "Number": 3244,
      "Metric": "Ranking Scores;\nF1",
      "Label": "Relevance Links",
      "Download": "√",
      "Region": "Pulled from PubMed",
      "Reference": "Boteva, Vera, Demian Gholipour, Artem Sokolov, and Stefan Riezler. \"A full-text learning to rank dataset for medical information retrieval.\" In Advances in Information Retrieval: 38th European Conference on IR Research, ECIR 2016, Padua, Italy, March 20–23, 2016. Proceedings 38, pp. 716-722. Springer International Publishing, 2016.",
      "Group": "Consumer Questions",
      "Institution": "NutritionFacts.org",
      "link": "https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Link prediction",
      "Language": "English",
      "Name": "IS-A/Part-of",
      "Domain": "Medical",
      "Format": "edgelist",
      "Description": "The IS-A dataset is a dataset of relations extracted from a medical ontology. The different entities in the ontology are related by the “is a” relation.",
      "Metric": "AUC",
      "Label": "Binary",
      "Download": "√",
      "Region": "UMLS (US maintained)",
      "Group": "Consumer Questions",
      "Institution": "University of Sheffield; Athens University of Economics and Business; Bloomberg; University of London; University of Crete",
      "link": "https://github.com/SotirisKot/Content-Aware-Node2Vec",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Named Entity Recognition;\nNamed Entity Linking;\nInformation Extraction",
      "Language": "English",
      "Name": "SourceData",
      "Domain": "biomedical literature",
      "Format": "xml\njson\ncsv",
      "Description": "SourceData is the largest annotated biomedical dataset for NER and NEL. It is unique on its focus on the core of scientific evidence: figure captions. It is also unique on its real-world configuration, since it does not present isolated sentences out of more general context.",
      "Number": "https://huggingface.co/datasets/EMBO/SourceData",
      "Metric": "Accuracy",
      "Label": "IOB2-style tags",
      "Download": "√",
      "Region": "Germany EMBO hosted",
      "Reference": "Liechti, Robin, Nancy George, Lou Götz, Sara El-Gebali, Anastasia Chasapi, Isaac Crespo, Ioannis Xenarios, and Thomas Lemberger. \"SourceData: a semantic platform for curating and searching figures.\" Nature methods 14, no. 11 (2017): 1021-1022.",
      "Group": "Bio/medical research literature",
      "Institution": "EMBO",
      "link": "https://huggingface.co/datasets/EMBO/SourceData",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Natural Language Inference",
      "Language": "English",
      "Name": "BioNLI",
      "Domain": "Biomedical Research Papers",
      "Format": "csv",
      "Description": "BioNLI is the first dataset in biomedical natural language inference. This dataset contains abstracts from biomedical literature and mechanistic premises generated with nine different strategies.",
      "Number": "13489 positive, 26907 negative",
      "Metric": "F1, Accuracy",
      "Label": "Entailment, Contradiction",
      "Download": "√",
      "Region": "Extracted from PubMed/MEDLINE, global coverage",
      "Group": "Bio/medical research literature",
      "Institution": "SBU NLP lab",
      "link": "https://drive.google.com/drive/folders/1-zNfaoDdszvu8cTCRqx9s1EWM2qZ0wcI?usp=sharing",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Natural Language Inference",
      "Language": "Russian ",
      "Name": "RuMedNLI",
      "Domain": "Clinical",
      "Format": "jsonl",
      "Description": "RuMedNLI is the full counterpart dataset of MedNLI in Russian language.",
      "Number": "training: 11232, Dev: 1395, Test: 1422",
      "Metric": "Accuracy;",
      "Label": "entailment; neutral; contradiction",
      "Download": "√",
      "Region": "Russia translated MedNLI",
      "Group": "Medical Exam Questions",
      "Institution": "Russian translators",
      "link": "https://www.physionet.org/content/rumednli-russian-inference/1.0.0/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Type": "NLP",
      "Task": "\nQuestion Answering",
      "Language": "English",
      "Name": "PubMedQA",
      "Domain": "Biomedical Research Papers",
      "Format": "json",
      "Description": "The task of PubMedQA is to answer research questions with yes/no/maybe using the corresponding abstracts.",
      "Number": "1k expert labeled, 61.2k unlabeled and 211.3k artificially generated QA instances",
      "Metric": "Accuracy; Macro-F1",
      "Label": "options",
      "Download": "√",
      "Region": "QA pairs from PubMed abstracts, cover globally",
      "Reference": "Jin, Qiao, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu. \"PubMedQA: A Dataset for Biomedical Research Question Answering.\" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 2567-2577. 2019.",
      "Group": "Bio/medical research literature",
      "Institution": "CMU, UPitt, Google",
      "link": "https://github.com/pubmedqa/pubmedqa",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "MedMCQA",
      "Domain": "Medical entrance exam questions",
      "Format": "json",
      "Description": "MedMCQA, a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address realworld medical entrance exam questions.",
      "Number": "194k",
      "Metric": "Accuracy",
      "Label": "The single or multiple answers from the option set",
      "Download": "√",
      "Region": "India",
      "Reference": "Pal, Ankit, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. \"Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering.\" In Conference on health, inference, and learning, pp. 248-260. PMLR, 2022.",
      "Group": "Medical Exam Questions",
      "Institution": "Saama AI Research",
      "link": "https://github.com/MedMCQA/MedMCQA",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English and simplified Chinese",
      "Name": "MedQA-USMLE",
      "Domain": "Medical Exams",
      "Format": "jsonl",
      "Description": "The data that contains both the QAs and textbooks can be downloaded from this google drive folder including various sources from US, China mainland and Taiwan",
      "Number": 61097,
      "Metric": "Accuracy\n",
      "Label": "Options and Evidence",
      "Download": "√",
      "Region": "US, Mainland of China, and Taiwan District",
      "Reference": "Jin, Di, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. \"What disease does this patient have? a large-scale open domain question answering dataset from medical exams.\" Applied Sciences 11, no. 14 (2021): 6421.",
      "Group": "Medical Exam Questions",
      "Institution": "MIT",
      "link": "https://www.kaggle.com/datasets/moaaztameer/medqa-usmle",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "LiveQA TREC 2017",
      "Domain": "consumer health question answering",
      "Format": "xml",
      "Description": "The LiveQA'17 medical task focuses on consumer health question answering. We use consumer health questions received by the U.S. National Library of Medicine (NLM). \nWe constructed medical question-answer pairs for training and testing, with additional annotations that can be used to develop question analysis and question answering systems.  ",
      "Number": "634 question-answer pairs for training, test questions cover 26 question types associated with five focus categories.",
      "Metric": "Accuracy",
      "Region": "US/NIH, live Questions",
      "Group": "Consumer Questions",
      "Institution": "National Library of Medicin",
      "link": "https://github.com/abachaa/LiveQA_MedicalTask_TREC2017?tab=readme-ov-file",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "MedicationQA",
      "Domain": "Consumers’ Medication Questions and Trusted Answers",
      "Format": "xlsx",
      "Description": "The gold standard corpus for medication question answering introduced in the MedInfo 2019 paper \"Bridging the Gap between Consumers’ Medication Questions and Trusted Answers\": http://ebooks.iospress.nl/publication/51941",
      "Number": 690,
      "Metric": "QA Eval (accuracy, etc.)",
      "Label": "QA Pairs",
      "Download": "√",
      "Region": "US Consumer Questions",
      "Group": "Consumer Questions",
      "Institution": "National Library of Medicine",
      "link": "https://huggingface.co/datasets/truehealth/medicationqa",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "MedQuAD",
      "Domain": "Consumer Health Question answering",
      "Format": "xml",
      "Description": "QA dataset mapping natural user questions to expert answers from trusted NIH health websites; includes evaluation set judged for relevance using TREC-LiveQA medical track grading",
      "Number": 47457,
      "Metric": "QA Eval (accuracy, etc.)",
      "Label": "QA Pairs",
      "Download": "√",
      "Region": "US Gov Websites",
      "Group": "Consumer Questions",
      "Institution": "National Library of Medicine",
      "link": "https://github.com/abachaa/MedQuAD",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "RadQA",
      "Domain": "Medical",
      "Description": "present a radiology question answering dataset, RadQA, with 3074 questions posed against radiology reports and annotated with their corresponding answer spans by physicians.",
      "Number": 6148,
      "Metric": "F1",
      "Label": "QA Pairs",
      "Download": "restricted-access resource",
      "Region": "Boston, MA\n",
      "Group": "Medical Exam Questions",
      "Institution": "PhysioNet",
      "link": "https://physionet.org/content/radqa/1.0.0/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "CliCR",
      "Domain": "Medical",
      "Description": " a new dataset for domain specific reading comprehension used to construct around 100,000 cloze queries from clinical case reports.",
      "Number": "~100000",
      "Metric": "F1",
      "Label": "Medical entities",
      "Download": "Please send us an email to simon.suster@unimelb.edu.au, and we will provide you with the link.",
      "Region": "UK Hosted Data (BMJ Case reports)",
      "Group": "Medical Exam Questions",
      "Institution": "University of Antwerp ",
      "link": "https://github.com/clips/clicr",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Regression",
      "Language": "English",
      "Name": "Body Fat Prediction Dataset",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "Lists estimates of the percentage of body fat determined by underwater\nweighing and various body circumference measurements for 252 men.",
      "Number": 251,
      "Metric": "Regression Metrics?",
      "Label": "Metadatas",
      "Download": "√",
      "Region": "BYU",
      "Reference": "Dr. A. Garth Fisher;",
      "Group": "Other - Clinical Prediction",
      "Institution": "BYU",
      "link": "https://www.kaggle.com/datasets/fedesoriano/body-fat-prediction-dataset",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Relation Extraction",
      "Language": "English",
      "Name": "BC5CDR",
      "Domain": "Chemical Disease Relation ",
      "Format": "xml\ntxt",
      "Description": "The BioCreative V Chemical Disease Relation (CDR) dataset is a large annotated text corpus of human annotations of all chemicals, diseases and their interactions in 1,500 PubMed articles.",
      "Number": "1500 PubMed articles with 4409 annotated chemicals, 5818 diseases and 3116 chemical-disease interactions.",
      "Metric": "F1",
      "Label": "Entities (Chemical and Disease)",
      "Download": "√",
      "Region": "US PubMed, Global Coverage",
      "Reference": "Li, Jiao, Yueping Sun, Robin J. Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis, Carolyn J. Mattingly, Thomas C. Wiegers, and Zhiyong Lu. \"BioCreative V CDR task corpus: a resource for chemical disease relation extraction.\" Database 2016 (2016).",
      "Group": "Bio/medical research literature",
      "Institution": "National Center for Biotechnology Information",
      "link": "https://huggingface.co/datasets/bigbio/bc5cdr",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Relational Database",
      "Language": "English",
      "Name": "MIMIC-III",
      "Domain": "Clinical",
      "Format": "CSV",
      "Description": "MIMIC-III integrates deidentified, comprehensive clinical data of patients admitted to the Beth Israel Deaconess Medical Center in Boston, Massachusetts, and makes it widely accessible to researchers internationally under a data use agreement.",
      "Number": "46,520 distinct ICU patients\n\n53,423 hospital admissions",
      "Metric": "F1",
      "Label": "Outcomes, demographics, clinical events, notes",
      "Download": "Restricted-access resource;\nneed agreement",
      "Region": "Boston, Massachusetts",
      "Reference": "Johnson, Alistair EW, Tom J. Pollard, Lu Shen, Li-wei H. Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G. Mark. \"MIMIC-III, a freely accessible critical care database.\" Scientific data 3, no. 1 (2016): 1-9.",
      "Group": "Other - Database",
      "Institution": "PhysioNet",
      "link": "https://physionet.org/content/mimiciii/1.4/files",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Stroke classification; Imbalance classification",
      "Language": "English",
      "Name": "Stroke Prediction Dataset",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "This dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status.",
      "Number": 5110,
      "Metric": "Acc/F1",
      "Label": "Binary 1/0 for stroke",
      "Download": "√",
      "Reference": "\n(Confidential Source) - Use only for educational purposes\nIf you use this dataset in your research, please credit the author.",
      "Group": "Other - Clinical Prediction",
      "link": "https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Text Summarization",
      "Language": "English",
      "Name": "PubMed",
      "Domain": "biomedical literature",
      "Format": "json",
      "Description": "PubMed comprises more than 36 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full-text content from PubMed Central and publisher web sites.",
      "Number": "~36million",
      "Metric": "ROUGE-1",
      "Download": "√",
      "Region": "US hosted",
      "Group": "Bio/medical research literature",
      "Institution": "National Library of Medicine",
      "link": "https://huggingface.co/datasets/ncbi/pubmed",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Text Summarization",
      "Language": "English",
      "Name": "MeQSum",
      "Domain": "Mecial NLP/Summarization",
      "Format": "xlsx",
      "Description": "Abstractive summarization dataset transforming verbose consumer health questions into concise medical inquiries. Suitable for training and evaluating summarization models.",
      "Number": 1000,
      "Metric": "ROUGE",
      "Label": "Expert Summary",
      "Download": "√",
      "Region": "Question to NIH, US",
      "Reference": "@Inproceedings{MeQSum,\nauthor = {Asma {Ben Abacha} and Dina Demner-Fushman},\ntitle = {On the Summarization of Consumer Health Questions},\nbooktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28th - August 2},\nyear = {2019},\nabstract = {Question understanding is one of the main challenges in question answering. In real world applications, users often submit natural language questions that are longer than needed and include peripheral information that increases the complexity of the question, leading to substantially more false positives in answer retrieval. In this paper, we study neural abstractive models for medical question summarization. We introduce the MeQSum corpus of 1,000 summarized consumer health questions. We explore data augmentation methods and evaluate state-of-the-art neural abstractive models on this new task. In particular, we show that semantic augmentation from question datasets improves the overall performance, and that pointer-generator networks outperform sequence-to-sequence attentional models on this task, with a ROUGE-1 score of 44.16%. We also present a detailed error analysis and discuss directions for improvement that are specific to question summarization. }}",
      "Group": "Consumer Questions",
      "Institution": "NIH",
      "link": "https://huggingface.co/datasets/sumedh/MeQSum",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Time series forecasting",
      "Language": "English",
      "Name": "ExtMarker",
      "Domain": "Medical",
      "Format": "csv",
      "Description": "A collection of nine time-series recordings of three-dimensional positions of reflective markers placed on the chest and abdomen of healthy volunteers during natural breathing (sampling at approximately 10 Hz over 73–222 s). ",
      "Number": 9,
      "Metric": "RMSE",
      "Label": "Continuous coordinates",
      "Download": "√",
      "Region": "Lithuania",
      "Group": "Other - Time Series",
      "Institution": "https://arxiv.org/pdf/1508.00749 (check here)",
      "link": "https://github.com/pohl-michel/time-series-forecasting-with-UORO-RTRL-LMS-and-linear-regression/tree/main",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Multitask Clinical NLP",
      "Language": "English, Chinese, Spanish, German, French, Portuguese, Korean, Japanese, Vietnamese (Multilingual)",
      "Name": "BRIDGE",
      "Domain": "Medical/Clinical",
      "Format": "json",
      "Description": "Large-scale multilingual benchmark, how LLMs udnerstand real-world clinical text-especially from electronic health records (EHRs) across 87 tasks, 9 languages, 14 clinical specialities.",
      "Number": "1.4millions",
      "Metric": "Task Specific (Accuracy, BLEU, etc.)",
      "Label": "Varies by task (entities, codes, diagnoses, answers, etc)",
      "Download": "√ (need hf authorization first)",
      "Region": "USA, clinical text from the other languages (likely the region as well)",
      "Institution": "Havard, Brigham and\nWomen's Hospital & Harvard Medical School",
      "link": "https://huggingface.co/datasets/YLab-Open/BRIDGE-Open",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Clinical Trial",
      "Language": "English",
      "Name": "MIMIC‑IV v3.1",
      "Domain": "Clinical",
      "Format": "Relational Tabels/CSV",
      "Description": "De-identified electronic health records from routine clinical care at BIDMC (2008–2019), organized modularly to support flexible analysis, linking structured data (lab results, vitals, orders) with unstructured clinical notes and physiological signals.",
      "Download": "Credential Needed",
      "Region": "Boston, MA",
      "Institution": "PhysioNet",
      "link": "https://physionet.org/content/mimiciv/3.1/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "JAMA Clinical Challenge",
      "Domain": "Clinical Reasoning, QA",
      "Format": "jsonl",
      "Description": "Challenging, real-world clinical case questions sourced from JAMA Clinical Challenge archive (2013–2023), each with question, 4 choices, and human expert explanation",
      "Number": 1524,
      "Metric": "Accuracy, Correctness, Completeness, Relevance",
      "Label": "Answer (MC) with Human expert explanation",
      "Download": "√",
      "Region": "us hosted data",
      "Institution": "JAMA, US based",
      "link": "https://huggingface.co/datasets/JesseLiu/Jama_challenge",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "Medbullets‑5",
      "Domain": "Clinical Reasoning, QA",
      "Format": "jsonl",
      "Description": "308 high‑quality USMLE Step 2/3–style clinical questions from Medbullets, each with case, 5 answer options, and human expert explanation ",
      "Number": 308,
      "Metric": "Accuracy, Correctness, Completeness, Relevance",
      "Label": "Answer (MC) with Human expert explanation",
      "Download": "√",
      "Region": "US Medical Exam",
      "Reference": "https://arxiv.org/abs/2402.18060",
      "Institution": "JHU",
      "link": "https://huggingface.co/datasets/JesseLiu/medbulltes5op",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Question Answering",
      "Language": "English",
      "Name": "Medbullets‑4",
      "Domain": "Clinical Reasoning, QA",
      "Format": "jsonl",
      "Description": "Medbullets-5 but with 4 options",
      "Number": 308,
      "Metric": "Accuracy, Correctness, Completeness, Relevance",
      "Label": "Answer (MC) with Human expert explanation",
      "Download": "√",
      "Region": "US Medical Exam",
      "Reference": "https://arxiv.org/abs/2402.18060",
      "Institution": "JHU",
      "link": "https://huggingface.co/datasets/JesseLiu/medbulltes4op",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Clinical Trial",
      "Language": "English",
      "Name": "Trialbench",
      "Domain": "Clinical Trials Tasks",
      "Description": "A suite of 23 curated datasets for 8 critical clinical trial prediction tasks—duration forecasting, dropout rate, serious adverse events, mortality, trial approval, failure reason classification, eligibility criteria generation, and dose-finding—derived from ClinicalTrials.gov, enriched with DrugBank and TrialTrove metadata",
      "Number": "Vary by tasks, total about ~40000 trials",
      "Metric": "RMSE, F1, AUC, etc, vary by tasks",
      "Download": "√",
      "Region": "US Based",
      "Reference": "https://arxiv.org/pdf/2407.00631",
      "Institution": "ClinicalTrials.Gov",
      "link": "https://huyjj.github.io/Trialbench/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Clinical Trial",
      "Language": "English",
      "Name": "CliniFact",
      "Domain": "Clinical Trials Tasks",
      "Format": "csv",
      "Description": "A benchmark for evaluating LLMs on medical research claim verification: atomic claims (“<Intervention> is <stat test> to <Comparator> for <Outcome>”) extracted from ClinicalTrials.gov and linked to abstracts labeled as supporting evidence, inconclusive, or NEI. Includes trial features (arms, p-values, stats).",
      "Number": " 1,970 instances from 992 unique clinical trials related to 1,540 unique publications",
      "Metric": "F1, Accuracy",
      "Label": "Inclusion/Eligibility",
      "Download": "√",
      "Region": "US Based",
      "Reference": "https://arxiv.org/pdf/2407.00631",
      "Institution": "ClinicalTrials.Gov",
      "link": "https://github.com/ds4dh/CliniFact",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Task": "Clinical Trial",
      "Language": "English",
      "Name": "UK Biobank",
      "Domain": "Biomedical Database",
      "Format": "csv",
      "Description": "large-scale biomedical database and research resource. Record from more than 500,000 pateints",
      "Download": "√",
      "Region": "UK",
      "Institution": "UK Biobank",
      "link": "https://www.ukbiobank.ac.uk/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "Bio_dataset_for_NLP_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Visual Question Answering",
      "Modality": "CT",
      "Name": "CT-RATE",
      "Link": "CT-RATE",
      "Domain": "lung, liver, mediastinum, kidney, heart, etc.",
      "Dimension": "Mixed",
      "Format": "nii, csv",
      "Description": "CT-RATE is an innovative dataset in 3D medical imaging that uniquely combines chest CT images with corresponding radiology text reports, addressing the challenge of limited comprehensive datasets in the field. It contains 25,692 non-contrast chest CT volumes (expandable to 50,188) from 21,304 unique patients, each accompanied by radiology text reports, multi-abnormality labels, and metadata, all freely accessible to researchers. The dataset is divided into a training set of 20,000 patients and a validation set of 1,304 patients, with a clear file naming structure of split_patientID_scanID_reconstructionID to facilitate easy access and utilization by researchers.\n",
      "#": "21,304 unique patients with textual reports",
      "Metric": "AUROC,  F1 Score,  Accuracy, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "1. @article{hamamci2024foundation,\n  title={A foundation model utilizing chest CT volumes and radiology reports for supervised-level zero-shot detection of abnormalities},\n  author={Hamamci, Ibrahim Ethem and Er, Sezgin and Almas, Furkan and Simsek, Ayse Gulnihan and Esirgun, Sevval Nil and Dogan, Irem and Dasdelen, Muhammed Furkan and Wittmann, Bastian and Simsar, Enis and Simsar, Mehmet and others},\n  journal={arXiv preprint arXiv:2403.17834},\n  year={2024}\n}\n\n2. @article{hamamci2023generatect,\n  title={GenerateCT: Text-Conditional Generation of 3D Chest CT Volumes},\n  author={Hamamci, Ibrahim Ethem and Er, Sezgin and Sekuboyina, Anjany and Simsar, Enis and Tezcan, Alperen and Simsek, Ayse Gulnihan and Esirgun, Sevval Nil and Almas, Furkan and Dogan, Irem and Dasdelen, Muhammed Furkan and others},\n  journal={arXiv preprint arXiv:2305.16037},\n  year={2023}\n}\n\n3. @article{hamamci2024ct2rep,\n  title={Ct2rep: Automated radiology report generation for 3d medical imaging},\n  author={Hamamci, Ibrahim Ethem and Er, Sezgin and Menze, Bjoern},\n  journal={arXiv preprint arXiv:2403.06801},\n  year={2024}\n}\n ",
      "modality description": "all CT",
      "link": "https://huggingface.co/datasets/ibrahimhamamci/CT-RATE/:~:text=CT-RATE:%20A%20novel%20dataset%20of%20chest%20CT%20volumes",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Question Answering",
      "Modality": "CT, MR, Endoscopy, X-Ray, Ultrasound, Histopathology, Dermoscopy, Microscopy, Fundus, PET",
      "Name": "LLaVA-Med",
      "Link": "LLaVA-Med",
      "Domain": "cell, rib, tissue, face, brain, vascular, liver, bone, lymph, etc.",
      "Dimension": "Mixed",
      "Format": "jpg, json",
      "Description": "The LLaVA-Med dataset is designed to train instruction-following assistants using biomedical image-text pairs. It includes 600,000 image-text pairs for concept alignment, where questions prompt descriptions of images, and 60,000 pairs for instruction tuning, featuring multi-round conversations about the images with added context from original PubMed papers. This dataset enables improved interaction capabilities for models in the biomedical field, enhancing their ability to generate meaningful responses based on visual and textual data.",
      "#": "660k image-text pairs",
      "Metric": "Open-Closed",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{li2023llavamed,\n  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},\n  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},\n  journal={arXiv preprint arXiv:2306.00890},\n  year={2023}\n}",
      "modality description": "VQA answer ",
      "link": "https://github.com/microsoft/LLaVA-Med",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Question Answering",
      "Modality": "Pathology",
      "Name": "Path-VQA training",
      "Link": "Path-VQA training",
      "Domain": " \n         \ngastrointestinal, colon, appendix, pinworm,etc.",
      "Dimension": "Mixed",
      "Format": "Parquet",
      "Description": "PathVQA is a dataset of question-answer pairs on pathology images. The dataset is intended to be used for training and testing Medical Visual Question Answering (VQA) systems. The dataset includes both open-ended questions and binary \"yes/no\" questions. The dataset is built from two publicly-available pathology textbooks: \"Textbook of Pathology\" and \"Basic Pathology\", and a publicly-available digital library: \"Pathology Education Informational Resource\" (PEIR).",
      "#": "5,004 images and 32,795 question-answer pairs",
      "Metric": "BLEU-1, BLEU-2, BLEU-3, Exactmatch, F1, accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{he2020pathvqa,\n    title={PathVQA: 30000+ Questions for Medical Visual Question Answering},\n    author={He, Xuehai and Zhang, Yichen and Mou, Luntian and Xing, Eric and Xie, Pengtao},\n    journal={arXiv preprint arXiv:2003.10286},\n    year={2020}\n}\n",
      "modality description": "all pathology",
      "link": "https://huggingface.co/datasets/flaviagiammarino/path-vqa",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Question Answering",
      "Modality": " \n         \nCT, MR, Endoscopy, X-Ray, Ultrasound, Histopathology, Dermoscopy, Microscopy, Fundus, PET",
      "Name": "PMC-VQA",
      "Link": "PMC-VQA",
      "Domain": " \n         \ncell, brain, tissue, artery, bone, face, rib, vascular, liver, eye, etc.",
      "Dimension": "Mixed",
      "Format": "Parquet",
      "Description": "PMC-VQA is a medical Visual Question Answering dataset containing 227,000 Q&A pairs and 149,000 images. The dataset is derived from the commercially usable PMC Open Access subset and is licensed under CC BY-SA, making it suitable for developing medical generative models.",
      "#": "227k VQA pairs of 149k images",
      "Metric": "AUC, ACC, Bleu-1",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{zhang2023pmcvqa,\n      title={PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering}, \n      author={Xiaoman Zhang and Chaoyi Wu and Ziheng Zhao and Weixiong Lin and Ya Zhang and Yanfeng Wang and Weidi Xie},\n      year={2023},\n      journal={arXiv preprint arXiv:2305.10415},\n}",
      "modality description": "none",
      "link": "https://github.com/xiaoman-zhang/PMC-VQA",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Question Answering",
      "Modality": "Histopathology",
      "Name": "Quilt-1M",
      "Link": "QUILT-1M (quilt1m.github.io)",
      "Domain": " \n         \nskin, lung, soft tissue, blood, kidney, bone, etc.",
      "Dimension": "512x512 or Mixed",
      "Format": "mp4, csv",
      "Description": "Quilt is a large-scale vision-language dataset for histopathology, containing 768,826 image-text pairs curated from 1,087 hours of educational videos on YouTube. The dataset was created using a combination of large language models, handcrafted algorithms, and automatic speech recognition. When combined with other sources like Twitter and research papers, it forms Quilt-1M, the largest vision-language histopathology dataset with 1 million paired samples. Fine-tuning a pre-trained CLIP model on Quilt-1M demonstrates improved performance on zero-shot and linear probing tasks across various pathology images, surpassing state-of-the-art models.",
      "#": "419,780 images 768,826 text pairs",
      "Metric": "Open-Closed",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{ikezogwo2023quilt,\n      title={Quilt-1M: One Million Image-Text Pairs for Histopathology},\n      author={Ikezogwo, Wisdom Oluchi and Seyfioglu, Mehmet Saygin and Ghezloo, Fatemeh and Geva, Dylan Stefan Chan and Mohammed, Fatwir Sheikh \n      and Anand, Pavan Kumar and Krishna, Ranjay and Shapiro, Linda},\n      journal={arXiv preprint arXiv:2306.11207},\n      year={2023}\n    }",
      "modality description": "all pathology",
      "link": "https://quilt1m.github.io/",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Question Answering",
      "Modality": "Pathology WSI",
      "Name": "WSI-VQA",
      "Link": "WSI-VQA",
      "Domain": "Carcinoma cell",
      "Dimension": "Mixed",
      "Format": "json, svs",
      "Description": " \nThe WSI-VQA dataset comprises 977 whole slide images (WSIs) and 8,672 corresponding question-answer pairs. It is designed to facilitate generative visual question answering in pathology, enabling tasks such as immunohistochemical grading, survival prediction, and tumor subtyping. The dataset includes both close-ended questions with multiple-choice answers and open-ended questions requiring free-form responses. It serves as a benchmark for developing models that interpret WSIs through a question-answering framework.",
      "#": "977 WSIs and 8672 QA pairs ",
      "Metric": "Bleu-1 Bleu-4 METEOR ROUGEACC Factent",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{chen2025wsi,\n  title={Wsi-vqa: Interpreting whole slide images by generative visual question answering},\n  author={Chen, Pingyi and Zhu, Chenglu and Zheng, Sunyi and Li, Honglin and Yang, Lin},\n  booktitle={European Conference on Computer Vision},\n  pages={401--417},\n  year={2025},\n  organization={Springer}\n}",
      "modality description": "all pathology",
      "link": "https://github.com/cpystan/WSI-VQA",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Image Caption",
      "Modality": "CT, MR, Endoscopy, X-Ray, Ultrasound, Histopathology, Dermoscopy, Microscopy, Fundus, PET",
      "Name": "PMC-OA",
      "Link": "PMC-OA",
      "Domain": "cell, tissue, vascular, brain, bone, liver, lymph, eye, epithelium, etc.",
      "Dimension": "Mixed",
      "Format": "jpg, json",
      "Description": "The PMC-OA dataset contains 1.65 million image-text pairs created through a three-step process: collecting medical figures from 2.4 million PubMedCentral papers, separating compound figures into subfigures, and aligning captions with subfigures. The dataset is diverse, covering various diagnostic procedures and diseases, with a gender balance of 54% males. Compared to existing datasets, PMC-OA is larger and offers improved accuracy in alignment, making it a valuable resource for biomedical research.",
      "#": "1.65M image-text pairs",
      "Metric": "AUC, ACC, R@1, Open-Closed",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{lin2023pmc,\n  title={Pmc-clip: Contrastive language-image pre-training using biomedical documents},\n  author={Lin, Weixiong and Zhao, Ziheng and Zhang, Xiaoman and Wu, Chaoyi and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},\n  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},\n  pages={525--536},\n  year={2023},\n  organization={Springer}\n}",
      "modality description": "caption",
      "link": "https://huggingface.co/datasets/axiong/pmc_oa/:~:text=The%20difference%20between%20PMC-OA%20&%20PMC-OA-Beta%20lies%20in",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Image Caption",
      "Modality": "X-Ray",
      "Name": "MIMIC-CXR-JPG",
      "Link": "MIMIC-CXR-JPG",
      "Domain": "lung",
      "Dimension": "Mixed",
      "Format": "jpg, csv",
      "Description": "MIMIC-CXR-JPG, which offers over 377,000 chest radiographs in JPG format with structured labels derived from radiology reports. The dataset is designed for research in medical imaging, natural language processing, and decision support systems. It aims to facilitate easier access to medical images by converting DICOM files into JPG format while providing consistent data splits and labels for research purposes. Access to the data requires signing a data use agreement and completing specific training.",
      "#": "377,110 JPG format images and 227,827 free-text radiology reports",
      "Metric": "Precision Recall F1",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{johnson2019mimic,\n  title={Mimic-cxr-jpg-chest radiographs with structured labels},\n  author={Johnson, Alistair and Lungren, Matt and Peng, Yifan and Lu, Zhiyong and Mark, Roger and Berkowitz, Seth and Horng, Steven},\n  journal={PhysioNet},\n  year={2019}\n}\n@article{johnson2019mimic,\n  title={MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs},\n  author={Johnson, Alistair EW and Pollard, Tom J and Greenbaum, Nathaniel R and Lungren, Matthew P and Deng, Chih-ying and Peng, Yifan and Lu, Zhiyong and Mark, Roger G and Berkowitz, Seth J and Horng, Steven},\n  journal={arXiv preprint arXiv:1901.07042},\n  year={2019}\n}",
      "modality description": "all X-Ray",
      "link": "https://physionet.org/content/mimic-cxr-jpg/2.0.0/",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Image Caption",
      "Modality": "Ultrasound, X-Ray, CT, MRI, PET, Microscopy",
      "Name": "ROCOv2",
      "Link": "ROCOv2",
      "Domain": "abdomen, breast, chest, cranium, lower extremity, pelvis, spine, and upper extremity",
      "Dimension": "Mixed",
      "Format": ".csv, .jpg",
      "Description": "\nROCOv2 (Radiology Objects in COntext Version 2) is a multimodal dataset comprising 79,789 radiological images paired with corresponding medical concepts and captions. Extracted from the PubMed Open Access subset, it encompasses seven clinical imaging modalities, including X-ray, CT, MRI, PET, ultrasound, and angiography. This updated version of the 2018 ROCO dataset adds 35,705 new images and includes manually curated medical concepts for modality, anatomy (specific to X-rays), and directionality (specific to X-rays). ROCOv2 is suitable for training image annotation models based on image-caption pairs or for multi-label image classification using Unified Medical Language System (UMLS) concepts, facilitating the development of systems that support structured medical reporting.",
      "#": "79,789 radiological images paired with corresponding medical concepts and captions",
      "Metric": "F1, ROUGE, BERTScore, BLEURT ,BLEU ,METEOR, CIDEr ,CLIPScore",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{pelka2018radiology,\n  title={Radiology objects in context (roco): a multimodal image dataset},\n  author={Pelka, Obioma and Koitka, Sven and R{\\\"u}ckert, Johannes and Nensa, Felix and Friedrich, Christoph M},\n  booktitle={Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis: 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 3},\n  pages={180--189},\n  year={2018},\n  organization={Springer}\n}   @article{ruckert2024rocov2,\n  title={Rocov2: Radiology objects in context version 2, an updated multimodal image dataset},\n  author={R{\\\"u}ckert, Johannes and Bloch, Louise and Br{\\\"u}ngel, Raphael and Idrissi-Yaghir, Ahmad and Sch{\\\"a}fer, Henning and Schmidt, Cynthia S and Koitka, Sven and Pelka, Obioma and Abacha, Asma Ben and G. Seco de Herrera, Alba and others},\n  journal={Scientific Data},\n  volume={11},\n  number={1},\n  pages={688},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n}",
      "modality description": "caption",
      "link": "https://zenodo.org/records/8333645",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Image Caption",
      "Modality": "CT",
      "Name": "PadChest",
      "Link": "PadChest",
      "Domain": "lung",
      "Dimension": "Mixed",
      "Format": "DICOM ",
      "Description": "Rx-thorax-automatic-captioning is a dataset that focuses on chest X-ray images and their corresponding multi-label annotated reports. It consists of 160,000 high-resolution images derived from 67,000 patients, all interpreted by radiologists at San Juan Hospital in Spain. The dataset includes labels for 19 differential diagnoses, 103 anatomical locations, and 179 radiological findings, mapped using the Unified Medical Language System (UMLS). It also provides a valuable resource for COVID-19 research by identifying various patterns relevant to diagnosing pneumonia. The dataset facilitates advanced research in medical imaging and natural language processing through its comprehensive annotations and diverse data.",
      "#": "160K images with reports",
      "Metric": "Accuracy, MacroF1, MicroF1, WeightedF1",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{bustos2020padchest,\n  title={Padchest: A large chest x-ray image dataset with multi-label annotated reports},\n  author={Bustos, Aurelia and Pertusa, Antonio and Salinas, Jose-Maria and De La Iglesia-Vaya, Maria},\n  journal={Medical image analysis},\n  volume={66},\n  pages={101797},\n  year={2020},\n  publisher={Elsevier}\n}",
      "modality description": "all ct",
      "link": "https://github.com/auriml/Rx-thorax-automatic-captioning",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Grounding",
      "Modality": "CT, MRI, X-Ray",
      "Name": "SLAKE training",
      "Link": "SLAKE training",
      "Domain": "brain, liver, kidney, pelvic, lung",
      "Dimension": "mixed",
      "Format": "jpg, json",
      "Description": "SLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical Visual Question Answering [ISBI 2021 oral]",
      "#": " 642 images with14,028  question-answer pairs  and  5232  medical knowledgetriplets",
      "Metric": "Open-Closed",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{liu2021slake,\n  title={Slake: A semantically-labeled knowledge-enhanced dataset for medical visual question answering},\n  author={Liu, Bo and Zhan, Li-Ming and Xu, Li and Ma, Lin and Yang, Yan and Wu, Xiao-Ming},\n  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)},\n  pages={1650--1654},\n  year={2021},\n  organization={IEEE}\n}",
      "modality description": "contain modality",
      "link": "https://huggingface.co/datasets/BoKelvin/SLAKE",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Grounding",
      "Modality": "histopathology ",
      "Name": "Quilt-Instruct",
      "Link": "Quilt-LLaVA",
      "Domain": "cell",
      "Dimension": "mixed",
      "Format": "parquet, json",
      "Description": "Quilt-Instruct is a large-scale dataset comprising 107,131 histopathology-specific instruction question/answer pairs. It was developed by extracting localized narratives from educational histopathology videos on YouTube, utilizing narrators' cursor movements for spatial grounding. This dataset enhances diagnostic reasoning and spatial awareness in models by providing contextually rich information beyond individual image patches.",
      "#": "107,131 histopathology-specific instruction question/answer pairs",
      "Metric": " Open Closed",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{seyfioglu2024quilt,\n  title={Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos},\n  author={Seyfioglu, Mehmet Saygin and Ikezogwo, Wisdom O and Ghezloo, Fatemeh and Krishna, Ranjay and Shapiro, Linda},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={13183--13192},\n  year={2024}\n}",
      "modality description": "all pathology",
      "link": "https://quilt-llava.github.io/",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Grounding",
      "Modality": "X-Ray",
      "Name": "MS-CXR",
      "Link": "link",
      "Domain": "Chest",
      "Dimension": "depends on the source of MIMIC-CXR (could be 512*512, 1k*1k or higher)",
      "Format": "json, csv, jpg, dicom",
      "Description": "The MS-CXR dataset provides 1162 image–sentence pairs of bounding boxes and corresponding phrases, collected across eight different cardiopulmonary radiological findings, with an approximately equal number of pairs for each finding. This dataset complements the existing MIMIC-CXR v.2 dataset and comprises: 1. Reviewed and edited bounding boxes and phrases (1026 pairs of bounding box/sentence); and 2. Manual bounding box labels from scratch (136 pairs of bounding box/sentence).",
      "#": "1. Reviewed and edited bounding boxes and phrases (1026 pairs of bounding box/sentence); and 2. Manual bounding box labels from scratch (136 pairs of bounding box/sentence).",
      "Metric": "mIoU, accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{boecking2022making,\n  title={Making the most of text semantics to improve biomedical vision--language processing},\n  author={Boecking, Benedikt and Usuyama, Naoto and Bannur, Shruthi and Castro, Daniel C and Schwaighofer, Anton and Hyland, Stephanie and Wetscherek, Maria and Naumann, Tristan and Nori, Aditya and Alvarez-Valle, Javier and others},\n  booktitle={European conference on computer vision},\n  pages={1--21},\n  year={2022},\n  organization={Springer}\n}",
      "modality description": "all x-ray",
      "link": "https://physionet.org/content/ms-cxr/0.1/",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Task": "Visual Grounding",
      "Modality": "X-Ray",
      "Name": "ChestX-ray8",
      "Link": "link",
      "Domain": "Chest",
      "Dimension": "1024*1024",
      "Description": "ChestX-ray8 is a medical imaging dataset which comprises 108,948 frontal-view X-ray images of 32,717 (collected from the year of 1992 to 2015) unique patients with the text-mined eight common disease labels, mined from the text radiological reports via NLP techniques.",
      "#": "ChestX-ray8 is a large- scale dataset for diagnosing 8 common chest diseases, of which 984 images with pathology are provided with hand- labeled bounding boxes.",
      "Metric": "mIoU, accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "@inproceedings{wang2017chestx,\n  title={Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases},\n  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={2097--2106},\n  year={2017}\n}",
      "modality description": "all x-ray",
      "link": "https://nihcc.app.box.com/v/ChestXray-NIHCC",
      "_source_file": "工作表1.json",
      "_source_sheet": "工作表1",
      "_source_directory": "VisionandLanguage_data_json_data"
    },
    {
      "Reference Index": 1,
      "Dataset/Challenge": "iSeg2017",
      "Citation": "http://iseg2017.web.unc.edu/wp-content/uploads/sites/14056/2019/02/Benchmark-on-Automatic-6-month-old-Infant-Brain-Segmentation-Algorithms.pdf",
      "Year": 2017,
      "Modality": "T1/T2",
      "Focus": "Accurate segmentation of 6-month infant brain MR images into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF)",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "train/test 10/13",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://iseg2017.web.unc.edu/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 2,
      "Dataset/Challenge": "iSeg2019",
      "Citation": "https://doi.org/10.1109/TMI.2021.3055428",
      "Year": 2019,
      "Modality": "T1/T2",
      "Focus": "Accurate segmentation of 6-month infant brain MR images into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF)",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "T1:1×1×1mm3/T2:1.25×1.25×1.95mm3",
      "Scale": "train/val/test 10/13/16",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://iseg2019.web.unc.edu/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 3,
      "Dataset/Challenge": "BraTS-GoAT",
      "Citation": "https://doi.org/10.1038/s42256-023-00652-2",
      "Year": 2024,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "-",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "ISBI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.synapse.org/Synapse:syn52939291/wiki/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 4,
      "Dataset/Challenge": "BraTS2023",
      "Citation": "https://doi.org/10.1038/s42256-023-00652-2",
      "Year": 2023,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation/Synthesis",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "~4,500+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.synapse.org/Synapse:syn51156910/wiki/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 5,
      "Dataset/Challenge": "BraTS2022",
      "Citation": "-",
      "Year": 2022,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": 5880,
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.synapse.org/Synapse:syn27046444/wiki/616571",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 6,
      "Dataset/Challenge": "BraTS2021",
      "Citation": "U.Baid, et al., The RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor Segmentation and Radiogenomic Classification, arXiv:2107.02314, 2021.",
      "Year": 2021,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": 2000,
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.synapse.org/Synapse:syn25829067/wiki/610863",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 7,
      "Dataset/Challenge": "BraTS2020",
      "Citation": "-",
      "Year": 2020,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation/Others",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "243+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.med.upenn.edu/cbica/brats2020/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 8,
      "Dataset/Challenge": "BraTS2019",
      "Citation": "-",
      "Year": 2019,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation/Others",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "243+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.med.upenn.edu/cbica/brats-2019/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 9,
      "Dataset/Challenge": "BraTS2018",
      "Citation": "S. Bakas, M. Reyes, A. Jakab, S. Bauer, M. Rempfler, A. Crimi, et al., \"Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge\", arXiv preprint arXiv:1811.02629 (2018)",
      "Year": 2018,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation/Others",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "243+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.med.upenn.edu/sbia/brats2018.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 10,
      "Dataset/Challenge": "BraTS2017",
      "Citation": "S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J.S. Kirby, et al., \"Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features\", Nature Scientific Data, 4:170117 (2017) DOI: 10.1038/sdata.2017.117",
      "Year": 2017,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation/Others",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "243+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.med.upenn.edu/sbia/brats2017/data.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 11,
      "Dataset/Challenge": "BraTS2016",
      "Citation": "https://doi.org/10.1109/TMI.2014.2377694",
      "Year": 2016,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "300+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.smir.ch/BRATS/Start2016",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 12,
      "Dataset/Challenge": "BraTS2015",
      "Citation": "https://doi.org/10.1109/TMI.2014.2377694",
      "Year": 2015,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "300+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.smir.ch/BRATS/Start2015",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 13,
      "Dataset/Challenge": "BraTS2014",
      "Citation": "https://doi.org/10.1109/TMI.2014.2377694",
      "Year": 2014,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "-",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.cbica.upenn.edu/sbia/Spyridon.Bakas/MICCAI_BraTS/MICCAI_BraTS_2014_proceedings.pdf",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 14,
      "Dataset/Challenge": "BraTS2013",
      "Citation": "https://doi.org/10.1109/TMI.2014.2377694",
      "Year": 2013,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": 80,
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.smir.ch/BRATS/Start2013",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 15,
      "Dataset/Challenge": "BraTS2012",
      "Citation": "https://doi.org/10.1109/TMI.2014.2377694",
      "Year": 2012,
      "Modality": "T1/T1Gd/T2/T2-FLAIR",
      "Focus": "Multi-modalities",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "Train/val/test 10/13/16",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www2.imm.dtu.dk/projects/BRATS2012/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 16,
      "Dataset/Challenge": "ISLES2022",
      "Citation": "Hernandez Petzsche, M. R., de la Rosa, E., Hanning, U., Wiest, R., Valenzuela, W., Reyes, M., ... & Kirschke, J. S. (2022). ISLES 2022: A multi-center magnetic resonance imaging stroke lesion segmentation dataset. Scientific data, 9(1), 762.",
      "Year": 2022,
      "Modality": "DWI/ADC/FLAIR/T1w",
      "Focus": "Ischemic stroke",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Stroke lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "1205+",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.isles-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 17,
      "Dataset/Challenge": "ISLES2018",
      "Citation": "Cereda, Carlo W., Søren Christensen, Bruce CV Campbell, Nishant K. Mishra, Michael Mlynash, Christopher Levi, Matus Straka et al. \"A benchmarking tool to evaluate computer tomography perfusion infarct core predictions against a DWI standard.\" Journal of Cerebral Blood Flow & Metabolism 36, no. 10 (2016): 1780-1789.",
      "Year": 2018,
      "Modality": "DWI",
      "Focus": "Ischemic stroke",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Stroke lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Train/test 63/40",
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.isles-challenge.org/ISLES2018/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 18,
      "Dataset/Challenge": "ISLES2017",
      "Citation": "-",
      "Year": 2017,
      "Modality": "DWI/ADC/T2",
      "Focus": "Ischemic stroke",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Stroke lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Train/test 43/32",
      "Multi-center": "-",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.isles-challenge.org/ISLES2017/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 19,
      "Dataset/Challenge": "ISLES2016",
      "Citation": "-",
      "Year": 2016,
      "Modality": "ADC",
      "Focus": "Ischemic stroke",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Stroke lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Train/test 35/40",
      "Multi-center": "-",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.isles-challenge.org/ISLES2016/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 20,
      "Dataset/Challenge": "ISLES2015",
      "Citation": "-",
      "Year": 2015,
      "Modality": "FLAIR/T2w TSE/T1w TFE/T1w TSE/DWI",
      "Focus": "Ischemic stroke",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Stroke lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1mm3",
      "Scale": "Train/test 28/36",
      "Multi-center": "-",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://www.isles-challenge.org/ISLES2015/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 21,
      "Dataset/Challenge": "ATLAS",
      "Citation": "A large, curated, open-source stroke neuroimaging dataset to improve lesion segmentation algorithms | medRxiv",
      "Year": 2018,
      "Modality": "T1",
      "Focus": "Anatomical segmentation",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Stroke lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "1 mm3 or higher",
      "Scale": "Train/test 655/300",
      "Multi-center": "-",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://fcon_1000.projects.nitrc.org/indi/retro/atlas.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 22,
      "Dataset/Challenge": "CTICH",
      "Citation": "https://doi.org/10.13026/4nae-zg36",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Intra-cranial hemorrhage",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Intra-cranial hemorrhage",
      "Disease": "-",
      "Category": "-",
      "Resolution": "5 mm",
      "Scale": 75,
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "PhysioNet Restricted Health Data License 1.5.0",
      "Fully Open": "Registry",
      "link": "https://physionet.org/content/ct-ich/1.3.1/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 23,
      "Dataset/Challenge": "RSNA Intracranial Hemorrhage Detection",
      "Citation": "Anouk Stein, MD, Carol Wu, Chris Carr, George Shih, Jayashree Kalpathy-Cramer, Julia Elliott, kalpathy, Luciano Prevedello, Marc Kohli, MD, Matt Lungren, Phil Culliton, Robyn Ball, Safwan Halabi MD. (2019). RSNA Intracranial Hemorrhage Detection. Kaggle. https://kaggle.com/competitions/rsna-intracranial-hemorrhage-detection",
      "Year": 2019,
      "Modality": "CT",
      "Focus": "Intra-cranial hemorrhage",
      "Tasks": "Classification",
      "Lesion/Tumor": "Intra-cranial hemorrhage",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": 874035,
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "RSNA",
      "License": "-",
      "Fully Open": "Y",
      "link": "https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection/overview",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 24,
      "Dataset/Challenge": "Head CT - hemorrhage",
      "Citation": "Felipe Campos Kitamura. (2018). Head CT - hemorrhage [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DSV/152137",
      "Year": 2018,
      "Modality": "CT",
      "Focus": "Intra-cranial hemorrhage",
      "Tasks": "Classification",
      "Lesion/Tumor": "Intra-cranial hemorrhage",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": 200,
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "-",
      "License": "CC0 1.0",
      "Fully Open": "Y",
      "link": "https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 25,
      "Dataset/Challenge": "OASIS 1",
      "Citation": "Open Access Series of Imaging Studies (OASIS): Cross-Sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults. Marcus, DS, Wang, TH, Parker, J, Csernansky, JG, Morris, JC, Buckner, RL. Journal of Cognitive Neuroscience, 19, 1498-1507. doi: 10.1162/jocn.2007.19.9.1498",
      "Year": 2007,
      "Modality": "T1",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "NC/AD 316/100",
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://sites.wustl.edu/oasisbrains/home/oasis-1/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 26,
      "Dataset/Challenge": "OASIS 2",
      "Citation": "Open Access Series of Imaging Studies (OASIS): Longitudinal MRI Data in Nondemented and Demented Older Adults. Marcus, DS, Fotenos, AF, Csernansky, JG, Morris, JC, Buckner, RL, 2010. Journal of Cognitive Neuroscience, 22, 2677-2684. doi: 10.1162/jocn.2009.21407",
      "Year": 2009,
      "Modality": "T1",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "NC/AD 72/78",
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://sites.wustl.edu/oasisbrains/home/oasis-2/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 27,
      "Dataset/Challenge": "OASIS 3",
      "Citation": "OASIS-3: Longitudinal Neuroimaging, Clinical, and Cognitive Dataset for Normal Aging and Alzheimer Disease Pamela J LaMontagne, Tammie L.S. Benzinger, John C. Morris, Sarah Keefe, Russ Hornbeck, Chengjie Xiong, Elizabeth Grant, Jason Hassenstab, Krista Moulder, Andrei Vlassenko, Marcus E. Raichle, Carlos Cruchaga, Daniel Marcus, 2019. medRxiv. doi: 10.1101/2019.12.13.19014902",
      "Year": 2019,
      "Modality": "T1/T2/FLAIR/CT/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "NC/AD 755/622",
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://sites.wustl.edu/oasisbrains/home/oasis-3/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 28,
      "Dataset/Challenge": "OASIS 4",
      "Citation": "Select Atrophied Regions in Alzheimer disease (SARA): An improved volumetric model for identifying Alzheimer disease dementia. Koenig, L et al 2020. NeuroImage Clinical, 26,102248. doi: 10.1016/j.nicl.2020.102248",
      "Year": 2020,
      "Modality": "T1/T2/FLAIR/CT/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": 663,
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://sites.wustl.edu/oasisbrains/home/oasis-4/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 29,
      "Dataset/Challenge": "ADNI 1",
      "Citation": "https://doi.org/10.1016/j.nic.2005.09.008",
      "Year": 2004,
      "Modality": "T1/T2/DWI/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Mild cognitive impairment/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "NC/MCI/AD 200/400/200",
      "Multi-center": "Y",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://adni.loni.usc.edu/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 30,
      "Dataset/Challenge": "ADNI-GO",
      "Citation": "https://doi.org/10.1016/j.nic.2005.09.008",
      "Year": 2009,
      "Modality": "T1/T2/DWI/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Mild cognitive impairment/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "Y",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://adni.loni.usc.edu/methods/documents/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 31,
      "Dataset/Challenge": "ADNI 2",
      "Citation": "https://doi.org/10.1016/j.jalz.2015.05.005",
      "Year": 2011,
      "Modality": "T1/T2/DWI/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Mild cognitive impairment/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "NC/EMCI/LMCI/AD +150/+150/+150/+200",
      "Multi-center": "Y",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://adni.loni.usc.edu/methods/documents/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 32,
      "Dataset/Challenge": "ADNI 3",
      "Citation": "https://doi.org/10.1016/j.jalz.2016.10.006",
      "Year": 2016,
      "Modality": "T1/T2/DWI/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Early mild cognitive impairment/Late mild cognitive impairment/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "NC/MCI/AD 133/151/87",
      "Multi-center": "Y",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://adni.loni.usc.edu/methods/documents/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 33,
      "Dataset/Challenge": "ADNI 4",
      "Citation": "-",
      "Year": 2022,
      "Modality": "T1/T2/DWI/PET",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Early mild cognitive impairment/Late mild cognitive impairment/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "~1500",
      "Multi-center": "Y",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://adni.loni.usc.edu/methods/documents/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 34,
      "Dataset/Challenge": "CADDementia",
      "Citation": "E.E. Bron et al., Standardized evaluation of algorithms for computer-aided diagnosis of dementia based on structural MRI: the CADDementia challenge, Neuroimage, 2015.",
      "Year": 2015,
      "Modality": "T1",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Alzheimer’s disease",
      "Category": "Normal cognition/Mild cognitive impairment/Alzheimer’s disease",
      "Resolution": "-",
      "Scale": "Train/test 30/354",
      "Multi-center": "Y",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "Registry",
      "link": "https://caddementia.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 35,
      "Dataset/Challenge": "ANT",
      "Citation": "Trevor K. M. Day and Tara M. Madyastha and Peter Boord and Mary K. Askren and Thomas J. Montine and Thomas J. Grabowski (2019). ANT: Healthy aging and Parkinson's disease. OpenNeuro. [Dataset] doi: ",
      "Year": 2019,
      "Modality": "T1",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Parkinson’s disease",
      "Category": "Normal cognition/Parkinson’s disease",
      "Resolution": "-",
      "Scale": "NC/PD 25/21",
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "CC0 1.0",
      "Fully Open": "Y",
      "link": "https://openneuro.org/datasets/ds001907/versions/2.0.3",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 36,
      "Dataset/Challenge": "SCA2",
      "Citation": "Mario Mascalchi (2018). SCA2 Diffusion Tensor Imaging. OpenNeuro. [Dataset] doi: ",
      "Year": 2018,
      "Modality": "T1/DWI",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Spinocerebellar ataxia typeII",
      "Category": "Normal cognition/SCA2",
      "Resolution": "-",
      "Scale": "NC/SCA2 16/9",
      "Multi-center": "N",
      "Rank": "-",
      "Conference": "-",
      "License": "CC-BY 4.0",
      "Fully Open": "Y",
      "link": "https://openneuro.org/datasets/ds001378/versions/00003",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 37,
      "Dataset/Challenge": "CQ500",
      "Citation": "https://arxiv.org/abs/1803.05854",
      "Year": 2018,
      "Modality": "CT",
      "Focus": "Intra-cranial hemorrhage",
      "Tasks": "Classification",
      "Lesion/Tumor": "Intra-cranial hemorrhage",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": 491,
      "Multi-center": "-",
      "Rank": "-",
      "Conference": "-",
      "License": "CC-BY-NC-SA/EULA",
      "Fully Open": "Registry",
      "link": "http://headctstudy.qure.ai/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 38,
      "Dataset/Challenge": "FeTA",
      "Citation": "https://arxiv.org/abs/2010.15526",
      "Year": 2021,
      "Modality": "MRI",
      "Focus": "Fetal Tissue",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Fetal Tissue",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": 40,
      "Multi-center": "Y",
      "Rank": "Y",
      "Conference": "MICCAI",
      "License": "-",
      "Fully Open": "Registry",
      "link": "http://neuroimaging.ch/feta",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 39,
      "Dataset/Challenge": "MSD_Brain",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "FLAIR/T1w/T1Gd/T2w",
      "Focus": "Gliomas segmentation necrotic/active tumour and oedema",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Brain tumor",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Train/test 484/266",
      "Multi-center": "-",
      "Rank": "Y",
      "Conference": "-",
      "License": "CC BY-SA 4.0",
      "Fully Open": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 40,
      "Dataset/Challenge": "MSD_Hippocampus",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "MRI",
      "Focus": "Hippocampus head and body",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Train/test 263/131",
      "Multi-center": "-",
      "Rank": "Y",
      "Conference": "-",
      "License": "CC BY-SA 4.0",
      "Fully Open": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 2,
      "Dataset/Challenge": "FIRE",
      "Citation": "https://doi.org/10.35119/maio.v1i4.42",
      "Year": 2017,
      "Modality": "Fundus photography",
      "Focus": "-",
      "Tasks": "Registration",
      "Lesion/Tumor": 268,
      "Disease": "Y",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://odir2019.grand-challenge.org/dataset/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 3,
      "Dataset/Challenge": "STARE",
      "Citation": "A. Hoover, V. Kouznetsova and M. Goldbaum, \"Locating Blood Vessels in Retinal Images by Piece-wise Threhsold Probing of a Matched Filter Response\", IEEE Transactions on Medical Imaging , vol. 19 no. 3, pp. 203-210, March 2000.",
      "Year": 2000,
      "Modality": "Fundus photography",
      "Focus": "-",
      "Tasks": "Segmentation",
      "Lesion/Tumor": 20,
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://projects.ics.forth.gr/cvrl/fire/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 4,
      "Dataset/Challenge": "CHASE_DB1",
      "Citation": "Owen, C.G, Rudnicka, A.R., Nightingale, C.M., Mullen, R., Barman, S.A., Sattar, N. Cook, D.G., and Whincup, P.H. (2011) Retinal arteriolar tortuosity and cardiovascular risk factors in a multi-ethnic population study of 10-year-old children; the Child Heart and Health Study in England (CHASE). Arteriosclerosis, Thrombosis, and Vascular Biology, 31(8), pp. 1933-1938.",
      "Year": 2011,
      "Modality": "Fundus photography",
      "Focus": "-",
      "Tasks": "Segmentation",
      "Lesion/Tumor": 28,
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://cecas.clemson.edu/~ahoover/stare/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 5,
      "Dataset/Challenge": "IDRID",
      "Citation": "Prasanna Porwal, Samiksha Pachade, Ravi Kamble, Manesh Kokare, Girish Deshmukh, Vivek Sahasrabuddhe, Fabrice Meriaudeau. (2018). \"Indian Diabetic Retinopathy Image Dataset (IDRiD).\" Web.",
      "Year": 2018,
      "Modality": "Fundus photography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Segmentation/Disease Grading/Detection",
      "Lesion/Tumor": "Train/test 54/27 Train/test 413/103 ",
      "Disease": "Y",
      "Category": "-",
      "Resolution": "CC BY 4.0",
      "Scale": "Registry",
      "link": "https://blogs.kingston.ac.uk/retinal/chasedb1/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 6,
      "Dataset/Challenge": "EyePACS",
      "Citation": "Emma Dugas, Jared, Jorge, Will Cukierski. (2015). Diabetic Retinopathy Detection. Kaggle. https://kaggle.com/competitions/diabetic-retinopathy-detection",
      "Year": 2015,
      "Modality": "Fundus photography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Y",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://idrid.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 7,
      "Dataset/Challenge": "Messidor",
      "Citation": "http://dx.doi.org/10.5566/ias.1155",
      "Year": 2004,
      "Modality": "Fundus photography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Disease Grading",
      "Lesion/Tumor": 1200,
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://www.kaggle.com/c/diabetic-retinopathy-detection/data",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 8,
      "Dataset/Challenge": "Messidor2",
      "Citation": "http://dx.doi.org/10.5566/ias.1155",
      "Year": 2009,
      "Modality": "Fundus photography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Registration",
      "Lesion/Tumor": 875,
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://www.adcis.net/en/third-party/messidor/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 9,
      "Dataset/Challenge": "Eophtha",
      "Citation": "http://dx.doi.org/10.1016/j.irbm.2013.01.010",
      "Year": 2013,
      "Modality": "Fundus photography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Classification",
      "Lesion/Tumor": "Exudates/No lesion 47/35 Microaneurysms/No lesion 148/233",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://www.adcis.net/en/third-party/messidor2/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 10,
      "Dataset/Challenge": "REFUGE",
      "Citation": "https://doi.org/10.1016/j.media.2019.101570",
      "Year": 2018,
      "Modality": "Fundus photography",
      "Focus": "Glaucoma",
      "Tasks": "Classification/Segmentation/Detection",
      "Lesion/Tumor": "-",
      "Disease": "Y",
      "Category": "MICCAI",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://www.adcis.net/en/third-party/e-ophtha/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 11,
      "Dataset/Challenge": "REFUGE2",
      "Citation": "https://doi.org/10.1016/j.media.2019.101570",
      "Year": 2020,
      "Modality": "Fundus photography",
      "Focus": "Glaucoma",
      "Tasks": "Classification/Segmentation/Detection",
      "Lesion/Tumor": "-",
      "Disease": "Y",
      "Category": "MICCAI",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://refuge.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 12,
      "Dataset/Challenge": "AGE",
      "Citation": "Fu H, Li F, Sun X, Cao X, Liao J, Orlando JI, Tao X, Li Y, Zhang S, Tan M, Yuan C. Age challenge: Angle closure glaucoma evaluation in anterior segment optical coherence tomography. Medical Image Analysis. 2020 Dec 1;66:101798.",
      "Year": 2019,
      "Modality": "Optical Coherence Tomography",
      "Focus": "Closure glaucoma",
      "Tasks": "Classification/Detection",
      "Lesion/Tumor": 4800,
      "Disease": "Y",
      "Category": "MICCAI",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://refuge.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 13,
      "Dataset/Challenge": "OCT",
      "Citation": "Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2",
      "Year": 2017,
      "Modality": "Optical Coherence Tomography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Classification",
      "Lesion/Tumor": 108312,
      "Disease": "-",
      "Category": "-",
      "Resolution": "CC BY 4.0",
      "Scale": "Y",
      "link": "https://age.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 14,
      "Dataset/Challenge": "DRIVE",
      "Citation": "-",
      "Year": 2019,
      "Modality": "Fundus photography",
      "Focus": "Vessel extraction",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Train/test 20/20",
      "Disease": "Y",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://data.mendeley.com/datasets/rscbjbr9sj/2",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 15,
      "Dataset/Challenge": "PALM",
      "Citation": "http://dx.doi.org/10.21227/55pk-8z03",
      "Year": 2019,
      "Modality": "Fundus photography",
      "Focus": "Myopia",
      "Tasks": "Classification/Segmentation/Detection",
      "Lesion/Tumor": "Train/val/test 400/400/400",
      "Disease": "Y",
      "Category": "ISBI",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://drive.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 16,
      "Dataset/Challenge": "ADAM",
      "Citation": "https://doi.org/10.21227/dt4f-rt59",
      "Year": 2018,
      "Modality": "Fundus photography",
      "Focus": "AMD",
      "Tasks": "Classification/Detection",
      "Lesion/Tumor": "-",
      "Disease": "Y",
      "Category": "ISBI",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://palm.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 17,
      "Dataset/Challenge": "ROCC",
      "Citation": "-",
      "Year": 2017,
      "Modality": "Optical Coherence Tomography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Classification",
      "Disease": "Y",
      "Category": "MVIP",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://amd.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 18,
      "Dataset/Challenge": "CATARACTS2018",
      "Citation": "Al Hajj H, Lamard M, Conze PH, Roychowdhury S, Hu X, Maršalkaitė G, Zisimopoulos O, Dedmari MA, Zhao F, Prellberg J, Sahu M, Galdran A, Araújo T, Vo DM, Panda C, Dahiya N, Kondo S, Bian Z, Vahdat A, Bialopetravičius J, Flouty E, Qiu C, Dill S, Mukhopadhyay A, Costa P, Aresta G, Ramamurthy S, Lee SW, Campilho A, Zachow S, Xia S, Conjeti S, Stoyanov D, Armaitis J, Heng PA, Macready WG, Cochener B, Quellec G. CATARACTS: Challenge on automatic tool annotation for cataRACT surgery. Med Image Anal. 2019 Feb;52:24-41.",
      "Year": 2018,
      "Modality": "Video",
      "Focus": "Surgery tools detection",
      "Tasks": "Detection",
      "Lesion/Tumor": "Train/test 20/20",
      "Disease": "Y",
      "Category": "MICCAI",
      "Resolution": "-",
      "Scale": "Registry",
      "link": "https://rocc.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 19,
      "Dataset/Challenge": "SegOCT",
      "Citation": "S. J. Chiu, M. J. Allingham, P. S. Mettu, S. W. Cousins, J. A. Izatt, S. Farsiu, \"Kernel regression based segmentation of optical coherence tomography images with diabetic macular edema\", ( BIOMEDICAL OPTICS EXPRESS), 6(4), pp. 1172-1194, April, 2015",
      "Year": 2015,
      "Modality": "Optical Coherence Tomography",
      "Focus": "Diabetic macular edema",
      "Tasks": "Segmentation",
      "Lesion/Tumor": 21,
      "Disease": "Y",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://cataracts.grand-challenge.org/Download/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 20,
      "Dataset/Challenge": "ROC",
      "Citation": "https://doi.org/10.1109/TMI.2009.2033909",
      "Year": 2009,
      "Modality": "Fundus photography",
      "Focus": "Diabetic Retinopathy",
      "Tasks": "Detection",
      "Lesion/Tumor": "Train/test 50/50",
      "Disease": "-",
      "Category": "SPIE",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://www.kaggle.com/datasets/paultimothymooney/chiu-2015",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 3,
      "Dataset/Challenge": "Head&Neck Autoseg 2010",
      "Citation": "https://doi.org/10.54294/263mqy",
      "Year": 2010,
      "Modality": "MRI",
      "Focus": "Parotid gland",
      "Tasks": "Segmentation",
      "Lesion/Tumor": 15,
      "Disease": "-",
      "Category": "MICCAI",
      "Resolution": "-",
      "Scale": "N",
      "link": "https://www.aicrowd.com/challenges/miccai-2021-hecktor",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 4,
      "Dataset/Challenge": "Ultrasound Nerve Segmentation",
      "Citation": "Anna Montoya, Hasnin, kaggle446, shirzad, Will Cukierski, yffud. (2016). Ultrasound Nerve Segmentation. Kaggle. https://kaggle.com/competitions/ultrasound-nerve-segmentation",
      "Year": 2016,
      "Modality": "Ultrasound",
      "Focus": "Nerve",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Train/test 11270/5508",
      "Disease": "Y",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://www.imagenglab.com/wiki/mediawiki/index.php?title=2015_MICCAI_Challenge",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 5,
      "Dataset/Challenge": "TNSCUI",
      "Citation": "-",
      "Year": 2020,
      "Modality": "Ultrasound",
      "Focus": "Nodular thyroid",
      "Tasks": "Segmentation/Classification",
      "Lesion/Tumor": 3644,
      "Disease": "Y",
      "Category": "MICCAI",
      "Resolution": "-",
      "Scale": "N",
      "link": "https://midasjournal.org/browse/publication/703",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 6,
      "Dataset/Challenge": "DDTI",
      "Citation": "-",
      "Year": 2021,
      "Modality": "Ultrasound",
      "Focus": "Nodular thyroid",
      "Tasks": "Segmentation",
      "Lesion/Tumor": 637,
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "Y",
      "link": "https://www.kaggle.com/c/ultrasound-nerve-segmentation",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 1,
      "Dataset/Challenge": "Anatomy3",
      "Citation": "https://doi.org/10.1109/TMI.2016.2578680",
      "Year": 2015,
      "Modality": "CT/MRI",
      "Focus": "Liver/Lung/Kidney/Spleen/Urinarybladder/Rectusabdominismuscle/1stlumbarvertebra/Pancreas/Psoasmajor/Muscle/Gallbladder/Sternum/Aorta/Trachea/Adrenalgland",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": 80,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://doi.org/10.1109/TMI.2016.2578680",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 2,
      "Dataset/Challenge": "VISCERAL",
      "Citation": "https://doi.org/10.1007/978-3-319-13972-2_15",
      "Year": 2014,
      "Modality": "CT/MRI",
      "Focus": "Liver/Lung/Kidney/Spleen/Urinarybladder/Rectusabdominismuscle/1stlumbarvertebra/Pancreas/Psoasmajor/Muscle/Gallbladder/Sternum/Aorta/Trachea/Adrenalgland",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 60/20",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://doi.org/10.1007/978-3-319-13972-2_15",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 3,
      "Dataset/Challenge": "EXACT09",
      "Citation": "http://image.diku.dk/marleen/papers/Lo_TMI12.pdf",
      "Year": 2009,
      "Modality": "CT",
      "Focus": "Lung",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 20/20",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "http://image.diku.dk/marleen/papers/Lo_TMI12.pdf",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 4,
      "Dataset/Challenge": "CHAOS",
      "Citation": "https://doi.org/10.1016/j.media.2020.101950",
      "Year": 2019,
      "Modality": "MRI",
      "Focus": "Liver/Kidney/Spleen",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 20/20",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "CC BY-NC-SA 4.0",
      "Rank": "Y",
      "link": "https://visceral.eu/closed-benchmarks/anatomy3/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 5,
      "Dataset/Challenge": "LiTS",
      "Citation": "https://arxiv.org/pdf/1901.04056",
      "Year": 2017,
      "Modality": "CT",
      "Focus": "Liver",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 130/70",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "ISBI/MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://visceral.eu/benchmark-1b-isbi/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 6,
      "Dataset/Challenge": "BTCV",
      "Citation": "-",
      "Year": 2015,
      "Modality": "CT",
      "Focus": "Liver/Kidney/Adrenalglands/Aorta/esophagus/gallbladder/pancreas/splenic veins/portalveins/spleen/stomach/venacava",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 60/40",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "http://image.diku.dk/exact/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 7,
      "Dataset/Challenge": "SLIVER07",
      "Citation": "https://doi.org/10.1109/TMI.2009.2013851",
      "Year": 2007,
      "Modality": "CT",
      "Focus": "Liver",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 20/10",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://chaos.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 8,
      "Dataset/Challenge": "KiTS19",
      "Citation": "-",
      "Year": 2019,
      "Modality": "CT",
      "Focus": "Kidney",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test  210/15",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "CC BY-NC-SA",
      "Rank": "Registry",
      "link": "https://competitions.codalab.org/competitions/17094",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 9,
      "Dataset/Challenge": "PROMISE12",
      "Citation": "https://zenodo.org/doi/10.5281/zenodo.8014040",
      "Year": 2012,
      "Modality": "MRI",
      "Focus": "Prostate",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": 50,
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.synapse.org/Synapse:syn3193805/files/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 10,
      "Dataset/Challenge": "PROMISE09",
      "Citation": "-",
      "Year": 2009,
      "Modality": "MRI",
      "Focus": "Prostate",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test  15/6",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://sliver07.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 11,
      "Dataset/Challenge": "SegTHOR",
      "Citation": "Lambert, Z., Petitjean, C., Dubray, B., & Kuan, S. (2020, November). SegTHOR: Segmentation of thoracic organs at risk in CT images. In 2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA) (pp. 1-6). IEEE.",
      "Year": 2019,
      "Modality": "CT",
      "Focus": "Heart/Aorta/trachea/esophagus",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 40/20",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://kits19.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 12,
      "Dataset/Challenge": "CRASS12",
      "Citation": "-",
      "Year": 2012,
      "Modality": "Computed radiography",
      "Focus": "Chest structure",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 299/249",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://promise12.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 13,
      "Dataset/Challenge": "CAMUS",
      "Citation": "S. Leclerc, E. Smistad, J. Pedrosa, A. Ostvik, et al. Deep Learning for Segmentation using an Open Large-Scale Dataset in 2D Echocardiography in IEEE Transactions on Medical Imaging, vol. 38, no. 9, pp. 2198-2210, Sept. 2019.",
      "Year": 2019,
      "Modality": "Ultrasound",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 450/50",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.na-mic.org/wiki/2009_prostate_segmentation_challenge_MICCAI",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 14,
      "Dataset/Challenge": "HVSMR2016",
      "Citation": "D.F. Pace, A.V. Dalca, T. Geva, A.J. Powell, M.H. Moghari, P. Golland, “Interactive whole-heart segmentation in congenital heart disease”, Medical Image Computing and Computer Assisted Interventions (MICCAI 2015), Lecture Notes in Computer Science; 9351:80-88, 2015.",
      "Year": 2016,
      "Modality": "MRI",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "-",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "-",
      "link": "https://competitions.codalab.org/competitions/21145",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 15,
      "Dataset/Challenge": "CETUS",
      "Citation": "https://doi.org/10.1109/TMI.2015.2503890",
      "Year": 2014,
      "Modality": "Ultrasound",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test1/test2 15/15/15",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "-",
      "link": "https://crass.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 16,
      "Dataset/Challenge": "LVSeg",
      "Citation": "-",
      "Year": 2011,
      "Modality": "MRI",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 100/100",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.creatis.insa-lyon.fr/Challenge/camus/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 17,
      "Dataset/Challenge": "LOLA11",
      "Citation": "https://doi.org/10.5281/zenodo.4708800",
      "Year": 2011,
      "Modality": "CT",
      "Focus": "Lung",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test -/55",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "http://segchd.csail.mit.edu/index.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 18,
      "Dataset/Challenge": "VESSEL12",
      "Citation": "https://doi.org/10.5281/zenodo.8055066",
      "Year": 2012,
      "Modality": "CT",
      "Focus": "Lung",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": 20,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.creatis.insa-lyon.fr/Challenge/CETUS/index.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 19,
      "Dataset/Challenge": "CheXpert",
      "Citation": "https://arxiv.org/abs/1901.07031",
      "Year": 2019,
      "Modality": "Computed radiography",
      "Focus": "Chest",
      "Tasks": "-",
      "Lesion/Tumor": "Classification/Segmentation",
      "Disease": "Train/test 224316/500",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.cardiacatlas.org/lv-segmentation-challenge/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 20,
      "Dataset/Challenge": "CheXpert-small",
      "Citation": "https://arxiv.org/abs/1901.07031",
      "Year": 2019,
      "Modality": "Computed radiography",
      "Focus": "Chest",
      "Tasks": "-",
      "Lesion/Tumor": "Classification",
      "Disease": "Train/val 223414/234",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://lola11.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 21,
      "Dataset/Challenge": "PadChest",
      "Citation": "https://www.sciencedirect.com/science/article/pii/S1361841520301614?via%3Dihub",
      "Year": 2019,
      "Modality": "Computed radiography",
      "Focus": "Chest",
      "Tasks": "-",
      "Lesion/Tumor": "Classification",
      "Disease": 160861,
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://vessel12.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 22,
      "Dataset/Challenge": "SIIMACR",
      "Citation": "Anna Zawacki, Carol Wu, George Shih, Julia Elliott, Mikhail Fomitchev, Mohannad Hussain, ParasLakhani, Phil Culliton, Shunxing Bao. (2019). SIIM-ACR Pneumothorax Segmentation. Kaggle. https://kaggle.com/competitions/siim-acr-pneumothorax-segmentation",
      "Year": 2019,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "Pneumothorax",
      "Lesion/Tumor": "Classification/Segmentation",
      "Disease": 3205,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "SIIM CMIMI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 23,
      "Dataset/Challenge": "PulmonaryCXR",
      "Citation": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/",
      "Year": 2018,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "Tuberculosis",
      "Lesion/Tumor": "Classification/Segmentation",
      "Disease": "500+",
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.kaggle.com/datasets/mimsadiislam/chexpert",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 24,
      "Dataset/Challenge": "CXRPneumonia",
      "Citation": "http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5",
      "Year": 2018,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "Pneumonia",
      "Lesion/Tumor": "Classification",
      "Disease": "Train/test 5232/624",
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "CC BY 4.0",
      "Rank": "Y",
      "link": "https://bimcv.cipf.es/bimcv-projects/padchest/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 25,
      "Dataset/Challenge": "AIDAE1",
      "Citation": "-",
      "Year": 2016,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Mucosa damage in celiac disease",
      "Lesion/Tumor": "Classification",
      "Disease": 88,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 26,
      "Dataset/Challenge": "AIDAE2",
      "Citation": "-",
      "Year": 2016,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Mucosa in Barrett’s esophagus",
      "Lesion/Tumor": "Classification",
      "Disease": 50,
      "Category": "N",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.kaggle.com/datasets/kmader/pulmonary-chest-xray-abnormalities",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 27,
      "Dataset/Challenge": "AIDAE3",
      "Citation": "-",
      "Year": 2016,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Mucosa in gastric chromoendoscopy",
      "Lesion/Tumor": "Classification",
      "Disease": 262,
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 28,
      "Dataset/Challenge": "MIMIC-CXR-JPG",
      "Citation": "https://doi.org/10.13026/8360-t248",
      "Year": 2019,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "Chest x-ray",
      "Lesion/Tumor": "Classification/Segmentation",
      "Disease": 377110,
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "PhysioNet Credentialed Health Data License 1.5.0",
      "Rank": "Registry",
      "link": "https://aidasub-chromogastro.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 29,
      "Dataset/Challenge": "LNDb",
      "Citation": "https://doi.org/10.5281/zenodo.7153205",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Pulmonary nodule",
      "Lesion/Tumor": "Classification/Detection",
      "Disease": 294,
      "Category": "N",
      "Resolution": "Y",
      "Scale": "RSNA",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://aidasub-cleceliachy.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 30,
      "Dataset/Challenge": "StructSeg",
      "Citation": "-",
      "Year": 2019,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Lung cancer & organs at risk",
      "Lesion/Tumor": "Classification/Segmentation",
      "Disease": "Train/test 100/20",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://aidasub-clebarrett.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 31,
      "Dataset/Challenge": "LUNA16",
      "Citation": "https://doi.org/10.1016/j.media.2017.06.015",
      "Year": 2016,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Pulmonary nodule",
      "Lesion/Tumor": "Classification/Detection",
      "Disease": 888,
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://physionet.org/content/mimic-cxr-jpg/2.1.0/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 32,
      "Dataset/Challenge": "DigitalMammographyDREAM",
      "Citation": "-",
      "Year": 2016,
      "Modality": "Computed radiography/Mammography",
      "Focus": "-",
      "Tasks": "Breast cancer",
      "Lesion/Tumor": "Classification/Detection",
      "Disease": "640000+",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://lndb.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 33,
      "Dataset/Challenge": "ImageCLEF",
      "Citation": "Bogdan Ionescu, Henning Müller, Mauricio Villegas, Alba García Seco de Herrera, Carsten Eickhoff, Vincent Andrearczyk, Yashin Dicente Cid, Vitali Liauchuk, Vassili Kovalev, Sadid A. Hasan, Yuan Ling, Oladimeji Farri, Joey Liu¡, Matthew Lungren, Duc-Tien Dang-Nguyen, Luca Piras, Michael Riegler, Liting Zhou, Mathias Lux, Cathal Gurrin, Overview of ImageCLEF 2018: Challenges, Datasets and Evaluation. In: Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Ninth International Conference of the CLEF Association (CLEF 2018), Avignon, France, LNCS Lecture Notes in Computer Science, Springer (September 10-14 2018)",
      "Year": 2018,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Tuberculosis",
      "Lesion/Tumor": "Detection",
      "Disease": "Train/test 259/236 677/317 170/109",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://structseg2019.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 34,
      "Dataset/Challenge": "Data Science Bowl 2017",
      "Citation": "-",
      "Year": 2017,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Lung cancer",
      "Lesion/Tumor": "Detection",
      "Disease": "1000+",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "N",
      "link": "https://luna16.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 35,
      "Dataset/Challenge": "LIDC IDRI",
      "Citation": "https://www.cancerimagingarchive.net/collection/lidc-idri/#citations",
      "Year": 2011,
      "Modality": "CT/Computed radiography",
      "Focus": "-",
      "Tasks": "Non-small-cell lung cancer",
      "Lesion/Tumor": "Detection",
      "Disease": 26,
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.synapse.org/Synapse:syn4224222/wiki/401743",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 36,
      "Dataset/Challenge": "ANODE09",
      "Citation": "B. van Ginneken, S.G. Armato, B. de Hoop, S. van de Vorst, T. Duindam, M. Niemeijer, K. Murphy, A.M.R. Schilham, A. Retico, M.E. Fantacci, N. Camarlinghi, F. Bagagli, I. Gori, T. Hara, H. Fujita, G. Gargano, R. Belloti, F.D. Carlo, R. Megna, S. Tangaro, L. Bolanos, P. Cerello, S.C. Cheran, E.L. Torres and M. Prokop. \"Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed tomography scans: the ANODE09 study\", Medical Image Analysis 2010;14:707-722.",
      "Year": 2009,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Pulmonary nodule",
      "Lesion/Tumor": "Detection",
      "Disease": "Train/example/test 0/5/50",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "SPIE",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.imageclef.org/2018/tuberculosis",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 37,
      "Dataset/Challenge": "EndoCV2021",
      "Citation": "https://doi.org/10.1038/s41598-020-59413-5",
      "Year": 2021,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Colon(polyp,cancer), oesophagus(Barrett’s, dysplasia, andcancer), and stomach",
      "Lesion/Tumor": "Segmentation/Detection",
      "Disease": "-",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.kaggle.com/c/data-science-bowl-2017",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 38,
      "Dataset/Challenge": "EAD2020",
      "Citation": "An objective comparison of detection and segmentation algorithms for artefacts in clinical endoscopy.",
      "Year": 2020,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Endoscopy Artefact Detection",
      "Lesion/Tumor": "Segmentation/Detection",
      "Disease": "-",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "N",
      "link": "https://www.cancerimagingarchive.net/collection/lidc-idri/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 39,
      "Dataset/Challenge": "EDD2020",
      "Citation": "http://dx.doi.org/10.21227/f8xg-wb80",
      "Year": 2020,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Colon(polyp,cancer), oesophagus(Barrett’s, dysplasia, andcancer), and stomach",
      "Lesion/Tumor": "Segmentation/Detection",
      "Disease": "-",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-NC-SA 4.0",
      "Rank": "Registry",
      "link": "https://anode09.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 40,
      "Dataset/Challenge": "EAD2019",
      "Citation": "Endoscopy artifact detection (EAD 2019) challenge dataset",
      "Year": 2019,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Endoscopy Artefact Detection",
      "Lesion/Tumor": "Segmentation/Detection",
      "Disease": "Train/test 2000/700",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://endocv2021.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 41,
      "Dataset/Challenge": "SARAS-ESAD",
      "Citation": "https://arxiv.org/abs/2104.03178",
      "Year": 2020,
      "Modality": "Endoscopy",
      "Focus": "-",
      "Tasks": "Surgeon action detection",
      "Lesion/Tumor": "Classification/Detection",
      "Disease": "Train/test 22601/4574",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-NC-SA",
      "Rank": "Y",
      "link": "https://ead2020.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 42,
      "Dataset/Challenge": "RSNA Pneumonia Detection",
      "Citation": "-",
      "Year": 2018,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "Pneumonia",
      "Lesion/Tumor": "Detection",
      "Disease": "-",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "RSNA",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://edd2020.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 43,
      "Dataset/Challenge": "NIH Chest X-rays",
      "Citation": "https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community",
      "Year": 2017,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "Lung disease",
      "Lesion/Tumor": "Classification/Detection",
      "Disease": 112120,
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "CC0 1.0",
      "Rank": "Y",
      "link": "https://ead2019.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 44,
      "Dataset/Challenge": "BUSI",
      "Citation": "https://www.sciencedirect.com/science/article/pii/S2352340919312181?via%3Dihub",
      "Year": 2020,
      "Modality": "Mammography",
      "Focus": "-",
      "Tasks": "Breast cancer",
      "Lesion/Tumor": "Classification/Segmentation/Detection",
      "Disease": 780,
      "Category": "N",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://saras-esad.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 45,
      "Dataset/Challenge": "Low Dose CT",
      "Citation": "-",
      "Year": 2016,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Low-dose CT & liver lesion",
      "Lesion/Tumor": "Detection",
      "Disease": "Train/test 10/20",
      "Category": "N",
      "Resolution": "Y",
      "Scale": "AAPM",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.kaggle.com/c/rsna-pneumonia-detection-challenge",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 46,
      "Dataset/Challenge": "Covid19 Ultrasound",
      "Citation": "https://www.mdpi.com/2076-3417/11/2/672",
      "Year": 2020,
      "Modality": "Ultrasound",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification",
      "Disease": "200+",
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://github.com/jannisborn/covid19_ultrasound/tree/master/data",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 47,
      "Dataset/Challenge": "CovidCT",
      "Citation": "COVID-CT-Dataset: a CT scan dataset about COVID-19",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification",
      "Disease": 746,
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.sciencedirect.com/science/article/pii/S2352340919312181?via%3Dihub",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 48,
      "Dataset/Challenge": "CovidCXR",
      "Citation": "COVID-19 Image Data Collection: Prospective Predictions Are the Future",
      "Year": 2020,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification",
      "Disease": "-",
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "Apache 2.0/CC BY-NC-SA 4.0/CC BY 4.0/CC BY-NC-SA 4.0",
      "Rank": "Y",
      "link": "https://www.aapm.org/GrandChallenge/LowDoseCT/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 49,
      "Dataset/Challenge": "COVID19Radiography",
      "Citation": "https://ieeexplore.ieee.org/document/9144185",
      "Year": 2020,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification/Segmentation/Detection",
      "Disease": 33920,
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://github.com/jannisborn/covid19_ultrasound",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 50,
      "Dataset/Challenge": "COVID19Xray",
      "Citation": "-",
      "Year": 2020,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification",
      "Disease": 372,
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "CC0 1.0",
      "Rank": "Y",
      "link": "https://covid-ct.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 51,
      "Dataset/Challenge": "COVIDQUEx",
      "Citation": "https://doi.org/10.1016/j.compbiomed.2021.105002",
      "Year": 2021,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification/Segmentation/Detection",
      "Disease": 33920,
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "https://github.com/ieee8023/covid-chestxray-dataset",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 52,
      "Dataset/Challenge": "COVID-19-20",
      "Citation": "https://www.sciencedirect.com/science/article/pii/S1361841522002353",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/val/test 199/50/46",
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY 4.0",
      "Rank": "Y",
      "link": "https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 53,
      "Dataset/Challenge": "AbdomenCT-1K",
      "Citation": "https://ieeexplore.ieee.org/document/9497733",
      "Year": 2022,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Abdominal organ segmentation",
      "Lesion/Tumor": "Segmentation",
      "Disease": "1000+",
      "Category": "-",
      "Resolution": "-",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.kaggle.com/datasets/bachrr/covid-chest-xray",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 54,
      "Dataset/Challenge": "AMOS22",
      "Citation": "AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation",
      "Year": 2022,
      "Modality": "CT/MRI",
      "Focus": "-",
      "Tasks": "Abdominal organ segmentation",
      "Lesion/Tumor": "Segmentation",
      "Disease": 600,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.kaggle.com/datasets/anasmohammedtahir/covidqu",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 55,
      "Dataset/Challenge": "COVIDx",
      "Citation": "COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images",
      "Year": 2020,
      "Modality": "Computed radiography",
      "Focus": "-",
      "Tasks": "COVID-19",
      "Lesion/Tumor": "Classification",
      "Disease": 84818,
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "Apache 2.0/CC BY-NC-SA 4.0/CC BY 4.0/GPLv3/CC BY 3.0/CC BY-NC 4.0",
      "Rank": "Y",
      "link": "https://covid-segmentation.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 56,
      "Dataset/Challenge": "LungNM",
      "Citation": "-",
      "Year": 2017,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "Pulmonary nodule",
      "Lesion/Tumor": "Classification",
      "Disease": 6690,
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://github.com/JunMa11/AbdomenCT-1K",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 57,
      "Dataset/Challenge": "RadImageNet",
      "Citation": "https://doi.org/10.1148/ryai.210315",
      "Year": 2022,
      "Modality": "CT/MRI/Ultrasound/PET",
      "Focus": "-",
      "Tasks": "Medical database",
      "Lesion/Tumor": "Classification",
      "Disease": "5000000+",
      "Category": "Y",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "Conference": "rin2d.tar.gz",
      "link": "https://amos22.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 58,
      "Dataset/Challenge": "3D-IRCADb",
      "Citation": "3D image reconstruction for comparison of algorithm database: A patient specific anatomical and medical image database.",
      "Year": 2010,
      "Modality": "CT",
      "Focus": "Liver",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": 22,
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "CC BY-NC-ND 4.0",
      "Rank": "Y",
      "link": "https://www.kaggle.com/datasets/andyczhao/covidx-cxr2",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 59,
      "Dataset/Challenge": "ACDC",
      "Citation": "Deep Learning Techniques for Automatic MRI Cardiac Multi-structures Segmentation and Diagnosis: Is the Problem Solved ?",
      "Year": 2018,
      "Modality": "MRI",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Classification",
      "Disease": "Train/test 100/50",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://www.kaggle.com/datasets/kmader/lungnodemalignancy",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 60,
      "Dataset/Challenge": "HMC-QU",
      "Citation": "Early Myocardial Infarction Detection over Multi-view Echocardiography,” Biomedical Signal Processing and Control",
      "Year": 2019,
      "Modality": "Echocardiography",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation/Detection",
      "Disease": 322,
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "CC BY-NC-SA 3.0 IGO",
      "Rank": "Registry",
      "link": "https://www.radimagenet.com/copy-of-home",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 61,
      "Dataset/Challenge": "BUS",
      "Citation": "M. Xian, Y. Zhang, and H. D. Cheng, “Fully automatic segmentation of breast ultrasound images based on breast characteristics in space and frequency domains,” Pattern Recognit., vol. 48, no. 2, pp. 485-497, 2015.",
      "Year": 2015,
      "Modality": "Ultrasound",
      "Focus": "Breast",
      "Tasks": "Breast tumor",
      "Lesion/Tumor": "Segmentation",
      "Disease": 562,
      "Category": "Y",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.ircad.fr/research/data-sets/liver-segmentation-3d-ircadb-01/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 62,
      "Dataset/Challenge": "CRT-EPiggy19",
      "Citation": "https://link.springer.com/article/10.1007%2Fs12265-013-9464-1",
      "Year": 2019,
      "Modality": "-",
      "Focus": "-",
      "Tasks": "Optical mapping data of a perfused ex-vivo porcine heart",
      "Lesion/Tumor": "Registration",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "MICCAI",
      "Multi-center": "CC",
      "Rank": "Y",
      "link": "https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 63,
      "Dataset/Challenge": "LVQuan18",
      "Citation": "https://link.springer.com/book/10.1007/978-3-030-12029-0",
      "Year": 2018,
      "Modality": "MRI",
      "Focus": "-",
      "Tasks": "Full quantification of cardiac LV",
      "Lesion/Tumor": "Regression",
      "Disease": "Train/test 145/30",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "-",
      "link": "https://www.kaggle.com/datasets/aysendegerli/hmcqu-dataset",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 64,
      "Dataset/Challenge": "LVQuan19",
      "Citation": "-",
      "Year": 2019,
      "Modality": "MRI",
      "Focus": "-",
      "Tasks": "Full quantification of cardiac LV",
      "Lesion/Tumor": "Regression",
      "Disease": "Train/test 56/30",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "http://cvprip.cs.usu.edu/busbench/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 65,
      "Dataset/Challenge": "Second Annual Data Science Bowl",
      "Citation": "A. Newton, AJ_Buckeye, Dr. Andrew Arai NIH, JonathanMulholland, Josette_BoozAllen, kungvu, Meghan O'Connell, Mike Kim, RomanSalasznyk, Shannon, Steve Mills, Will Cukierski. (2015). Second Annual Data Science Bowl. Kaggle. https://kaggle.com/competitions/second-annual-data-science-bowl",
      "Year": 2015,
      "Modality": "MRI",
      "Focus": "-",
      "Tasks": "Cardiac ejection fraction",
      "Lesion/Tumor": "Regression",
      "Disease": "100+",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Y",
      "link": "https://crt-epiggy19.surge.sh/datasets.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 66,
      "Dataset/Challenge": "CLUST2014",
      "Citation": "De Luca, V., Benz, T., Kondo, S., König, L., Lübke, D., Rothlübbers, S., Somphone, O., Allaire, S., Lediju Bell, M.A., Chung, D.Y.F., Cifor, A., Grozea, C., Günther, M., Jenne, J., Kipshagen, T., Kowarschik, M., Navab, N., Rühaak, J., Schwaab, J., Tanner, C.: The 2014 liver ultrasound tracking benchmark. Physics in Medicine and Biology 60(14), 5571 (2015)",
      "Year": 2014,
      "Modality": "Ultrasound",
      "Focus": "-",
      "Tasks": "Liver tracking",
      "Lesion/Tumor": "Tracking",
      "Disease": 54,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://lvquan18.github.io/intro",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 67,
      "Dataset/Challenge": "CLUST2015",
      "Citation": "https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.13152",
      "Year": 2015,
      "Modality": "Ultrasound",
      "Focus": "-",
      "Tasks": "Liver tracking",
      "Lesion/Tumor": "Tracking",
      "Disease": 86,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "MICCAI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://lvquan19.github.io/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 68,
      "Dataset/Challenge": "ECHONET",
      "Citation": "https://echonet.github.io/dynamic/NeuroIPS_2019_ML4H%20Workshop_Paper.pdf",
      "Year": 2020,
      "Modality": "Echocardiography",
      "Focus": "Heart",
      "Tasks": "Cardiac motion and chamber sizes",
      "Lesion/Tumor": "Tracking",
      "Disease": 10030,
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://www.kaggle.com/c/second-annual-data-science-bowl/overview",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 69,
      "Dataset/Challenge": "LUMIC",
      "Citation": "Grob, Dagmar, et al. \"Accuracy of registration algorithms in subtraction CT of the lungs: A digital phantom study.\" Medical physics 46.5 (2019): 2264-2274.",
      "Year": 2019,
      "Modality": "CT",
      "Focus": "-",
      "Tasks": "CT registration with phantom images",
      "Lesion/Tumor": "Registration",
      "Disease": "-",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://clust.ethz.ch/clust2014.html",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 70,
      "Dataset/Challenge": "A-AFMA",
      "Citation": "-",
      "Year": 2020,
      "Modality": "Ultrasound",
      "Focus": "-",
      "Tasks": "Amniotic fluid detection",
      "Lesion/Tumor": "Detection",
      "Disease": "-",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "ISBI",
      "Multi-center": "-",
      "Rank": "Registry",
      "link": "https://clust.ethz.ch/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 71,
      "Dataset/Challenge": "MSD_Liver",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Liver",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 131/70",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "https://echonet.github.io/dynamic/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 72,
      "Dataset/Challenge": "MSD_Lung",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Lung",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 64/32",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "https://lumic.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 73,
      "Dataset/Challenge": "MSD_Prostate",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "T2/ADC",
      "Focus": "Prostate",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 32/16",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "https://a-afma-detection.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 74,
      "Dataset/Challenge": "MSD_Cardiac",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "MRI",
      "Focus": "Heart",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 20/10",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 75,
      "Dataset/Challenge": "MSD_Pancreas",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Pancreas",
      "Tasks": "Pancreas tumour",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 282/139",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 76,
      "Dataset/Challenge": "MSD_Colon",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Colon",
      "Tasks": "Colon cancer",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 126/64",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 77,
      "Dataset/Challenge": "MSD_Liver",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Liver",
      "Tasks": "Hepatic Vessels",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 303/140",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 78,
      "Dataset/Challenge": "MSD_Spleen",
      "Citation": "https://www.nature.com/articles/s41467-022-30695-9",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Spleen",
      "Tasks": "-",
      "Lesion/Tumor": "Segmentation",
      "Disease": "Train/test 41/20",
      "Category": "-",
      "Resolution": "Y",
      "Scale": "-",
      "Multi-center": "CC BY-SA 4.0",
      "Rank": "Y",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 2,
      "Dataset/Challenge": "SurgVisDom",
      "Citation": "https://arxiv.org/abs/2102.13644",
      "Year": 2020,
      "Modality": "Endoscopy",
      "Focus": "Surgical video",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "Dissection/Knot-Tying/Needle-driving",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": 476,
      "Conference": "-",
      "License": "-",
      "Fully Open": "MICCAI",
      "link": "http://medicaldecathlon.com/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 7,
      "Dataset/Challenge": "Endovis17_Robotic",
      "Citation": "https://arxiv.org/abs/1902.06426",
      "Year": 2017,
      "Modality": "Endoscopy",
      "Focus": "Robotic surgical videos",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/test 8/8",
      "Conference": "-",
      "License": "-",
      "Fully Open": "MICCAI",
      "link": "https://surgvisdom.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 8,
      "Dataset/Challenge": "MISAW",
      "Citation": "https://www.sciencedirect.com/science/article/pii/S0169260721005265",
      "Year": 2020,
      "Modality": "Surgical microscope",
      "Focus": "Micro-Surgical Anastomose Workflow recognition",
      "Tasks": "Workflow recognition",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "920*540",
      "Rank": "-",
      "Conference": "-",
      "License": "-",
      "Fully Open": "MICCAI",
      "link": "https://endovissub-instrument.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 9,
      "Dataset/Challenge": "FetReg2021",
      "Citation": "https://arxiv.org/abs/2106.05923",
      "Year": 2021,
      "Modality": "Fetoscopy",
      "Focus": "Fetoscopy laser photocoagulation in the treatment of Twin-to-Twin Transfusion Syndrome",
      "Tasks": "Segmentation/Registration",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "Placenta",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": 2060,
      "Conference": "Y",
      "License": "-",
      "Fully Open": "MICCAI",
      "link": "https://polyp.grand-challenge.org/CVCClinicDB/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 10,
      "Dataset/Challenge": "SAR-RARP50",
      "Citation": "https://arxiv.org/abs/2401.00496",
      "Year": 2022,
      "Modality": "Surgical microscope",
      "Focus": "Robotic Assisted Radical Prostatectomy",
      "Tasks": "Segmentation/Recognition",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "Prostate",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": 50,
      "Conference": "-",
      "License": "-",
      "Fully Open": "MICCAI",
      "link": "https://endovissub-barrett.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 11,
      "Dataset/Challenge": "SurgT",
      "Citation": "https://arxiv.org/abs/2302.03022",
      "Year": 2022,
      "Modality": "Surgical microscope",
      "Focus": "Tissue trackers in surgery",
      "Tasks": "Tracking",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/val 125/12",
      "Conference": "-",
      "License": "-",
      "Fully Open": "MICCAI",
      "link": "https://endovissub-abnormal.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 12,
      "Dataset/Challenge": "SIIM-ISIC",
      "Citation": "https://doi.org/10.34970/2020-ds01",
      "Year": 2020,
      "Modality": "Dermoscopy",
      "Focus": "Skin lesion",
      "Tasks": "Classification",
      "Lesion/Tumor": "Skin lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "Benign/Malignant",
      "Scale": "-",
      "Multi-center": "1024*1024",
      "Rank": "Train/test 33126/10982",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "ISIC",
      "link": "https://endovissub2017-giana.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 13,
      "Dataset/Challenge": "ISIC2019",
      "Citation": "Tschandl P., Rosendahl C. & Kittler H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 doi.10.1038/sdata.2018.161 (2018)",
      "Year": 2019,
      "Modality": "Dermoscopy",
      "Focus": "Skin lesion",
      "Tasks": "Classification",
      "Lesion/Tumor": "Skin lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/test 25331/8238",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "ISIC",
      "link": "https://www.synapse.org/Synapse:syn21776936/wiki/601700",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 14,
      "Dataset/Challenge": "ISIC2018",
      "Citation": "Noel Codella, Veronica Rotemberg, Philipp Tschandl, M. Emre Celebi, Stephen Dusza, David Gutman, Brian Helba, Aadi Kalloo, Konstantinos Liopyris, Michael Marchetti, Harald Kittler, Allan Halpern: \"Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)\", 2018; https://arxiv.org/abs/1902.03368",
      "Year": 2018,
      "Modality": "Dermoscopy",
      "Focus": "Skin lesion",
      "Tasks": "Classification",
      "Lesion/Tumor": "Skin lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/test 10015/1512",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "ISIC",
      "link": "https://www.synapse.org/Synapse:syn25313156/wiki/609152",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 15,
      "Dataset/Challenge": "ISIC_S2018",
      "Citation": "Noel Codella, Veronica Rotemberg, Philipp Tschandl, M. Emre Celebi, Stephen Dusza, David Gutman, Brian Helba, Aadi Kalloo, Konstantinos Liopyris, Michael Marchetti, Harald Kittler, Allan Halpern: \"Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)\", 2018; https://arxiv.org/abs/1902.03368",
      "Year": 2018,
      "Modality": "Dermoscopy",
      "Focus": "Skin lesion",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "Skin lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/test 2594/1000",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "ISIC",
      "link": "https://www.synapse.org/Synapse:syn27618412/wiki/616881",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 16,
      "Dataset/Challenge": "ISIC2017",
      "Citation": "Codella N, Gutman D, Celebi ME, Helba B, Marchetti MA, Dusza S, Kalloo A, Liopyris K, Mishra N, Kittler H, Halpern A. \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\". arXiv: 1710.05006 [cs.CV]",
      "Year": 2017,
      "Modality": "Dermoscopy",
      "Focus": "Skin lesion",
      "Tasks": "Classification/Segmentation",
      "Lesion/Tumor": "Skin lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "2000+",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "ISIC/ISBI",
      "link": "https://surgt.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 17,
      "Dataset/Challenge": "ISIC2016",
      "Citation": "Gutman, David; Codella, Noel C. F.; Celebi, Emre; Helba, Brian; Marchetti, Michael; Mishra, Nabin; Halpern, Allan. \"Skin Lesion Analysis toward Melanoma Detection: A Challenge at the International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the International Skin Imaging Collaboration (ISIC)\". eprint arXiv:1605.01397. 2016.",
      "Year": 2016,
      "Modality": "Dermoscopy",
      "Focus": "Skin lesion",
      "Tasks": "Classification/Segmentation",
      "Lesion/Tumor": "Skin lesion",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/test 900/379",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "ISIC/ISBI",
      "link": "https://www.kaggle.com/c/siim-isic-melanoma-classification/data",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 18,
      "Dataset/Challenge": "MURA",
      "Citation": "https://arxiv.org/abs/1712.06957",
      "Year": 2018,
      "Modality": "Computed radiography",
      "Focus": "Musculoskeletal radiographs",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "Normal/Abnormal",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": 40561,
      "Conference": "N",
      "License": "Y",
      "Fully Open": "-",
      "link": "https://challenge.isic-archive.com/data/2019",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 19,
      "Dataset/Challenge": "RSNABoneAge",
      "Citation": "-",
      "Year": 2017,
      "Modality": "Computed radiography",
      "Focus": "Bone Age",
      "Tasks": "Regression",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/test 12600/200",
      "Conference": "Y",
      "License": "-",
      "Fully Open": "RSNA",
      "link": "https://challenge.isic-archive.com/data/2018",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 20,
      "Dataset/Challenge": "MRNet",
      "Citation": "https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699",
      "Year": 2019,
      "Modality": "MRI",
      "Focus": "-",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "Knee",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/val/test 1130/120/120",
      "Conference": "-",
      "License": "-",
      "Fully Open": "-",
      "link": "https://challenge.isic-archive.com/data/2018",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 21,
      "Dataset/Challenge": "VerSe20",
      "Citation": "https://doi.org/10.1148/ryai.2020190138",
      "Year": 2020,
      "Modality": "CT",
      "Focus": "Vertebrae",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "Vertebrae",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": 300,
      "Conference": "-",
      "License": "Y",
      "Fully Open": "MICCAI",
      "link": "https://challenge.isic-archive.com/data/2017",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 22,
      "Dataset/Challenge": "VerSe19",
      "Citation": "https://doi.org/10.1148/ryai.2020190138",
      "Year": 2019,
      "Modality": "CT",
      "Focus": "Vertebrae",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "Vertebrae",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/val/test 80/40/40",
      "Conference": "-",
      "License": "Y",
      "Fully Open": "MICCAI",
      "link": "https://challenge.isic-archive.com/data/2016",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 23,
      "Dataset/Challenge": "MESAD_Real",
      "Citation": "-",
      "Year": 2021,
      "Modality": "Endoscopy",
      "Focus": "Prostatectomy",
      "Tasks": "Detection",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/val 23366/2024",
      "Conference": "-",
      "License": "Y",
      "Fully Open": "-",
      "link": "https://stanfordmlgroup.github.io/competitions/mura/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 24,
      "Dataset/Challenge": "MESAD_Phantom",
      "Citation": "-",
      "Year": 2021,
      "Modality": "Endoscopy",
      "Focus": "Prostatectomy",
      "Tasks": "Detection",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "Train/val 22609/2285",
      "Conference": "-",
      "License": "Y",
      "Fully Open": "-",
      "link": "https://www.kaggle.com/datasets/kmader/rsna-bone-age?select=boneage-test-dataset.csv",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 1,
      "Dataset/Challenge": "HEROHE",
      "Citation": "https://doi.org/10.3390/jimaging8080213",
      "Year": 2020,
      "Modality": "-",
      "Focus": "HER2 Status in Breast Cancer",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Breast Cancer",
      "Category": "Breast",
      "Resolution": "-",
      "Scale": "H&E",
      "Multi-center": "-",
      "Rank": "Train/test 360/150",
      "Conference": "N",
      "License": "Y",
      "Fully Open": "MICCAI",
      "link": "https://osf.io/nqjyw/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 2,
      "Dataset/Challenge": "Gleason2019",
      "Citation": "Nir G, Hor S, Karimi D, Fazli L, Skinnider BF, Tavassoli P, Turbin D, Villamil CF, Wang G, Wilson RS, Iczkowski KA. Automatic grading of prostate cancer in digitized histopathology images: Learning from multiple experts. Medical image analysis. 2018 Dec 1;50:167-80.",
      "Year": 2019,
      "Modality": "-",
      "Focus": "Prostate cancer Gleason grading",
      "Tasks": "Classification",
      "Lesion/Tumor": "-",
      "Disease": "Prostate cancer",
      "Category": "Prostate",
      "Resolution": "-",
      "Scale": "H&E",
      "Multi-center": "-",
      "Rank": "Train/test 244/87",
      "Conference": "-",
      "License": "Y",
      "Fully Open": "MICCAI",
      "link": "https://saras-mesad.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 3,
      "Dataset/Challenge": "PAIP2019",
      "Citation": "-",
      "Year": 2019,
      "Modality": "-",
      "Focus": "Liver cancer",
      "Tasks": "Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "Liver cancer",
      "Category": "Liver",
      "Resolution": "-",
      "Scale": "H&E",
      "Multi-center": "-",
      "Rank": "Train/val/test 50/10/40",
      "Conference": "-",
      "License": "Y",
      "Fully Open": "MICCAI",
      "link": "https://saras-mesad.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 4,
      "Dataset/Challenge": "CAMELYON17",
      "Citation": "https://doi.org/10.1093/gigascience/giy065",
      "Year": 2017,
      "Modality": "-",
      "Focus": "Breast cancer metastases",
      "Tasks": "Classification/Detection",
      "Lesion/Tumor": "-",
      "Disease": "Breast cancer",
      "Category": "Breast",
      "Resolution": "-",
      "Scale": "H&E",
      "Multi-center": "-",
      "Rank": "Train/test 50/500",
      "Conference": "Y",
      "License": "Y",
      "Fully Open": "ISBI",
      "link": "https://doi.org/10.1093/gigascience/giy065",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 7,
      "Dataset/Challenge": "OpenPath",
      "link": "https://ecdp2020.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 8,
      "Dataset/Challenge": "DigestPath ",
      "link": "https://gleason2019.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 10,
      "Dataset/Challenge": "PubMed and Books pathology collection",
      "link": "https://camelyon17.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 11,
      "Dataset/Challenge": "KIMIA Path24C",
      "link": "https://zenodo.org/record/1214456",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 5,
      "Dataset/Challenge": "ANHIR",
      "Citation": "https://doi.org/10.1109/TMI.2020.2986331",
      "Year": 2019,
      "Modality": "-",
      "Focus": "Pathology image registration",
      "Tasks": "Non-linear image registration",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "-",
      "Multi-center": "-",
      "Rank": "50+",
      "Conference": "Y",
      "License": "Y",
      "Fully Open": "ISBI",
      "link": "https://doi.org/10.1109/TMI.2020.2986331",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Reference Index": 6,
      "Dataset/Challenge": "Particle Tracking Challenge",
      "Citation": "-",
      "Year": 2012,
      "Modality": "-",
      "Focus": "Particle Tracking",
      "Tasks": "Tracking",
      "Lesion/Tumor": "-",
      "Disease": "-",
      "Category": "-",
      "Resolution": "-",
      "Scale": "EM",
      "Multi-center": "-",
      "Rank": "-",
      "License": "Y",
      "Fully Open": "-",
      "link": "https://digestpath2019.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Dataset/Challenge": "PAIP2020",
      "Citation": "-",
      "Year": 2020,
      "Modality": "-",
      "Focus": "Colorectal cancer",
      "Tasks": "Classification/Segmentation",
      "Lesion/Tumor": "-",
      "Disease": "Colorectal Cancer",
      "Category": "Colon Rectum",
      "Resolution": "-",
      "Scale": "H&E",
      "Rank": "Train/val/test 47/31/40",
      "License": "Y",
      "Fully Open": "MICCAI",
      "link": "https://wsss4luad.grand-challenge.org/",
      "_source_file": "BioBank.json",
      "_source_sheet": "BioBank",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Image Captioning",
      "Modality": "Mixed",
      "Name": "MedICaT",
      "Link": "github",
      "Domain": "Mixed",
      "Dimension": "Mixed",
      "Format": "png + jsonl",
      "Description": "MEDICAT consists of 217K images from 131K open access biomedical papers, and includes captions, inline references for 74% of figures, and manually annotated sub- figures and subcaptions for a subset of fig- ures.",
      "#": 217060.0,
      "Metric": "Rouge\nBELU\nMETEOR\nCIDEr\nSPICE",
      "Label": "√",
      "Download": "√",
      "Reference": "[1] MedICaT: A Dataset of Medical Images, Captions, and Textual References\n\n[2] Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. S2ORC: The Semantic Scholar Open Research Corpus.\n\n[3] O. Pelka, S. Koitka, J. Rückert, F. Nensa, C.M. Friedrich, \"Radiology Objects in COntext (ROCO): A Multimodal Image Dataset\".",
      "link": "https://github.com/allenai/medicat",
      "_source_file": "Kai.json",
      "_source_sheet": "Kai",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Image Captioning",
      "Modality": "X-rays",
      "Name": "IU X-ray",
      "Domain": "Chest",
      "Download": "√",
      "link": "https://github.com/nlpaueb/bioCaption",
      "_source_file": "Kai.json",
      "_source_sheet": "Kai",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Image Captioning",
      "Modality": "Radiology",
      "Name": "ROCO",
      "link": "https://github.com/razorx89/roco-dataset",
      "_source_file": "Kai.json",
      "_source_sheet": "Kai",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision",
      "Task": "Classification",
      "Modality": "X-ray",
      "Name": "NIH Chest X-rays",
      "Link": "NIH Chest X-rays | Kaggle",
      "Domain": "Chest",
      "Dimension": "(1024, 1024)",
      "Format": ".png",
      "Description": "This NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. 14 (15) classes.",
      "#": 112120,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. IEEE CVPR 2017",
      "link": "https://www.kaggle.com/datasets/nih-chest-xrays/data?select=README_CHESTXRAY.pdf",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "X-ray",
      "Name": "CheXpert",
      "Link": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison (stanfordmlgroup.github.io)",
      "Domain": "Chest",
      "Dimension": "-",
      "Format": "-",
      "Description": "A Large Chest Radiograph Dataset. ",
      "#": 224316,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "-",
      "Reference": "Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S., Chute, C., ... & Ng, A. Y. (2019, July). Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 590-597).",
      "link": "https://stanfordmlgroup.github.io/competitions/chexpert/",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "X-ray, OCT, ultrasound, CT, electron microscope",
      "Name": "MedMNIST v2 2D",
      "Link": "MedMNIST",
      "Domain": "Multiple",
      "Dimension": "(28, 28)",
      "Format": ".npy",
      "Description": "a large-scale MNIST-like dataset collection of standardized biomedical images, including 12 datasets for 2D",
      "#": 708069,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "Yang, J., Shi, R., Wei, D., Liu, Z., Zhao, L., Ke, B., ... & Ni, B. (2023). MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification. Scientific Data, 10(1), 41.",
      "link": "https://medmnist.com/",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "X-ray, OCT, ultrasound, CT, electron microscope",
      "Name": "MedMNIST v2 3D",
      "Link": "MedMNIST",
      "Domain": "Multiple",
      "Dimension": "(28, 28, 28)",
      "Format": ".npy",
      "Description": "a large-scale MNIST-like dataset collection of standardized biomedical images, including 6 datasets for 3D",
      "#": 9998,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "Yang, J., Shi, R., Wei, D., Liu, Z., Zhao, L., Ke, B., ... & Ni, B. (2023). MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification. Scientific Data, 10(1), 41.",
      "link": "https://medmnist.com/",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "Optical camera",
      "Name": "EyePACS",
      "Link": "Diabetic Retinopathy Detection | Kaggle",
      "Domain": "Fundus",
      "Dimension": "from (433, 289) to (5184, 3456)",
      "Format": ".jpg",
      "Description": "a large set of high-resolution retina images A clinician has rated the presence of diabetic retinopathy in each image on a scale of 0 to 4",
      "#": 35126,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "Kaggle. Diabetic retinopathy detection challenge, 2015. URL https://www.kaggle.com/c/ diabetic-retinopathy-detection.",
      "link": "https://www.kaggle.com/competitions/diabetic-retinopathy-detection/data",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "Camera",
      "Name": "SIIM-ISIC",
      "Link": "SIIM-ISIC Melanoma Classification | Kaggle",
      "Domain": "Skin",
      "Dimension": "(1024, 1024)",
      "Format": ".jpg",
      "Description": "identify melanoma in images of skin lesions. 116GB.",
      "#": 44048,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "@misc{siim-isic-melanoma-classification, author = {Anna Zawacki, Brian Helba, George Shih, Jochen Weber, Julia Elliott, Marc Combalia, Nicholas Kurtansky, NoelCodella, Phil Culliton, Veronica Rotemberg}, title = {SIIM-ISIC Melanoma Classification}, publisher = {Kaggle}, year = {2020}, url = {https://kaggle.com/competitions/siim-isic-melanoma-classification} }",
      "link": "https://www.kaggle.com/c/siim-isic-melanoma-classification/data?select=train.csv",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "X-ray",
      "Name": "MURA",
      "Domain": "Bone",
      "Dimension": "-",
      "Format": "-",
      "Description": "MURA is a dataset of musculoskeletal radiographs consisting of 14,863 studies from 12,173 patients, with a total of 40,561 multi-view radiographic images. 3GB.",
      "#": 40561,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "√",
      "Reference": "MURA: Large Dataset for Abnormality Detection in Musculoskeletal Radiographs Pranav Rajpurkar*, Jeremy Irvin*, Aarti Bagul, Daisy Ding, Tony Duan, Hershel Mehta, Brandon Yang, Kaylie Zhu, Dillon Laird, Robyn L. Ball, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng",
      "link": "https://us13.mailchimp.com/mctx/clicks?url=https%3A%2F%2Fcs.stanford.edu%2Fgroup%2Fmlgroup%2FMURA-v1.1.zip&xid=06f8a38a0e&uid=55365305&pool=contact_facing&subject=MURA-v1.1%3A+Link+To+Dataset&v=1&h=132b9d18c73c565aeef6792263e8e855727e61255f9dee2f9908a521dac8bd00",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "Multi",
      "Name": "RadImageNet",
      "Link": "RadImageNet | Medical Image Artificial Intelligence",
      "Domain": "Multiple",
      "Dimension": "-",
      "Format": "-",
      "Description": "RadImageNet is a large database of annotated medical images from multiple modalities and of multiple pathologies.",
      "#": 1350000,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "-",
      "Reference": "@article{doi:10.1148/ryai.210315,\nauthor = {Mei, Xueyan and Liu, Zelong and Robson, Philip M. and Marinelli, Brett and Huang, Mingqian and Doshi, Amish and Jacobi, Adam and Cao, Chendi and Link, Katherine E. and Yang, Thomas and Wang, Ying and Greenspan, Hayit and Deyer, Timothy and Fayad, Zahi A. and Yang, Yang},\ntitle = {RadImageNet: An Open Radiologic Deep Learning Research Dataset for Effective Transfer Learning},\njournal = {Radiology: Artificial Intelligence},\nvolume = {0},\nnumber = {ja},\npages = {e210315},\nyear = {0},\ndoi = {10.1148/ryai.210315},\n\nURL = { \n        https://doi.org/10.1148/ryai.210315\n    \n},\neprint = { \n        https://doi.org/10.1148/ryai.210315\n}\n}",
      "link": "https://www.radimagenet.com/copy-of-home",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "Dermoscopy",
      "Name": "ISIC-2018",
      "Domain": "Skin",
      "Dimension": "（1024,768）",
      "Format": "JPEG文件",
      "Description": "Skin lesion",
      "#": 2594,
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "Pranav Rajpurkar, Jeremy Irvin, Aarti Bagul, Daisy Ding, Tony Duan, Hershel Mehta, Brandon Yang, Kaylie Zhu, Dillon Laird, Robyn L. Ball, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng",
      "link": "https://challenge.isic-archive.com/data/2018",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "Dermoscopy",
      "Name": "ISIC-2019",
      "Domain": "Skin",
      "Dimension": "（1024,768）",
      "Format": "JPEG文件",
      "Description": "Skin lesion",
      "#": 25331,
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "BCN_20000 Dataset: (c) Department of Dermatology, Hospital Clínic de Barcelona\n\nHAM10000 Dataset: (c) by ViDIR Group, Department of Dermatology, Medical University of Vienna; https://doi.org/10.1038/sdata.2018.161\n\nMSK Dataset: (c) Anonymous; https://arxiv.org/abs/1710.05006; https://arxiv.org/abs/1902.03368\n\n[1] Tschandl P., Rosendahl C. & Kittler H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 doi.10.1038/sdata.2018.161 (2018)\n\n[2] Noel C. F. Codella, David Gutman, M. Emre Celebi, Brian Helba, Michael A. Marchetti, Stephen W. Dusza, Aadi Kalloo, Konstantinos Liopyris, Nabin Mishra, Harald Kittler, Allan Halpern: \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\", 2017; arXiv:1710.05006.\n\n[3] Marc Combalia, Noel C. F. Codella, Veronica Rotemberg, Brian Helba, Veronica Vilaplana, Ofer Reiter, Allan C. Halpern, Susana Puig, Josep Malvehy: \"BCN20000: Dermoscopic Lesions in the Wild\", 2019; arXiv:1908.02288.",
      "link": "https://challenge.isic-archive.com/data/2019",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT, MRI",
      "Name": "MSD(Medical Segmentation Decathlon)",
      "Domain": "Multiple",
      "Dimension": "-",
      "Format": "NIfTI",
      "Description": "A large collection of annotated medical image datasets\nof various clinically relevant anatomies available under open source license, 10 tasks in total",
      "#": 2633,
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "Amber L Simpson, Michela Antonelli, Spyridon Bakas,\nMichel Bilello, Keyvan Farahani, Bram Van Ginneken, Annette Kopp-Schneider, Bennett A Landman, Geert Litjens,\nBjoern Menze, et al. A large annotated medical image\ndataset for the development and evaluation of segmentation\nalgorithms. arXiv preprint arXiv:1902.09063, 2019\n\n Antonelli, M., Reinke, A., Bakas, S. et al. The Medical Segmentation Decathlon. Nat Commun 13, 4128 (2022). https://doi.org/10.1038/s41467-022-30695-9",
      "link": "http://medicaldecathlon.com/results/",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "chest X-ray (CXR)",
      "Name": "COVID-QU-Ex",
      "Domain": "Lung",
      "Dimension": "-",
      "Format": ".png",
      "Description": "The researchers of Qatar University have compiled the COVID-QU-Ex dataset, which consists of 33,920 chest X-ray (CXR) images including:\n\n11,956 COVID-19\n11,263 Non-COVID infections (Viral or Bacterial Pneumonia)\n10,701 Normal\nGround-truth lung segmentation masks are provided for the entire dataset. This is the largest ever created lung mask dataset.",
      "#": 33920,
      "Metric": "dice accuracy, IoU, ACC",
      "Label": "√",
      "Download": "√",
      "Reference": "[1] A. M. Tahir, M. E. H. Chowdhury, A. Khandakar, Y. Qiblawey, U. Khurshid, S. Kiranyaz, N. Ibtehaz, M. S. Rahman, S. Al-Madeed, S. Mahmud, M. Ezeddin, K. Hameed, and T. Hamid, “COVID-19 Infection Localization and Severity Grading from Chest X-ray Images”, Computers in Biology and Medicine, vol. 139, p. 105002, 2021, https://doi.org/10.1016/j.compbiomed.2021.105002.\n[2] Anas M. Tahir, Muhammad E. H. Chowdhury, Yazan Qiblawey, Amith Khandakar, Tawsifur Rahman, Serkan Kiranyaz, Uzair Khurshid, Nabil Ibtehaz, Sakib Mahmud, and Maymouna Ezeddin, “COVID-QU-Ex .” Kaggle, 2021, https://doi.org/10.34740/kaggle/dsv/3122958.\n[3] T. Rahman, A. Khandakar, Y. Qiblawey A. Tahir S. Kiranyaz, S. Abul Kashem, M. Islam, S. Al Maadeed, S. Zughaier, M. Khan, M. Chowdhury, \"Exploring the Effect of Image Enhancement Techniques on COVID-19 Detection using Chest X-rays Images,\" Computers in Biology and Medicine, p. 104319, 2021, https://doi.org/10.1016/j.compbiomed.2021.104319.\n[4] A. Degerli, M. Ahishali, M. Yamac, S. Kiranyaz, M. E. H. Chowdhury, K. Hameed, T. Hamid, R. Mazhar, and M. Gabbouj, \"Covid-19 infection map generation and detection from chest X-ray images,\" Health Inf Sci Syst 9, 15 (2021), https://doi.org/10.1007/s13755-021-00146-8.\n[5] M. E. H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M. A. Kadir, Z. B. Mahbub, K. R. Islam, M. S. Khan, A. Iqbal, N. A. Emadi, M. B. I. Reaz, M. T. Islam, \"Can AI Help in Screening Viral and COVID-19 Pneumonia?,\" IEEE Access, vol. 8, pp. 132665-132676, 2020, https://doi.org/10.1109/ACCESS.2020.3010287.",
      "link": "https://www.kaggle.com/datasets/anasmohammedtahir/covidqu",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "chest X-ray (CXR)",
      "Name": "CheXmask Database",
      "Domain": "Lung,Heart",
      "Dimension": "(1024, 1024)",
      "Format": ".jpg",
      "Description": "a large-scale dataset of anatomical segmentation masks for chest x-ray images，The CheXmask Database presents a comprehensive, uniformly annotated collection of chest radiographs, constructed from six public databases",
      "#": "676803 anatomical segmentation masks",
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. In: Navab N, Hornegger J, Wells W, Frangi A, editors. Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015. Cham: Springer; 2015. p. 234-241. (Lecture Notes in Computer Science; vol 9351).\nMoukheiber D, Mahindre S, Moukheiber L, Moukheiber M, Wang S, Ma C, Shih G, Peng Y, Gao M. Few-Shot Learning Geometric Ensemble for Multi-label Classification of Chest X-Rays. InData Augmentation, Labelling, and Imperfections: Second MICCAI Workshop, DALI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 22, 2022, Proceedings 2022 Sep 16 (pp. 112-122). Cham: Springer Nature Switzerland.\nGaggion N, Mansilla L, Mosquera C, Milone DH, Ferrante E. Improving anatomical plausibility in medical image segmentation via hybrid graph neural networks: applications to chest x-ray analysis. IEEE Trans Med Imaging. 2022. doi:10.1109/TMI.2022.3224660.\nFeng S, et al. Curation of the candid-ptx dataset with free-text reports. Radiology: Artificial Intelligence. 2021;3(6):e210136.\nWang X, et al. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.\nIrvin J, et al. Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. Proceedings of the AAAI conference on artificial intelligence. 2019;33(01).\nJohnson AE, et al. MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs. arXiv preprint. 2019. arXiv:1901.07042.\nBustos A, et al. Padchest: A large chest x-ray image dataset with multi-label annotated reports. Med Image Anal. 2020;66:101797.\nNguyen HQ, et al. VinDr-CXR: An open dataset of chest X-rays with radiologist’s annotations. Sci Data. 2022;9(1):429.\nValindria VV, et al. Reverse classification accuracy: predicting segmentation performance in the absence of ground truth. IEEE Trans Med Imaging. 2017;36:1597–1606.\nGaggion N. Chest-xray-landmark-dataset [Internet]. GitHub repository. Available from: https://github.com/ngaggion/Chest-xray-landmark-dataset. [Accessed 6/27/2023]\nGaggion N, Vakalopoulou M, Milone DH, Ferrante E. Multi-center anatomical segmentation with heterogeneous labels via landmark-based models. In: 20th IEEE International Symposium on Biomedical Imaging (ISBI). IEEE; 2023.",
      "link": "https://physionet.org/content/chexmask-cxr-segmentation-data/0.1/",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "MG",
      "Name": "CBIS-DDSM",
      "Domain": "Breast",
      "Dimension": "-",
      "Format": ".jpeg",
      "Description": "This CBIS-DDSM (Curated Breast Imaging Subset of DDSM) is an updated and standardized version of the Digital Database for Screening Mammography (DDSM). The DDSM is a database of 2,620 scanned film mammography studies. It contains normal, benign, and malignant cases with verified pathology information.",
      "#": 10239,
      "Metric": "-",
      "Label": "√",
      "Download": "√",
      "Reference": "R. S. Lee, F. Gimenez, A. Hoogi, D. Rubin. Curated Breast Imaging Subset of DDSM. The Cancer Imaging Archive, 2016.\n\nR. S. Lee, F. Gimenez, A. Hoogi, K. K. Miyake, M. Gorovoy, D. L. Rubin. A Curated Mammography Data set for Use in Computer-aided Detection and Diagnosis Research. Scientific Data Volume 4, Article number: 170177, 2017.\n\nK. Clark, B. Vendt, K. Smith, J. Freymann, J. Kirby, P. Koppel, S. Moore, S. Phillips, D. Maffitt, M. Pringle, L. Tarbox, F. Prior. The Cancer Imaging Archive(TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, Volume 26, 2013.",
      "link": "https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "chest X-ray (CXR)",
      "Name": "SIIM-ACR Pneumothorax Segmentation",
      "Domain": "Lung",
      "Dimension": "(1024, 1024)",
      "Format": ".png",
      "Description": "This dataset contains the stage 1 train and test data from the Kaggle SIIM-ACR Pneumothorax Segmentation competition - structured in a way that makes it easier to use.",
      "#": 12047,
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "没找到",
      "link": "https://www.kaggle.com/datasets/vbookshelf/pneumothorax-chest-xray-images-and-masks",
      "_source_file": "Milestone_1.json",
      "_source_sheet": "Milestone_1",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "kvas": "Vision",
      "Task": "Segmentation",
      "Modality": "MRI",
      "Name": "ACDC",
      "Domain": "Heart",
      "Dimension": "(30, 10, 256, 216)",
      "Format": "nii文件",
      "Description": "Ventricular endocardium on Cardiac MRI",
      "#": 100,
      "Metric": "dice accuracy, IoU, H distance",
      "Download": "√",
      "Reference": "O. Bernard, A. Lalande, C. Zotti, F. Cervenansky, et al.\n\"Deep Learning Techniques for Automatic MRI Cardiac Multi-structures Segmentation and\nDiagnosis: Is the Problem Solved ?\" in IEEE Transactions on Medical Imaging,\nvol. 37, no. 11, pp. 2514-2525, Nov. 2018\n\ndoi: 10.1109/TMI.2018.2837502",
      "link": "https://humanheart-project.creatis.insa-lyon.fr/database/collection/637218c173e9f0047faa00fb/folder/637218e573e9f0047faa00fc",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "T1, T1GD, T2, FLAIR",
      "Name": "BraTS",
      "Domain": "Brain",
      "Dimension": "(240, 240, 155)",
      "Format": "nii文件",
      "Description": "Brain Tumor Segmentation",
      "#": 369,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": "[1] U.Baid, et al., \"The RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor Segmentation and Radiogenomic Classification\", arXiv:2107.02314, 2021(opens in a new window).\n\n[2] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, et al. \"The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)\", IEEE Transactions on Medical Imaging 34(10), 1993-2024 (2015) DOI: 10.1109/TMI.2014.2377694 (opens in a new window)\n\n[3] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J.S. Kirby, et al., \"Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features\", Nature Scientific Data, 4:170117 (2017) DOI: 10.1038/sdata.2017.117(opens in a new window)",
      "link": "https://www.kaggle.com/datasets/dschettler8845/brats-2021-task1",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "Ultrasound",
      "Name": "BUID",
      "Link": "Breast Ultrasound Images Dataset | Kaggle",
      "Domain": "Breast",
      "Dimension": "(500,500,3）",
      "Format": "png文件",
      "Description": "Breast tumor regions",
      "#": 780,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": "W. Al-Dhabyani, M. Gomaa, H. Khaled, and A. Fahmy, “Dataset of breast ultrasound images,” Data in brief, vol. 28, p. 104863, 2020",
      "link": "https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT",
      "Name": "CIR",
      "Domain": "Lung",
      "Dimension": "(64, 64, 64)",
      "Format": "npy文件",
      "Description": "Lung nodules ",
      "#": 956,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": " W. Choi, N. Dahiya, and S. Nadeem, “CIRDataset: A large-scale\ndataset for clinically-interpretable lung nodule radiomics and ma_x0002_lignancy prediction,” in International Conference on Medical Image\nComputing and Computer-Assisted Intervention. Springer, 2022, pp.\n13–22.",
      "link": "https://zenodo.org/record/6762573",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "Colonoscopy",
      "Name": "Kvasir",
      "Domain": "Bowel ",
      "Dimension": "from 720x576 up to 1920x1072",
      "Format": "jpg文件",
      "Description": "Polyps",
      "#": 1000,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": " D. Jha, P. H. Smedsrud, M. A. Riegler, P. Halvorsen, T. d. Lange,\nD. Johansen, and H. D. Johansen, “Kvasir-seg: A segmented\npolyp dataset,” in International Conference on Multimedia Modeling.\nSpringer, 2020, pp. 451–462",
      "link": "https://datasets.simula.no/kvasir/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT",
      "Name": "Pancreas",
      "Domain": "Pancreas",
      "Dimension": "(512, 512, 240)",
      "Format": "npy文件",
      "Description": "Pancreatic parenchyma and mass ",
      "#": 285,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": " M. A. Attiyeh, J. Chakraborty, A. Doussot, L. Langdon-Embry,\nS. Mainarich, M. Gonen, V. P. Balachandran, M. I. D’Angelica, R. P. ¨\nDeMatteo, W. R. Jarnagin et al., “Survival prediction in pancreatic\nductal adenocarcinoma by quantitative computed tomography\nimage analysis,” Annals of surgical oncology, vol. 25, no. 4, pp. 1034–\n1042, 2018.\nM. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider,\nB. A. Landman, G. Litjens, B. Menze, O. Ronneberger, R. M.\nSummers et al., “The medical segmentation decathlon,” Nature\ncommunications, vol. 13, no. 1, pp. 1–13, 2022",
      "link": "https://www.kaggle.com/datasets/tahsin/pancreasct-dataset",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "Gadolinium-enhanced MRI",
      "Name": "LA",
      "Link": "2018 Atria Segmentation Data – Cardiac Atlas Project",
      "Domain": "Heart",
      "Dimension": "（0.625 x 0.625 x 0.625）",
      "Format": "nii文件",
      "Description": "Left atrium",
      "#": 154,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": "Zhaohan Xiong, Qing Xia, Zhiqiang Hu, Ning Huang, Cheng Bian, Yefeng Zheng, Sulaiman Vesal, Nishant Ravikumar, Andreas Maier, Xin Yang, Pheng-Ann Heng, Dong Ni, Caizi Li, Qianqian Tong, Weixin Si, Elodie Puybareau, Younes Khoudli, Thierry Géraud, Chen Chen, Wenjia Bai, Daniel Rueckert, Lingchao Xu, Xiahai Zhuang, Xinzhe Luo, Shuman Jia, Maxime Sermesant, Yashu Liu, Kuanquan Wang, Davide Borra, Alessandro Masci, Cristiana Corsi, Coen de Vente, Mitko Veta, Rashed Karim, Chandrakanth Jayachandran Preetha, Sandy Engelhardt, Menyun Qiao, Yuanyuan Wang, Qian Tao, Marta Nuñez-Garcia, Oscar Camara, Nicolo Savioli, Pablo Lamata, Jichao Zhao. “A Global Benchmark of Algorithms for Segmenting the Left Atrium from Late Gadolinium-Enhanced Cardiac Magnetic Resonance Imaging.” Medical Image Analysis 67 (2021): 101832.",
      "link": "https://www.cardiacatlas.org/atriaseg2018-challenge/atria-seg-data/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT",
      "Name": "LiTS",
      "Domain": "Liver",
      "Dimension": "（512，512）",
      "Format": "jpg文件",
      "Description": "Liver tumor",
      "#": 131,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": "P. Bilic, P. Christ, H. B. Li, E. Vorontsov, A. Ben-Cohen, G. Kaissis,\nA. Szeskin, C. Jacobs, G. E. H. Mamani, G. Chartrand et al.,\n“The liver tumor segmentation benchmark (LiTS),” Medical Image\nAnalysis, vol. 84, p. 102680, 2023.",
      "link": "https://www.kaggle.com/datasets/harshwardhanbhangale/lits-dataset",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "T1-weighted MRI",
      "Name": "Hippo",
      "Domain": "Brain",
      "Dimension": "(36, 52, 32)",
      "Format": "nii文件",
      "Description": "Hippocampus",
      "#": 260,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": "M. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider,\nB. A. Landman, G. Litjens, B. Menze, O. Ronneberger, R. M.\nSummers et al., “The medical segmentation decathlon,” Nature\ncommunications, vol. 13, no. 1, pp. 1–13, 2022.",
      "link": "http://medicaldecathlon.com/dataaws/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "X-ray",
      "Name": "Chest X-rays",
      "Link": "Chest Xray Masks and Labels | Kaggle",
      "Domain": "Chest ",
      "Dimension": "4,020×4,892",
      "Format": "png文件",
      "Description": "Lung",
      "#": 662,
      "Metric": "dice accuracy",
      "Download": "√",
      "Reference": "] S. Jaeger, S. Candemir, S. Antani, Y.-X. J. Wang, P.-X. Lu, and ´ G. Thoma, “Two public chest x-ray datasets for computer-aided screening of pulmonary diseases,” Quantitative imaging in medicine and surgery, vol. 4, no. 6, p. 475, 2014.",
      "link": "https://www.kaggle.com/datasets/nikhilpandey360/chest-xray-masks-and-labels",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CheXpert-small",
      "Domain": "Chest",
      "Dimension": "-",
      "Format": ".jpg",
      "Description": "A Large Chest Radiograph Dataset",
      "Reference": "Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S., Chute, C., ... & Ng, A. Y. (2019, July). Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 590-597).",
      "link": "https://www.kaggle.com/datasets/ashery/chexpert",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "X-ray",
      "Name": "MIMIC-CXR",
      "Link": "MIMIC-CXR-JPG - chest radiographs with structured labels v2.0.0 (physionet.org)",
      "Domain": "Chest",
      "Dimension": "-",
      "Format": ".jpg",
      "Description": "chest radiographs in JPG format with structured labels",
      "#": 377110,
      "Metric": "AUC, ACC, F1, Recall, Precision",
      "Label": "√",
      "Download": "-",
      "Reference": "Johnson, A., Lungren, M., Peng, Y., Lu, Z., Mark, R., Berkowitz, S., & Horng, S. (2019). MIMIC-CXR-JPG - chest radiographs with structured labels (version 2.0.0). PhysioNet.",
      "link": "https://physionet.org/content/mimic-cxr-jpg/2.0.0/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT",
      "Name": "WORD",
      "Domain": "Abdominal organ",
      "Dimension": "(512, 512, from 159 to 330)",
      "Format": ".nii文件",
      "Description": "A large-scale whole abdominal CT multi-organ segmentation dataset containing 150 CT volumes and 16 organ annotations",
      "#": 150,
      "Metric": "dice accuracy，H distance",
      "Label": "√",
      "Download": "√",
      "Reference": "Xiangde Luo, Wenjun Liao, Jianghong Xiao, Tao Song, Xiaofan Zhang, Kang Li, Guotai Wang, and Shaoting Zhang. Word: Revisiting organs segmentation in the whole abdominal region. arXiv preprint arXiv:2111.02403, 2021.",
      "link": "https://github.com/HiLab-git/WORD",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT,DX,CR",
      "Name": "LIDC-IDRI",
      "Domain": "Lung",
      "Dimension": "(512, 512, from 133 to 277)",
      "Format": "DICOM",
      "Description": "(LIDC-IDRI) consists of diagnostic and lung cancer screening thoracic CT scans with marked-up annotated lesions. It is a resource for development, training, and evaluation of computer-assisted diagnostic (CAD) methods for lung cancer detection and diagnosis.",
      "#": "1012 scans, 244527 images",
      "Metric": "-",
      "Label": "√",
      "Download": "√",
      "Reference": "Arnaud Arindra Adiyoso Setio, Alberto Traverso, Thomas de Bel, Moira S.N. Berens, Cas van den Bogaard, Piergiorgio Cerello, Hao Chen, Qi Dou, Maria Evelina Fantacci, Bram Geurts, Robbert van der Gugten, Pheng Ann Heng, Bart Jansen, Michael M.J. de Kaste, Valentin Kotov, Jack Yu-Hung Lin, Jeroen T.M.C. Manders, Alexander Sóñora-Mengana, Juan Carlos García-Naranjo, Evgenia Papavasileiou, Mathias Prokop, Marco Saletta, Cornelia M Schaefer-Prokop, Ernst T. Scholten, Luuk Scholten, Miranda M. Snoeren, Ernesto Lopez Torres, Jef Vandemeulebroucke, Nicole Walasek, Guido C.A. Zuidhof, Bram van Ginneken, Colin Jacobs,\nValidation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: The LUNA16 challenge,\nMedical Image Analysis,\nVolume 42,\n2017",
      "link": "https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=1966254/1966254664661b500be4a23bbc7f096b7e1832f",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT",
      "Name": "AbdomenCT-1K",
      "Domain": "Abdominal organ",
      "Dimension": "(512, 512)",
      "Format": "nii文件",
      "Description": "a large-scale abdominal multi-organ CT dataset by extending the existing benchmark datasets with more organ annotations, 50 extra images from Nanjing University",
      "#": 1112,
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "[1] N. Heller, F. Isensee, K. H. Maier-Hein, X. Hou, C. Xie, F. Li, Y. Nan, G. Mu, Z. Lin, M. Han et al., “The state of the art in kidney and kidney tumor segmentation in contrast-enhanced ct imaging: Results of the kits19 challenge,” Medical Image Analysis, vol. 67, p. 101821, 2021.\n\n[2] A. L. Simpson, M. Antonelli, S. Bakas, M. Bilello, K. Farahani, B. Van Ginneken, A. Kopp-Schneider, B. A. Landman, G. Litjens, B. Menze et al., “A large annotated medical image dataset for the development and evaluation of segmentation algorithms,” arXiv preprint arXiv:1902.09063, 2019.\n\n[3] K. Clark, B. Vendt, K. Smith, J. Freymann, J. Kirby, P. Koppel, S. Moore, S. Phillips, D. Maffitt, M. Pringle et al., “The cancer imaging archive (tcia): maintaining and operating a public information repository,” Journal of Digital Imaging, vol. 26, no. 6, pp. 1045–1057, 2013.\n\n[4] P. Bilic, P. F. Christ, E. Vorontsov, G. Chlebus, H. Chen, Q. Dou, C.-W. Fu, X. Han, P.-A. Heng, J. Hesser et al., \"The liver tumor segmentation benchmark (lits),\" arXiv preprint arXiv:1901.04056, 2019. \n\n[5] H. R. Roth, A. Farag, E. B. Turkbey, L. Lu, J. Liu, and R. M. Summers, “Data from pancreas-CT,” The Cancer Imaging Archive, 2016.\n\n[6] H. R. Roth, L. Lu, A. Farag, H.-C. Shin, J. Liu, E. B. Turkbey, and R. M. Summers, “Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation,” in International Conference on Medical Image Computing and Computer-assisted Intervention, 2015, pp. 556–564.",
      "link": "https://abdomenct-1k-continual-learning.grand-challenge.org/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "OCT,OCTA",
      "Name": "OCTA-500",
      "Domain": "Multiple",
      "Dimension": "(400,400,640), (304,304,640)",
      "Format": "-",
      "Description": "The dataset provides rich images and annotations including two modalities (OCT/OCTA volumes), six types of projections, four types of text labels and seven types of segmentation labels.",
      "#": 500,
      "Metric": "dice accuracy, IoU, ACC, SE, SP",
      "Label": "√",
      "Download": "√",
      "Reference": "Mingchao Li, Kun Huang, Qiuzhuo Xu, Jiadong Yang, Yuhan Zhang, Zexuan Ji, Keren Xie, Songtao Yuan, Qinghuai Liu, and Qiang Chen. \"OCTA-500: A Retinal Dataset for Optical Coherence Tomography Angiography Study,\" arXiv:2012.07261, 2022.\n\nMingchao Li, Yerui Chen, Zexuan Ji, Keren Xie, Songtao Yuan, Qiang Chen, and Shuo Li.\"Image projection network: 3D to 2D image segmentation in OCTA images,\" IEEE Trans. Med. Imaging, vol.39, no.11, pp.3343-3354, 2020.",
      "link": "https://ieee-dataport.org/open-access/octa-500",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "CT",
      "Name": "NLST",
      "Domain": "Lung",
      "Dimension": "-",
      "Format": "-",
      "Description": "The datasets are comprehensive; they include data on participant characteristics, screening exam results, diagnostic procedures, lung cancer, and mortality. Images from over 75,000 CT screening exams are available. Over 1,200 pathology images from a subset of NLST lung cancer patients (~500 of over 2,000 patients) may be made available.",
      "#": 21082502,
      "Metric": "-",
      "Label": "-",
      "Download": "√",
      "Reference": "National Lung Screening Trial Research Team. (2013). Data from the National Lung Screening Trial (NLST) [Data set]. The Cancer Imaging Archive. https://doi.org/10.7937/TCIA.HMQ8-J677\n\nNational Lung Screening Trial Research Team*; Aberle DR, Adams AM, Berg CD, Black WC, Clapp JD, Fagerstrom RM, Gareen IF, Gatsonis C, Marcus PM, Sicks JD (2011). Reduced Lung-Cancer Mortality with Low-Dose Computed Tomographic Screening. New England Journal of Medicine, 365(5), 395–409. https://doi.org/10.1056/nejmoa1102873\n\nClark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057. DOI: https://doi.org/10.1007/s10278-013-9622-7",
      "link": "https://cdas.cancer.gov/nlst/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Segmentation",
      "Modality": "WLI, FICE ",
      "Name": "BKAI-IGH NeoPolyp-Small",
      "Domain": " colon",
      "Format": ".jpeg",
      "Description": "A dataset for colonoscopy polyp segmentation and neoplasm characterization",
      "#": 1200,
      "Metric": "dice accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "1. Lan, P.N., An, N.S., Hang, D.V., Long, D.V., Trung, T.Q., Thuy, N.T., Sang, D.V.: NeoUnet: Towards accurate colon polyp segmentation and neoplasm detection. In: Proceedings of the 16th International Symposium on Visual Computing (2021)\n2. Nguyen Sy An, Phan Ngoc Lan, Dao Viet Hang, Dao Van Long, Tran Quang Trung, Nguyen Thi Thuy, Dinh Viet Sang. BlazeNeo: Blazing fast polyp segmentation and neoplasm detection. IEEE Access, Vol. 10, 2022.",
      "link": "https://www.kaggle.com/competitions/bkai-igh-neopolyp/overview",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Registration",
      "Modality": "fundus camera",
      "Name": "FIRE",
      "Link": "FIRE: Fundus Image Registration Dataset (forth.gr)",
      "Domain": "Fundus",
      "Dimension": "(2912, 2912)",
      "Format": ".jpg",
      "Description": "Fundus Image Registration Dataset, annotated with ground truth data",
      "#": 134,
      "Metric": "MEE, MAE https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5416285",
      "Label": "√",
      "Download": "√",
      "Reference": "C. Hernandez-Matas, X. Zabulis, A. Triantafyllou, P. Anyfanti, S. Douma, A.A. Argyros\nJournal for Modeling in Ophthalmology, vol. 1, no. 4, pp. 16-28, Jul. 2017.\nDOI: 10.35119/maio.v1i4.42",
      "link": "https://projects.ics.forth.gr/cvrl/fire/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Unlabel",
      "Modality": "T1-weighted MRI",
      "Name": "OASIS-1",
      "Domain": "Brain",
      "Dimension": "(176, 208, 176)",
      "Format": "gif, img, hdr",
      "Description": "Cross-sectional MRI Data in Young, Middle Aged, Nondemented and Demented Older Adults",
      "#": 1736,
      "Metric": "-",
      "Label": "-",
      "Download": "√",
      "Reference": "Open Access Series of Imaging Studies (OASIS): Cross-Sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older AdultsMarcus, DS, Wang, TH, Parker, J, Csernansky, JG, Morris, JC, Buckner, RL. Journal of Cognitive Neuroscience, 19, 1498-1507. doi: 10.1162/jocn.2007.19.9.1498",
      "link": "http://www.oasis-brains.org/access",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Unlabel",
      "Modality": "T1-weighted MRI",
      "Name": "OASIS-2",
      "Domain": "Brain",
      "Dimension": "(176, 208, 176)",
      "Format": "gif, img, hdr",
      "Description": "Longitudinal MRI Data in Nondemented and Demented Older Adults",
      "#": 600,
      "Metric": "-",
      "Label": "-",
      "Download": "√",
      "Reference": "Open Access Series of Imaging Studies (OASIS): Longitudinal MRI Data in Nondemented and Demented Older Adults\nMarcus, DS, Fotenos, AF, Csernansky, JG, Morris, JC, Buckner, RL, 2010. Journal of Cognitive Neuroscience, 22, 2677-2684. doi: 10.1162/jocn.2009.21407",
      "link": "http://www.oasis-brains.org/access",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Unlabel",
      "Modality": "T1-weighted MRI, T2-weighted MRI",
      "Name": "OASIS-3",
      "Domain": "Brain",
      "Dimension": "(176, 208, 176)",
      "Format": "gif, img, hdr",
      "Description": "Longitudinal MRI Data in Nondemented and Demented Older Adults",
      "#": 2842,
      "Metric": "-",
      "Label": "-",
      "Download": "√",
      "Reference": "OASIS-3: Longitudinal Neuroimaging, Clinical, and Cognitive Dataset for Normal Aging and Alzheimer Disease\nPamela J LaMontagne, Tammie L.S. Benzinger, John C. Morris, Sarah Keefe, Russ Hornbeck, Chengjie Xiong, Elizabeth Grant, Jason Hassenstab, Krista Moulder, Andrei Vlassenko, Marcus E. Raichle, Carlos Cruchaga, Daniel Marcus, 2019. medRxiv. doi: 10.1101/2019.12.13.19014902",
      "link": "http://www.oasis-brains.org/access",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "kvas": "Language",
      "Task": "Inference",
      "Modality": "Text",
      "Name": "ROND",
      "Metric": "ACC",
      "Download": "√",
      "Reference": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "link": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "Text",
      "Name": "ROND",
      "Metric": "F1",
      "Download": "√",
      "Reference": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "link": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "NER",
      "Modality": "Text",
      "Name": "ROND",
      "Download": "√",
      "Reference": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "link": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "QA",
      "Modality": "Text",
      "Name": "ROND",
      "link": "https://github.com/zl-liu/Radiation-Oncology-NLP-Database",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "kvas": "Vision & Language",
      "Task": "Captioning / Report generation",
      "Modality": "ROCO",
      "Name": "Radiology images & out-of-class (non-radiology) images",
      "Domain": "CT, Ultra-sound, X-Ray, Fluoroscopy, PET, Mammography, MRI, Angiography and PET-CT",
      "Dimension": "Mixture",
      "link": "https://github.com/razorx89/roco-dataset",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Captioning / Report generation",
      "Modality": "MIMIC-CXR",
      "Name": "X-ray",
      "Domain": "Chest",
      "Reference": "[1]  Johnson AE, Pollard TJ, Greenbaum NR, Lungren MP, Deng C-Y, Peng Y, Lu Z, Mark RG, Berkowitz SJ, Horng S. MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs. arXiv preprint arXiv:1901.07042. 2019.\n\n[2] https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1224/reports/custom_117157386.pdf",
      "link": "https://github.com/aehrc/cvt2distilgpt2",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Captioning / Report generation",
      "Modality": "IU-Xray",
      "Name": "X-ray",
      "link": "https://github.com/nlpaueb/bio_image_caption",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Viasual question anwering",
      "Modality": "VQA-RAD",
      "Name": "CT & X-ray",
      "Domain": "104 head axial single-slice CTs or MRIs, 107 chest x-rays, and 104 abdominal axial CTs.",
      "Format": "jpg, json, xml, xlsx",
      "Description": "a manually constructed VQA dataset in radiology where questions and answers about images are naturally created and validated by clinicians. Trading off quantity of automatic generation, VQA-RAD is a high-quality design with only 60 hours of specialist contributions. Structured like other existing VQA datasets, each question can be answered with a single image alone.",
      "#": "3,515 question–answer pairs on 315 radiology images",
      "Metric": "Accuracy, AUC -- closed-ended, open-ended, and overall",
      "Label": "√",
      "Download": "√",
      "Reference": "[1] Lau, Jason J., et al. \"A dataset of clinically generated visual questions and answers about radiology images.\" Scientific data 5.1 (2018): 1-10.",
      "link": "https://osf.io/89kps/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Viasual question anwering / Object detection / Knowledge graph",
      "Modality": "SLAKE (EN)",
      "Name": "CT, X-ray, MRI",
      "Domain": "The images include 140 head CTs or MRIs, 41 neck CTs, 219 chest X-Rays or CTs, 201 abdomen CTs or MRIs, and 41 pelvic cavity CTs",
      "#": "there are 282 CTs, 181 MRIs, and 179 X-Rays. All CTs and MRIs are axial single-slice.\n\n642 images and 14K QA pairs.",
      "Label": "√",
      "Download": "√",
      "link": "https://github.com/pengfeiliheu/m2i2",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Viasual question anwering",
      "Modality": "PMC-VQA",
      "Name": "Mixture: Radiology, Pathology, Microscopy, Signals, Generic biomedical illlustrations, etc",
      "Domain": "Mixture: no clear and related descriptions",
      "Dimension": "Mixture",
      "Format": "jpg, csv",
      "Description": "PMC-VQA, contains 227k VQA pairs of 149k images, covering various modalities or diseases, surpassing existing datasets in terms of both amount and diversity,",
      "#": "149k images & 227 k Q&A pairs",
      "Metric": "Accuracy, AUC -- closed-ended, open-ended, and overall",
      "Label": "√",
      "Download": "√",
      "Reference": "[1] Zhang, Xiaoman, et al. \"Pmc-vqa: Visual instruction tuning for medical visual question answering.\" arXiv preprint arXiv:2305.10415 (2023). ",
      "link": "https://github.com/xiaoman-zhang/PMC-VQA",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Viasual question anwering",
      "Modality": "OVQA",
      "Name": "CT & X-Ray",
      "Domain": "Orthopedic",
      "Dimension": "hand, leg, head, and chest",
      "Description": "OVQA contains 19, 020 medical visual question and answer pairs generated from 2, 001 medical images collected from 2, 212 EMRs in Orthopedic. There are six types of questions: Abnormality, Condition Presence, Modality, Organ system, Plane, and Attribute Other. The most frequent question type is Abnormality with 31% (5, 920) questions, while the least frequent one is Plane, with only 4% (795) questions. QA pairs are split into 33% (6, 260) open-ended questions and 67% (12, 760) closed-ended ones. The“yes/no” QA pairs represent 76% (9, 699) of closed-ended ones, The number of“yes” and“no” answers are balanced, and the percentage of“yes” is 47%. The 2, 001 medical images contain two modalities of CT and XRay, and cover the body parts of hand, leg, chest, and head. The number of“CT” and“X-Ray” images is 1, 410 and 591 respectively. The hand images dominate, with 50% (999) images.",
      "#": "2, 001 medical images collected from 2, 212 EMRs in Orthopedic;\n\nQA pairs are split into 33% (6, 260) open-ended questions and 67% (12, 760) closed-ended ones. The“yes/no” QA pairs represent 76% (9, 699) of closed-ended ones, The number of“yes” and“no” answers are balanced, and the percentage of“yes” is 47%",
      "Metric": "Accuracy, AUC -- closed-ended, open-ended, and overall",
      "Label": "√",
      "Download": "√ (requesting)",
      "Reference": "[1] Huang, Yefan, et al. \"OVQA: a clinically generated visual question answering dataset.\" Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2022.\n\n[2] van Sonsbeek, Tom, et al. \"Open-ended medical visual question answering through prefix tuning of language models.\" arXiv preprint arXiv:2303.05977 (2023).",
      "link": "http://47.94.174.82/",
      "_source_file": "Milestone_2.json",
      "_source_sheet": "Milestone_2",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "tabular",
      "Task": "prediction/binary classification",
      "Modality": "Survey",
      "Name": "Indicators of Heart Disease",
      "Domain": "heart disease",
      "Format": ".csv",
      "Description": "The dataset originally comes from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to collect data on the health status of U.S. residents.",
      "Metric": "mse/mae or accuracy/F1 score",
      "Publish Year": 2022.0,
      "link": "https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease",
      "_source_file": "Yansong_tabular.json",
      "_source_sheet": "Yansong_tabular",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "prediction/binary classification",
      "Name": "Heart Failure Prediction",
      "Domain": "Cardiovascular diseases (CVDs) ",
      "Format": ".csv",
      "Metric": "mse/mae or accuracy/F1 score",
      "Reference": "Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020). ",
      "Publish Year": 2020.0,
      "link": "https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data",
      "_source_file": "Yansong_tabular.json",
      "_source_sheet": "Yansong_tabular",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "data generation/prediction/classification",
      "Name": "Breast Cancer Wisconsin (Diagnostic) Data Set",
      "Format": ".csv",
      "Metric": "mse/mae or accuracy/F1 score",
      "Reference": "K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34",
      "Publish Year": 1992.0,
      "link": "https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data",
      "_source_file": "Yansong_tabular.json",
      "_source_sheet": "Yansong_tabular",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "data generation/prediction/classification",
      "Name": "Biomechanical features of orthopedic patients",
      "Format": ".csv",
      "Metric": "mse/mae or accuracy/F1 score",
      "link": "https://kaggle.com/datasets/uciml/biomechanical-features-of-orthopedic-patients",
      "_source_file": "Yansong_tabular.json",
      "_source_sheet": "Yansong_tabular",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "data generation/prediction/classification",
      "Name": "Indian Liver Patient Records",
      "Format": ".csv",
      "Metric": "mse/mae or accuracy/F1 score",
      "link": "https://www.kaggle.com/datasets/uciml/indian-liver-patient-records",
      "_source_file": "Yansong_tabular.json",
      "_source_sheet": "Yansong_tabular",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "-=[[[[[[““““““[[[[": "time-series",
      "Task": "Classification",
      "Modality": "ECG",
      "Name": "Heartbeat",
      "Description": "This dataset is composed of two collections of heartbeat signals derived from two famous datasets in heartbeat classification, the MIT-BIH Arrhythmia Dataset and The PTB Diagnostic ECG Database. The number of samples in both collections is large enough for training a deep neural network.",
      "Domain": "heart",
      "Format": ".csv",
      "Metric": "Accuracy/ F1-score",
      "Reference": "Mohammad Kachuee, Shayan Fazeli, and Majid Sarrafzadeh. \"ECG Heartbeat Classification: A Deep Transferable Representation.\"",
      "Publish Year": 2018,
      "link": "https://www.kaggle.com/datasets/shayanfazeli/heartbeat",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "EEG",
      "Name": "SelfRegulationSCP1",
      "Description": "(healthypeople) https://bbci.de/competition/ii/tuebingen_desc_i.html",
      "Domain": "cortex",
      "Format": ".text",
      "Metric": "Accuracy/ F1-score",
      "Reference": "Birbaumer, N., Flor, H., Ghanayim, N., Hinterberger, T., Iverson, I., Taub, E., Kotchoubey, B., Kübler, A., & Perelmouter, J, A Brain-Controlled Spelling Device for the Completely Paralyzed, Nature, 398, 297-298.",
      "Publish Year": 1999,
      "link": "https://www.timeseriesclassification.com/description.php?Dataset=SelfRegulationSCP1",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Classification",
      "Modality": "EEG",
      "Name": "SelfRegulationSCP2",
      "Description": "(artificially respirated ALS patient) https://bbci.de/competition/ii/tuebingen_desc_ii.html",
      "Domain": "cortex",
      "Metric": "Accuracy/ F1-score",
      "Reference": "Birbaumer, N., Flor, H., Ghanayim, N., Hinterberger, T., Iverson, I., Taub, E., Kotchoubey, B., Kübler, A., & Perelmouter, J, A Brain-Controlled Spelling Device for the Completely Paralyzed, Nature, 398, 297-298.",
      "Publish Year": 1999,
      "link": "https://www.timeseriesclassification.com/description.php?Dataset=SelfRegulationSCP2",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Long-term Forecasting",
      "Modality": "ILI",
      "Name": "Epidata",
      "Description": "This is the home of Delphi’s epidemiological data API for tracking epidemics such as influenza, dengue, and norovirus. Note that additional data, including most COVID-19 signals, is available in the main Epidata API (formerly known as COVIDcast).",
      "Domain": "epidemics such as influenza, dengue, and norovirus",
      "Reference": "David C. Farrow, Logan C. Brooks, Ryan J. Tibshirani, Roni Rosenfeld (2015). Delphi Epidata API. https://github.com/cmu-delphi/delphi-epidata",
      "Publish Year": "originally released in 2016",
      "link": "https://cmu-delphi.github.io/delphi-epidata/api/README.html/influenza-data",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "-=[[[[[[““““““[[[[": "time series/tabular",
      "Task": "prediction/classification/ imputation/anomaly detection",
      "Name": "CDC-nhanes",
      "Description": "The National Health and Nutrition Examination Survey (NHANES) monitors the health and nutritional status of adults and children across the United States. ",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2021). National Health and Nutrition Examination Survey (NHANES) [Data file]. Retrieved from https://www.cdc.gov/nchs/nhanes/index.htm",
      "link": "https://www.cdc.gov/nchs/nhanes/index.htm",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NHIS",
      "Description": "The National Health Interview Survey (NHIS) monitors the health of the U.S. population by collecting and analyzing data on a broad range of health topics. NHIS focuses on the health of U.S. children and adults.",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2023). National Health Interview Survey (NHIS) [Data file]. Retrieved from https://www.cdc.gov/nchs/nhis/index.htm",
      "link": "https://www.cdc.gov/nchs/nhanes/index.htm",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NSFG",
      "Description": "The National Survey of Family Growth (NSFG) is a survey of people ages 15–49. NSFG gathers information on pregnancy and births, marriage, living arrangements, infertility, use of birth control, family life, and general and reproductive health.",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2023). National Survey of Family Growth (NSFG) [Data file]. Retrieved from https://www.cdc.gov/nchs/nsfg/index.htm",
      "link": "https://www.cdc.gov/nchs/nhis/data-questionnaires-documentation.htm",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NCHS",
      "Description": "NCHS Rapid Surveys provide data for evidence-based decision-making and faster public health response. ",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2024). National Health Statistics Reports [Data file]. Retrieved from https://www.cdc.gov/nchs/",
      "link": "https://www.cdc.gov/nchs/nsfg/nsfg_2011_2019_combined_files.htm",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NAMCS (unrestricted part could download, restricted partrequires a fee)",
      "Description": "The National Ambulatory Medical Care Survey (NAMCS) collects data about medical services provided in offices for patients who aren't admitted to a hospital or other facility.",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2024). National Ambulatory Medical Care Survey (NAMCS) [Data file]. Retrieved from https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm",
      "link": "https://www.cdc.gov/nchs/rss/data.html",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NEHRS",
      "Description": "The National Electronic Health Records Survey (NEHRS) measures the progress U.S. physicians and their offices have made in adopting electronic health records (EHRs). (unrestricted data avaliable only for 2018,2019,2021)",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2021). National Electronic Health Records Survey (NEHRS) [Data file]. Retrieved from https://www.cdc.gov/nchs/nehrs/index.htm",
      "link": "https://www.cdc.gov/nchs/namcs/about/index.html/cdc_survey_profile_how_surveys_are_conducted-data-and-documentation",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NHAMCS",
      "Description": "The National Hospital Ambulatory Medical Care Survey (NHAMCS) collected data about medical services for patients who were treated in hospital emergency and outpatient departments without being admitted to the hospital. (ends on 2022)",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2022). National Hospital Ambulatory Medical Care Survey (NHAMCS) [Data file]. Retrieved from https://www.cdc.gov/nchs/ahcd/ahcd_products.htm",
      "link": "https://www.cdc.gov/nchs/nhamcs/about/index.html",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NHCS (released public access data in 2020)",
      "Description": "The National Hospital Care Survey (NHCS) collects data on patient care in hospital-based settings to describe patterns of health care delivery and use in the United States.",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (2020). National Hospital Care Survey (NHCS) [Public-use data file]. Retrieved from https://www.cdc.gov/nchs/nhcs/index.htm",
      "link": "https://www.cdc.gov/nchs/nhamcs/about/index.html",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "CDC-NPALS (public accessible only for 2018 survey cycle",
      "Description": "The National Post-acute and Long-term Care Study (NPALS) collects and analyzes data from U.S. providers serving people who need continuing care after urgent medical treatment (post-acute care) or who cannot care for themselves for a long period (long-term care).",
      "Reference": "Centers for Disease Control and Prevention, National Center for Health Statistics. (Year). National Post-Acute and Long-Term Care Study (NPALS) [Data file]. Retrieved from https://www.cdc.gov/nchs/npals/index.html",
      "link": "https://www.cdc.gov/nchs/nhcs/data/index.html",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "ipum-global health (should cite properly and ask for permission to relesea subset, free for research purpose)",
      "Description": "IPUMS Global Health provides integrated international health survey data at no cost for research and educational purposes from three data series: the Demographic Health Surveys (DHS), the UNICEF Multiple Indicator Cluster surveys (MICS), and Performance Monitoring for Action (PMA).",
      "Format": ".csv",
      "Reference": "DHS: Elizabeth Heger Boyle, Miriam King, and Matthew Sobek. IPUMS-Demographic and Health Surveys: Version 11 [dataset]. IPUMS and ICF, 2024. https://doi.org/10.18128/D080.V11; MICS: Anna Bolgrien, Elizabeth Heger Boyle, Matthew Sobek, and Miriam King. IPUMS MICS Data Harmonization Code. Version 1.2 [Stata syntax]. IPUMS: Minneapolis, MN. , 2024. https://doi.org/10.18128/D082.V1.2; PMA: Devon Kristiansen, Elizabeth Heger Boyle, Kathryn L. Grace, and Matthew Sobek. IPUMS PMA: Version 8.1 [dataset]. Minneapolis, MN: IPUMS, 2024. https://doi.org/10.18128/D081.V8.1",
      "link": "https://www.cdc.gov/nchs/npals/questionnaires/index.html",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "ipum-health surveys",
      "Description": "IPUMS Health Surveys provide free individual-level survey data for research purposes from two leading sources of self-reported health and health care access information: the National Health Interview Survey (NHIS) and the Medical Expenditure Panel Survey (MEPS).",
      "Format": ".csv",
      "Reference": "Lynn A. Blewett, Julia A. Rivera Drew, Miriam L. King, Kari C.W. Williams, Daniel Backman, Annie Chen, and Stephanie Richards. IPUMS Health Surveys: National Health Interview Survey, Version 7.4 [dataset]. Minneapolis, MN: IPUMS, 2024. https://doi.org/10.18128/D070.V7.4",
      "link": "https://globalhealth.ipums.org/",
      "_source_file": "Yansong_time_series.json",
      "_source_sheet": "Yansong_time series",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Visual Question Answering",
      "Modality": "X-Ray, MRI",
      "Name": "VQA-RAD training",
      "Link": "VQA-RAD training",
      "Domain": "brain, lung, abdomen,etc.",
      "Dimension": "Mixed",
      "Format": "jpg, csv",
      "Description": "VQA-RAD is a dataset of question-answer pairs on radiology images. The dataset is intended to be used for training and testing Medical Visual Question Answering (VQA) systems. The dataset includes both open-ended questions and binary \"yes/no\" questions. The dataset is built from MedPix, which is a free open-access online database of medical images. The question-answer pairs were manually generated by a team of clinicians.",
      "#": "2,248 question-answer pairs and 315 images",
      "Metric": "Open-Closed",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{lau2018dataset,\n  title={A dataset of clinically generated visual questions and answers about radiology images},\n  author={Lau, Jason J and Gayen, Soumya and Ben Abacha, Asma and Demner-Fushman, Dina},\n  journal={Scientific data},\n  volume={5},\n  number={1},\n  pages={1--10},\n  year={2018},\n  publisher={Nature Publishing Group}\n}",
      "link": "https://huggingface.co/datasets/flaviagiammarino/vqa-rad",
      "_source_file": "Yuhan.json",
      "_source_sheet": "Yuhan",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Image Caption & VQA",
      "Modality": "CT, MRI, X-Ray, Ultrasound, PET-CT, Mammography",
      "Name": "PMC-Inline",
      "Link": "PMC-Inline",
      "Domain": "Chest, Breast, Head and Neck, Abdomen and Pelvis, Spine",
      "Dimension": "2D 512*512\n3D 256*256 (height and weight dimensions)",
      "Format": "json, jpg",
      "Description": " A medical dataset containing PMC-papers which links with images through inline reference.",
      "#": "1.1M question-answer pairs",
      "Metric": "ACC, F1. BLEU, ROUGUE, UMLS_Precision, UMLS_Recall",
      "Label": "√",
      "Download": "√",
      "Reference": "@article{wu2023towards,\n  title={Towards generalist foundation model for radiology},\n  author={Wu, Chaoyi and Zhang, Xiaoman and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},\n  journal={arXiv preprint arXiv:2308.02463},\n  year={2023}\n}",
      "link": "https://huggingface.co/datasets/chaoyi-wu/PMC-Inline",
      "_source_file": "Yuhan.json",
      "_source_sheet": "Yuhan",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Segmentation (LV), Quantification",
      "Modality": "3D Echocardiography (Ultrasound)",
      "Name": "MITEA (Cardiac Atlas Project)",
      "Domain": "Cardiac (LV)",
      "Dimension": "3D volumes (timepoints)",
      "Format": "3DE volumes, masks (NIfTI/HDF5 via CAP)",
      "Description": "536 annotated 3D echo images from 134 subjects with LV labels derived from subject‑specific CMR. No narrative US reports.",
      "#": "536 volumes (134 subjects)",
      "Metric": "Dice/IoU, EF error",
      "Label": "Open",
      "Download": "√",
      "Reference": "Zhao et al., Front Cardiovasc Med 2023",
      "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC9871929/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Prognosis",
      "Modality": "3D Pathology",
      "Name": "PCa_Bx_3Dpathology (TCIA)",
      "Domain": "Prostate (biopsy)",
      "Dimension": "3D volumes",
      "Format": "HDF5, CSV",
      "Description": "3D histopathology volumes with clinical outcomes (biochemical recurrence). No radiology reports.",
      "#": "50 patients",
      "Metric": "Survival metrics",
      "Label": "Open",
      "Download": "√",
      "Reference": "Xie et al., Cancer Res 2022",
      "link": "https://www.cancerimagingarchive.net/collection/pca_bx_3dpathology/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Registration, Segmentation",
      "Modality": "3D Ultrasound + CT",
      "Name": "TRUSTED (US‑CT paired)",
      "Domain": "Abdomen (liver)",
      "Dimension": "3D volumes",
      "Format": "NIfTI (US/CT), masks",
      "Description": "Paired 3D transabdominal ultrasound and CT with anatomical labels; designed for registration/segmentation. No narrative reports.",
      "#": "100+ subjects",
      "Metric": "Dice/IoU, TRE",
      "Label": "Open",
      "Download": "√",
      "Reference": "Abolmaesumi et al., Sci Data 2021",
      "link": "https://www.nature.com/articles/s41597-021-01042-z",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, Benchmarking (FORTE)",
      "Modality": "CT",
      "Name": "3D‑BrainCT (BrainGPT)",
      "Domain": "Brain",
      "Dimension": "3D volumes",
      "Format": "DICOM, TXT (reports)",
      "Description": "18,885 brain CT–report pairs curated for 3D report generation; access via IRB/data sharing request to TPEVGH (Taiwan).",
      "#": "18,885 text‑scan pairs",
      "Metric": "FORTE F1, BLEU/ROUGE",
      "Label": "Request (IRB)",
      "Download": "Apply",
      "Reference": "Li et al., Nat Commun 2025",
      "link": "https://www.nature.com/articles/s41467-025-57426-0",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, Segmentation",
      "Modality": "CT",
      "Name": "AbdomenAtlas 3.0 (RadGPT)",
      "Domain": "Abdomen (liver/kidney/pancreas tumors)",
      "Dimension": "3D volumes",
      "Format": "NIfTI (masks), TXT/JSON (reports)",
      "Description": "9,262 abdominal CT scans with per-voxel tumor masks and expert-reviewed reports; early access by request (first public abdominal CT+report dataset at scale).",
      "#": "9,262 scans (3,955 tumor-positive)",
      "Metric": "BLEU/ROUGE, Dice/IoU",
      "Label": "Request (email access)",
      "Download": "Apply",
      "Reference": "Bassi et al., arXiv:2501.04678; ICCV 2025",
      "link": "https://github.com/MrGiovanni/RadGPT",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, VQA, Retrieval, Classification",
      "Modality": "CT",
      "Name": "CT-RATE",
      "Domain": "Chest (lung, mediastinum, heart)",
      "Dimension": "3D volumes",
      "Format": "NIfTI, CSV",
      "Description": "25,692 non-contrast chest CT volumes (expandable to ~50k) paired with full radiology reports, multi-abnormality labels, and metadata.",
      "#": "21,304 patients / 25,692 scans",
      "Metric": "BLEU/ROUGE/CRG, AUROC, F1",
      "Label": "Open (DUA on HF)",
      "Download": "√",
      "Reference": "Hamamci et al., arXiv:2403.17834 (2024)",
      "link": "https://huggingface.co/datasets/ibrahimhamamci/CT-RATE",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Prognosis, Retrieval",
      "Modality": "CT",
      "Name": "Head-Neck-CT-Atlas (TCIA)",
      "Domain": "Head & Neck",
      "Dimension": "3D volumes",
      "Format": "DICOM, XLSX",
      "Description": "HNSCC patient CTs (diagnostic/planning/follow-up) paired with extensive clinical data tables (demographics, stage, recurrence, survival).",
      "#": "215 patients",
      "Metric": "C-index (survival)",
      "Label": "Mixed",
      "Download": "Apply",
      "Reference": "Grossberg et al., Sci Data 2018",
      "link": "https://www.cancerimagingarchive.net/collection/head-neck-ct-atlas/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Classification, Retrieval",
      "Modality": "CT",
      "Name": "LIDC-IDRI",
      "Domain": "Chest",
      "Dimension": "3D volumes",
      "Format": "DICOM, XML",
      "Description": "Thoracic CT scans with detailed XML annotations from 4 radiologists (nodule characteristics, outlines). No narrative reports.",
      "#": "1,018 cases",
      "Metric": "Dice/IoU, Classification Acc",
      "Label": "Open",
      "Download": "√",
      "Reference": "Armato et al., Med Phys 2011",
      "link": "https://www.cancerimagingarchive.net/collection/lidc-idri/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, Retrieval, Phenotype prediction, Segmentation",
      "Modality": "CT",
      "Name": "MERLIN (Abdominal CT + Reports + EHR)",
      "Domain": "Abdomen",
      "Dimension": "3D volumes",
      "Format": "DICOM (clinical), TXT (reports), ICD/EHR",
      "Description": "25,528 abdominal CTs with paired radiology reports and EHR phenotypes used to train the MERLIN 3D VLM; release planned pending PHI removal.",
      "#": "18,321 pts / 25,528 CTs",
      "Metric": "BLEU/ROUGE (RRG), Zero-shot retrieval/cls",
      "Label": "Request/Planned (IRB/DUA)",
      "Download": "Apply",
      "Reference": "Merlin paper (PMC 2024)",
      "link": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11230513/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Classification, Localization",
      "Modality": "CT",
      "Name": "RAD-ChestCT",
      "Domain": "Chest",
      "Dimension": "3D volumes",
      "Format": "NPZ, CSV",
      "Description": "Large-scale chest CTs. Full reports not public; provides NLP-extracted labels (84 abnormalities × 52 locations) + scan indications.",
      "#": "3,630 scans (public); 36,316 (full)",
      "Metric": "AUROC, F1-score",
      "Label": "Request",
      "Download": "Apply",
      "Reference": "Draelos et al., Med Image Anal 2021",
      "link": "https://zenodo.org/records/6406114",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Grounded Report Gen, VQA, Ref-SEG",
      "Modality": "CT",
      "Name": "RadGenome‑ChestCT (grounded reports + VQA)",
      "Domain": "Chest",
      "Dimension": "3D volumes",
      "Format": "NIfTI (masks), JSON/CSV (grounded reports/VQA)",
      "Description": "Built on CT‑RATE: 197 organ masks, 665k grounded reports (sentence‑level region links), 1.3M grounded VQA pairs for region‑aware training.",
      "#": "25,692 CTs; 665k reports; 1.3M VQA",
      "Metric": "BLEU/ROUGE/CRG, Dice/IoU",
      "Label": "Open",
      "Download": "√",
      "Reference": "Zhang et al., Sci Data 2025; arXiv:2404.16754",
      "link": "https://huggingface.co/datasets/RadGenome/RadGenome-ChestCT",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Text‑grounded Segmentation",
      "Modality": "CT",
      "Name": "ReXGroundingCT",
      "Domain": "Chest (findings grounding)",
      "Dimension": "3D volumes",
      "Format": "NIfTI (masks), TXT (findings)",
      "Description": "3,142 chest CTs from CT‑RATE with manually segmented regions for free‑text findings; sentence‑level grounding for 8,028 findings.",
      "#": "3,142 scans; 8,028 findings",
      "Metric": "Grounding F1/IoU",
      "Label": "Open",
      "Download": "√",
      "Reference": "Baharoon et al., arXiv:2507.22030",
      "link": "https://huggingface.co/datasets/rajpurkarlab/ReXGroundingCT",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, Diagnosis, Prognosis",
      "Modality": "CT (CTPA) + EHR",
      "Name": "INSPECT (PE)",
      "Domain": "Pulmonary Embolism (CTPA)",
      "Dimension": "3D volumes",
      "Format": "DICOM, TXT (impression), EHR tables",
      "Description": "19,402 patients; 23,248 CTPA studies paired with radiology report impression sections and longitudinal EHR; diagnosis & prognosis tasks; DUA required.",
      "#": "19,402 pts / 23,248 studies",
      "Metric": "AUROC/AUPRC, C-index; NLG for RRG",
      "Label": "Request (DUA)",
      "Download": "Apply",
      "Reference": "Huang et al., NeurIPS 2023 (Datasets)",
      "link": "https://som-shahlab.github.io/inspect-website/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, VQA, Retrieval, Ref-SEG",
      "Modality": "CT (multi-organs)",
      "Name": "M3D‑Data (M3D‑Cap + M3D‑VQA)",
      "Domain": "Multi‑organ (Radiopaedia-based)",
      "Dimension": "3D volumes",
      "Format": "NIfTI/NPY, JSON/TXT",
      "Description": "Largest public 3D multi‑modal dataset: 120k image‑text pairs + 662k instruction pairs across 8 tasks (report gen, VQA, retrieval, ref‑seg).",
      "#": "120k pairs (Cap) + 662k (VQA)",
      "Metric": "BLEU/ROUGE, VQA Acc",
      "Label": "Open",
      "Download": "√",
      "Reference": "BAAI M3D (arXiv 2024/2025)",
      "link": "https://github.com/BAAI-DCAI/M3D",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Detection, Diagnosis",
      "Modality": "CT + PET/CT",
      "Name": "LUNG‑PET‑CT‑Dx (TCIA)",
      "Domain": "Lung cancer",
      "Dimension": "3D volumes",
      "Format": "DICOM, XML (bbox)",
      "Description": "CT and PET/CT with XML annotations for tumor localization; grouped by histopathology. No narrative reports.",
      "#": "355+ patients",
      "Metric": "Detection mAP/FROC",
      "Label": "Open",
      "Download": "√",
      "Reference": "TCIA LUNG‑PET‑CT‑Dx",
      "link": "https://www.cancerimagingarchive.net/collection/lung-pet-ct-dx/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Radiogenomics, Semantics",
      "Modality": "CT + PET/CT",
      "Name": "NSCLC Radiogenomics",
      "Domain": "Lung (NSCLC)",
      "Dimension": "3D volumes",
      "Format": "DICOM, AIM (semantic), CSV",
      "Description": "211 subjects with CT and PET/CT, radiologist semantic annotations (AIM), tumor segmentations, genomics, and clinical outcomes.",
      "#": "211 subjects",
      "Metric": "Prognostic metrics, AUC",
      "Label": "Open",
      "Download": "√",
      "Reference": "Grossmann et al., Sci Data 2018",
      "link": "https://www.nature.com/articles/sdata2018202",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Report Gen, VQA, Prognosis",
      "Modality": "MRI",
      "Name": "BrainMD",
      "Domain": "Brain (glioma)",
      "Dimension": "3D volumes (+ curated 2D)",
      "Format": "NIfTI, CSV",
      "Description": "3D brain MRIs paired with full radiology reports and longitudinal EHRs. Includes radiologist-selected 2D slices for VLM benchmarking.",
      "#": "2,453 studies (561 pts)",
      "Metric": "VQA Acc, BLEU/ROUGE",
      "Label": "Mixed (examples open; full via DUA)",
      "Download": "Apply",
      "Reference": "Wang et al., NeurIPS 2024",
      "link": "https://github.com/YuliWanghust/BrainMD",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Diagnosis, Report Analysis",
      "Modality": "MRI",
      "Name": "PROSTATE-DIAGNOSIS (TCIA)",
      "Domain": "Prostate",
      "Dimension": "3D volumes (multi-sequence)",
      "Format": "DICOM, XLSX",
      "Description": "Multi-parametric prostate MRIs with accompanying pathology and radiology reports (XLS).",
      "#": "92 patients",
      "Metric": "Classification Acc, Dice/IoU",
      "Label": "Open",
      "Download": "√",
      "Reference": "Bloch et al., TCIA 2015",
      "link": "https://www.cancerimagingarchive.net/collection/prostate-diagnosis/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Text-guided Segmentation",
      "Modality": "MRI",
      "Name": "TextBraTS (Reports for BraTS20)",
      "Domain": "Brain (glioma)",
      "Dimension": "3D volumes (multi-sequence)",
      "Format": "NIfTI (+ text)",
      "Description": "Structured radiology reports aligned to BraTS'20 training set to enable text-guided segmentation (images via BraTS terms, text open).",
      "#": "369 scans (BraTS’20 train)",
      "Metric": "Dice/IoU",
      "Label": "Mixed (images request; text open)",
      "Download": "√ / request",
      "Reference": "Shi et al., MICCAI 2025",
      "link": "https://github.com/Jupitern52/TextBraTS",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Diagnosis/Prognosis (structured reports)",
      "Modality": "PET/CT",
      "Name": "ACRIN 6668 / RTOG 0235 (NSCLC FDG‑PET/CT)",
      "Domain": "Lung (NSCLC)",
      "Dimension": "3D volumes",
      "Format": "DICOM, Case Report Forms",
      "Description": "Clinical trial PET/CT with standardized reporting forms and outcomes; suitable for PERCIST-style analysis (no free‑text narratives).",
      "#": "~ 200+ subjects",
      "Metric": "Survival (C‑index), Response metrics",
      "Label": "Open",
      "Download": "√",
      "Reference": "TCIA ACRIN‑NSCLC‑FDG‑PET",
      "link": "https://www.cancerimagingarchive.net/collection/acrin-6668/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Lesion Segmentation",
      "Modality": "PET/CT",
      "Name": "ENHANCE.PET‑1.6k",
      "Domain": "Whole‑body oncology",
      "Dimension": "3D volumes",
      "Format": "NIfTI (PET/CT, masks)",
      "Description": "1,619 FDG‑PET/CT studies with manual whole‑body tumor masks; curated from multiple cohorts. No radiology reports.",
      "#": "1,619 studies",
      "Metric": "Dice/IoU",
      "Label": "Open",
      "Download": "√",
      "Reference": "Gong et al., 2025 (ENHANCE.PET)",
      "link": "https://zenodo.org/records/13975862",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Localization, Segmentation",
      "Modality": "PET/CT",
      "Name": "HEAD‑NECK‑PET‑CT (TCIA / HECKTOR)",
      "Domain": "Head & Neck cancer",
      "Dimension": "3D volumes",
      "Format": "DICOM, RTSTRUCT/SEG",
      "Description": "298 H&N PET/CT + planning CT for radiotherapy; widely used in HECKTOR. Contains manual tumor delineations; no radiology reports.",
      "#": "298 subjects",
      "Metric": "Dice/IoU",
      "Label": "Open",
      "Download": "√",
      "Reference": "HECKTOR collections (2019–2025)",
      "link": "https://www.cancerimagingarchive.net/collection/head-neck-pet-ct/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Classification (hypermetabolic), Retrieval",
      "Modality": "PET/CT",
      "Name": "SPADe (Stanford PET/CT Abnormality Detection)",
      "Domain": "Whole‑body",
      "Dimension": "3D volumes",
      "Format": "DICOM, CSV labels",
      "Description": "Large PET/CT set with hypermetabolic abnormality labels aggregated across organs. No narrative reports. Access by request.",
      "#": "10k+ studies (subset public)",
      "Metric": "AUROC, F1",
      "Label": "Request",
      "Download": "Apply",
      "Reference": "Stanford AIMI SPADe",
      "link": "https://aimi.stanford.edu/datasets/pet-ct-spade",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Segmentation, Classification",
      "Modality": "PET/CT",
      "Name": "autoPET Challenge",
      "Domain": "Whole-body (oncology)",
      "Dimension": "3D volumes",
      "Format": "DICOM, NIfTI, CSV",
      "Description": "Whole-body FDG-PET/CTs with expert lesion masks. No narrative reports (metadata CSV available).",
      "#": "1,014 studies",
      "Metric": "Dice/IoU, FROC",
      "Label": "Open (training set)",
      "Download": "√",
      "Reference": "Gatidis & Küstner, Sci Data 2022",
      "link": "https://autopet.grand-challenge.org/Dataset/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Classification, Retrieval",
      "Modality": "CT (Angio)",
      "Name": "RSNA STR Pulmonary Embolism Detection",
      "Domain": "CTPA (Pulmonary Embolism)",
      "Dimension": "3D volumes",
      "Format": "DICOM, CSV (study-level + image-level labels)",
      "Description": "Large CTPA dataset with 9+ study-level labels (and one image-level) derived from radiology reports; 3D CT volumes in series; used widely for PE classification.",
      "#": "~12k–18k studies (competition release)",
      "Metric": "AUROC, AUPRC",
      "Label": "Open (Kaggle terms)",
      "Download": "√",
      "Reference": "RSNA AI 2020; Colak et al., Radiology AI 2021",
      "link": "https://www.kaggle.com/competitions/rsna-str-pulmonary-embolism-detection",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Severity Classification, Retrieval",
      "Modality": "CT",
      "Name": "MosMedData (COVID‑19 CT Severity)",
      "Domain": "Chest (COVID‑19)",
      "Dimension": "3D volumes",
      "Format": "DICOM/NIfTI, CSV (CT0–CT4 severity)",
      "Description": "1110 chest CT studies with radiologist‑validated structured severity labels (CT0–CT4) from report systems; subset includes lesion masks.",
      "#": "1,110 studies",
      "Metric": "AUROC, F1",
      "Label": "Open",
      "Download": "√",
      "Reference": "Morozov et al., Digital Diagnostics 2020",
      "link": "https://journals.eco-vector.com/DD/article/view/46826",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Detection, Classification",
      "Modality": "CT",
      "Name": "RibFrac",
      "Domain": "Chest (ribs)",
      "Dimension": "3D volumes",
      "Format": "DICOM, CSV (fracture labels), masks",
      "Description": "660 chest CTs with ~5,000 rib fractures; provides classification labels and segmentation/bbox for lesions; suited for text‑linked lesion tasks.",
      "#": "660 CTs; ~5k fractures",
      "Metric": "FROC, mAP, Dice",
      "Label": "Open (challenge)",
      "Download": "√",
      "Reference": "RibFrac Grand‑Challenge",
      "link": "https://ribfrac.grand-challenge.org/tasks/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Vision & Language",
      "Task": "Labelling (vertebra IDs), Segmentation",
      "Modality": "CT",
      "Name": "VerSe (2019/2020)",
      "Domain": "Spine",
      "Dimension": "3D volumes",
      "Format": "DICOM/NIfTI, TXT/JSON (vertebra labels), masks",
      "Description": "Multi-centre CT spine dataset with vertebra labelling (names/IDs) and voxel-level segmentation; suitable as text‑linked 3D labelling benchmark.",
      "#": "319 CT series / 300 subjects (VerSe’20)",
      "Metric": "Dice/IoU, labeling accuracy",
      "Label": "Open (challenge)",
      "Download": "√",
      "Reference": "Liebl et al., Sci Data 2021",
      "link": "https://verse2020.grand-challenge.org/",
      "_source_file": "Yuhan_3D_text.json",
      "_source_sheet": "Yuhan_3D_text",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Language",
      "Task": "Text Classification",
      "Modality": "Text",
      "Name": "ADReSS",
      "Link": "ADReSS",
      "Domain": "Alzheimer's Dementia Recognition",
      "Dimension": "Text",
      "Format": "Text",
      "Description": "an AD classification task, where you are required to produce a model to predict the label (AD or non-AD) for a speech session. Your model can use speech data, language data (transcipts are provided), or both.",
      "#": 156,
      "Metric": "Accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "Luz, Saturnino, et al. \"Alzheimer's dementia recognition through spontaneous speech: The ADReSS challenge.\" arXiv preprint arXiv:2004.06833 (2020).",
      "link": "https://luzs.gitlab.io/adress/",
      "_source_file": "Zhengliang.json",
      "_source_sheet": "Zhengliang",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Multiple choice QA",
      "Modality": "Text",
      "Name": "MedMCQA",
      "Link": "MedMCQA",
      "Domain": "Medical (general)",
      "Dimension": "Text",
      "Format": "Text",
      "Description": "MedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.",
      "#": "Train/test/valid: 182,822/6,150/4,183",
      "Metric": "Accuracy",
      "Label": "√",
      "Download": "√",
      "Reference": "Pal, Ankit, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. \"Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering.\" Conference on Health, Inference, and Learning. PMLR, 2022.",
      "link": "https://huggingface.co/datasets/medmcqa",
      "_source_file": "Zhengliang.json",
      "_source_sheet": "Zhengliang",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Text Summarization/Clinical assessment",
      "Modality": "Text",
      "Name": "MIMIC-CXR-ImpressionGPT",
      "Link": "ImpressionGPT",
      "Domain": "Radiology",
      "Dimension": "Text",
      "Format": "Text",
      "Description": "Chest radiograph report. Findings-->Impressions",
      "#": "Train/test/valid: 122,014/957/1,606",
      "Metric": "ROUGE/Clinical Efficacy (CE)",
      "Label": "√",
      "Download": "√",
      "Reference": "Ma, Chong, et al. \"ImpressionGPT: an iterative optimizing framework for radiology report summarization with chatGPT.\" arXiv preprint arXiv:2304.08448 (2023).",
      "link": "https://arxiv.org/abs/2304.08448",
      "_source_file": "Zhengliang.json",
      "_source_sheet": "Zhengliang",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Named Entity Recognition (NER)",
      "Modality": "Text",
      "Name": "NCBI Disease Dataset",
      "Link": "NCBI Disease",
      "Domain": "Biomedical",
      "Dimension": "Text",
      "Format": "Text",
      "Description": "a collection of 793 PubMed abstracts fully annotated at the mention and concept level to serve as a research resource for the biomedical natural language processing community.",
      "#": "Train/test/valid: 5430/941/924",
      "Metric": "F1",
      "Label": "√",
      "Download": "√",
      "Reference": "Doğan, Rezarta Islamaj, Robert Leaman, and Zhiyong Lu. \"NCBI disease corpus: a resource for disease name recognition and concept normalization.\" Journal of biomedical informatics 47 (2014): 1-10.",
      "link": "https://www.ncbi.nlm.nih.gov/research/bionlp/Data/disease/",
      "_source_file": "Zhengliang.json",
      "_source_sheet": "Zhengliang",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Task": "Relation Extraction",
      "Modality": "Text",
      "Name": "MIMICause",
      "Link": "MIMICause",
      "Domain": "Clinical Notes",
      "Dimension": "Text",
      "Format": "Text",
      "Description": "MIMICause Dataset is a dataset for representation and automatic extraction of causal relation types from clinical notes. The MIMICause dataset requires manual download of the mimicause.zip file from the Community Annotations Downloads section of the n2c2 dataset on the Harvard's DBMI Data Portal after signing their agreement forms, which is a quick and easy procedure.",
      "#": "Train/test/valid: 1953/489/272",
      "Metric": " F1",
      "Label": "√",
      "Download": "√",
      "Reference": "Khetan, Vivek, et al. \"MIMICause: Representation and automatic extraction of causal relation types from clinical notes.\" arXiv preprint arXiv:2110.07090 (2021).",
      "link": "https://huggingface.co/datasets/pensieves/mimicause",
      "_source_file": "Zhengliang.json",
      "_source_sheet": "Zhengliang",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "time-series",
      "Modality": "EEG",
      "Domain": "Motor-Imagery",
      "Name": "Left/Right Hand MI",
      "Format": "mat",
      "Description": "Includes 52 subjects (38 validated subjects with discriminative features), results of physiological and psychological questionnaires, EMG Datasets, location of 3D EEG electrodes, and EEGs for non-task related states",
      "Reference": "Cho, H., Ahn, M., Ahn, S., Moonyoung Kwon, & Jun, S. C. (2017). Supporting data for \"EEG datasets for motor imagery brain computer interface\" [Data set]. GigaScience Database. https://doi.org/10.5524/100295",
      "Publish Year": 2017.0,
      "link": "http://gigadb.org/dataset/100295",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Motor Movement/Imagery Dataset",
      "Format": ".edf",
      "Description": "Includes 109 volunteers, 64 electrodes, 2 baseline tasks (eye-open and eye-closed), motor movement, and motor imagery (both fists or both feet)",
      "Reference": "Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE Transactions on Biomedical Engineering 51(6):1034-1043, 2004.",
      "Publish Year": 2000.0,
      "link": "https://www.physionet.org/physiobank/database/eegmmidb/",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Grasp-and-Lift EEG Detection",
      "Format": ".csv",
      "Description": "12 subjects, 32channels@500Hz, for 6 grasp and lift events, namely a). HandStart b). FirstDigitTouch c). BothStartLoadPhase d). LiftOff e). Replace f). BothReleased",
      "Reference": "BenoniEdin, Klaus Greff, and Will Cukierski. Grasp-and-Lift EEG Detection. https://kaggle.com/competitions/grasp-and-lift-eeg-detection, 2015. Kaggle.",
      "Publish Year": 2015.0,
      "link": "https://www.kaggle.com/c/grasp-and-lift-eeg-detection/data",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Domain": "Emotion-Recognition",
      "Name": "DEAP",
      "Format": "xls, csv, ods spreadsheet",
      "Description": "Includes 32 subjects, each watching 1-min long excerpts of music-videos, rated by users in terms of arousal/valence/like-dislike/dominance/familiarity, and frontal face recording of 22/32 subjects.",
      "Reference": "Koelstra S, Muhl C, Soleymani M, et al. Deap: A database for emotion analysis; using physiological signals[J]. IEEE transactions on affective computing, 2011, 3(1): 18-31.",
      "Publish Year": 2012.0,
      "link": "http://www.eecs.qmul.ac.uk/mmv/datasets/deap/",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Imagined Emotion:",
      "Description": "31 subjects, subjects listen to voice recordings that suggest an emotional feeling and ask subjects to imagine an emotional scenario or to recall an experience in which they have felt that emotion before.",
      "Reference": "Onton J A, Makeig S. High-frequency broadband modulation of electroencephalographic spectra[J]. Frontiers in human neuroscience, 2009, 3: 560.",
      "Publish Year": 2009.0,
      "link": "http://headit.ucsd.edu/studies/3316f70e-35ff-11e3-a2a9-0050563f2612",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "SEED",
      "Format": "pickle，xlsx",
      "Description": "15 subjects were shown video clips eliciting positive/negative/neutral emotion and EEG was recorded over 62 channels.",
      "Reference": "Wei-Long Zheng, and Bao-Liang Lu, Investigating Critical Frequency Bands and Channels for EEG-based Emotion Recognition with Deep Neural Networks, accepted by IEEE Transactions on Autonomous Mental Development (IEEE TAMD) 7(3): 162-175, 2015.",
      "link": "http://bcmi.sjtu.edu.cn/~seed/seed.html",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "SEED-VI",
      "Format": "pickle，xlsx",
      "Description": "15 subjects were shown video clips ellicity happy/sad/neutral/fear emotions and EEG was recorded over 62 channels (with eye-tracking) for 3 sessions per subject (24 trials per session).",
      "Reference": "Wei-Long Zheng, Wei Liu, Yifei Lu, Bao-Liang Lu, and Andrzej Cichocki, EmotionMeter: A Multimodal Framework for Recognizing Human Emotions. IEEE Transactions on Cybernetics, Volume: 49, Issue: 3, March 2019, Pages: 1110-1122, DOI: 10.1109/TCYB.2018.2797176.",
      "Publish Year": 2019.0,
      "link": "https://bcmi.sjtu.edu.cn/~seed/seed-iv.html",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Domain": "Error-Related Potentials (ErrP)",
      "Name": "BCI-NER Challenge",
      "Format": "csv",
      "Description": "26 subjects, 56 EEG Channels for a P300 Speller task, and labeled dataset for the response elicited when P300 decodes a correct or incorrect letter.",
      "Reference": "Jérémie Mattout, Manu, maucle, and Wendy Kan. BCI Challenge @ NER 2015. https://kaggle.com/competitions/inria-bci-challenge, 2014. Kaggle.",
      "Publish Year": 2015.0,
      "link": "https://www.kaggle.com/c/inria-bci-challenge",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Domain": "Clinical EEG",
      "Name": "Predict-UNM",
      "Description": "A large repository of clinical EEG datasets",
      "Reference": "Cavanagh J F, Napolitano A, Wu C, et al. The patient repository for EEG data+ computational tools (PRED+ CT)[J]. Frontiers in neuroinformatics, 2017, 11: 67.",
      "Publish Year": 2017.0,
      "link": "http://predict.cs.unm.edu/",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Domain": "Event Related Potentials [ERPs]",
      "Name": "Face vs. House Discrimination",
      "Format": "zip",
      "Description": "7 Epileptic subjects were presented with 50 grayscale stimulations each for Face and House pictures. For each subject, total 3 experimental runs were conducted resulting in 300 stimulations.",
      "Reference": "Miller, Kai J and Ojemann, Jeffrey G. (2015). Data and analyses for \"Spontaneous Decoding of the Timing and Content of Human Object Perception from Cortical Surface Recordings Reveals Complementary Information in the Event-Related Potential and Broadband Spectral Change\". Stanford Digital Repository. Available at: http://purl.stanford.edu/xd109qh3109",
      "link": "https://purl.stanford.edu/xd109qh3109",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Target Versus Non-Target",
      "Format": "csv,mat",
      "Description": "25 subjects testing Brain Invaders, a visual P300 Brain-Computer Interface using oddball paradigm. 16-electrodes, wet. publication, code. Dataset id: BI.EEG.2012-GIPSA.",
      "Reference": "Van Veen, G. F. P., Barachant, A., Andreev, A., Cattan, G., Coelho Rodrigues, P. L., & Congedo, M. (2019). Building Brain Invaders: EEG data of an experimental validation [Data set]. Zenodo. https://doi.org/10.5281/zenodo.2649069",
      "link": "https://zenodo.org/record/2649069",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Target Versus Non-Target",
      "Format": "csv,mat",
      "Description": "24 subjects playing Brain Invaders, a visual P300 Brain-Computer Interface using oddball paradigm. 16-electrodes, wet. Up to 8 sessions per subject. Two experimental conditions: with and without adaptive calibration using Riemannian geometry. publication, code. Dataset id: BI.EEG.2013-GIPSA.",
      "Reference": "Erwan Vaineau, Alexandre Barachant, Anton Andreev, Pedro L. C. Rodrigues, Grégoire Cattan, & Marco Congedo. (2018). Brain Invaders Adaptive versus Non-Adaptive P300 Brain-Computer Interface dataset [Data set]. Zenodo. https://doi.org/10.5281/zenodo.2669187",
      "link": "https://zenodo.org/record/2649069",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Target Versus Non-Target",
      "Format": "csv,mat",
      "Description": "71 subjects playing Brain Invaders, a visual P300 Brain-Computer Interface using oddball paradigm with adaptive Riemannian Geometry (no-calibration). 16-electrodes, dry. publication, code. Dataset id: bi2014a.",
      "Reference": "Korczowski, L., Ostaschenko, E., Andreev, A., Cattan, G., Coelho Rodrigues, P. L., Gautheret, V., & Congedo, M. (2019). Brain Invaders calibration-less P300-based BCI using dry EEG electrodes Dataset (bi2014a) [Data set]. Zenodo.",
      "link": "https://zenodo.org/record/2649069",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Target Versus Non-Target",
      "Format": "csv,mat",
      "Description": "38 subjects playing a multiplayer and collaborative version of Brain Invaders, a visual P300 Brain-Computer Interface using oddball paradigm with adaptive Riemannian Geometry (no-calibration). 32-electrodes per subject, wet, 2 subjects during each session. publication, code. Dataset id: bi2014b.",
      "Reference": "Korczowski, L., Ostaschenko, E., Andreev, A., Cattan, G., Coelho Rodrigues, P. L., Gautheret, V., & Congedo, M. (2019). Brain Invaders Solo versus Collaboration: Multi-User P300-based Brain-Computer Interface Dataset (bi2014b) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3267302",
      "link": "https://zenodo.org/record/2649069",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Target Versus Non-Target",
      "Format": "csv,mat",
      "Description": "50 subjects playing Brain Invaders, a visual P300 Brain-Computer Interface using oddball paradigm with adaptive Riemannian Geometry (no-calibration). 32-electrodes, wet. 3 sessions per subjects with modulation of flash duration. publication, code. Dataset id: bi2015a.",
      "Reference": "Korczowski, L., Cederhout, M., Andreev, A., Cattan, G., Coelho Rodrigues, P. L., Gautheret, V., & Congedo, M. (2019). Brain Invaders calibration-less P300-based BCI with modulation of flash duration Dataset (bi2015a) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3266930",
      "link": "https://zenodo.org/record/2649069",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Name": "Target Versus Non-Target",
      "Format": "csv,mat",
      "Description": "44 subjects playing a multiplayer (cooperation and competition) version of Brain Invaders, a visual P300 Brain-Computer Interface using oddball paradigm with adaptive Riemannian Geometry (no-calibration). 32-electrodes per subject, wet, 2 subjects for each session. publication, code. Dataset id: bi2015b.",
      "Reference": "Korczowski, L., Cederhout, M., Andreev, A., Cattan, G., Coelho Rodrigues, P. L., Gautheret, V., & Congedo, M. (2019). Brain Invaders Cooperative versus Competitive: Multi-User P300-based Brain-Computer Interface Dataset (bi2015b) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3268762",
      "link": "https://zenodo.org/record/2649069",
      "_source_file": "chuanqi-tIme_seriesEEG.json",
      "_source_sheet": "chuanqi-tIme series（EEG）",
      "_source_directory": "biomedbank_vision_v0_json_data"
    },
    {
      "Type": "Drug",
      "Task": "virtual screening",
      "Modality": "string",
      "Name": "ZINC",
      "Domain": "drug",
      "Dimension": "(249455,4)",
      "Format": "csv",
      "Description": "The dataset comes with molecule formula in SMILE representation along \nwith their respective molecular properties such as logP (water–octanal \npartition coefficient), SAS (synthetic accessibility score) and QED \n(Qualitative Estimate of Drug-likeness).",
      "Metric": "logp,qed,sa",
      "Download": "√",
      "Reference": "https://pubs.acs.org/doi/10.1021/ci3001277",
      "link": "https://www.kaggle.com/datasets/basu369victor/zinc250k",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "drug_dataset_json_data"
    },
    {
      "Task": "Molecular Generation",
      "Modality": " string, graphs",
      "Name": "MOSES",
      "Domain": "drug",
      "Dimension": "4,591,276 molecules and 1,936,962 molecular structures",
      "Format": "csv, npz",
      "Description": "The set is based on the ZINC Clean Leads collection.",
      "Metric": "Valid, Unique, Novelty, Filters, Fragment similarity, Scaffold similarity, Similarity to a nearest neighbor, Internal diversity, Fréchet ChemNet Distance, Molecular weight, logp, qed, sa",
      "Download": "√",
      "Reference": "https://arxiv.org/abs/1811.12823",
      "link": "https://github.com/molecularsets/moses",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "drug_dataset_json_data"
    },
    {
      "Task": "Molecular Generation",
      "Modality": "3D structure",
      "Name": "CrossDocked2020",
      "Domain": "protein",
      "Dimension": "4,260 redocking and 820,280 cross-docking\nprotein-ligand pairs ",
      "Format": "pdb, sdf",
      "Metric": "Output pose, Avg Time Per System",
      "Download": "√",
      "Reference": "https://chemrxiv.org/engage/chemrxiv/article-details/60c753ebbb8c1a1a9d3dc142",
      "link": "https://github.com/gnina/models/tree/master/data/CrossDocked2020",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "drug_dataset_json_data"
    },
    {
      "Task": "large biological molecules (proteins, DNA, and RNA)",
      "Modality": "3D structure",
      "Name": "RCSB Protein Data Bank (RCSB PDB)",
      "Domain": "large biological molecules (proteins, DNA, and RNA)",
      "Dimension": ">1 TB of Structure Data for Proteins, DNA, and RNA",
      "Format": "pdb",
      "Reference": "https://academic.oup.com/nar/article/28/1/235/2384399?login=false",
      "link": "https://www.rcsb.org/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "drug_dataset_json_data"
    },
    {
      "Task": "large biological molecules (proteins, DNA, and RNA)",
      "Modality": "3D structure",
      "Name": "PDBbind",
      "Domain": "a comprehensive collection of experimental binding affinity data for all\n biomolecular complexes recorded in the Protein Data Bank (PDB).",
      "Dimension": "a total of 27,408 biomolecular complexes in PDB, including protein-ligand (22,920), protein-protein (3,176), protein-nucleic acid (1,141), and nucleic acid-ligand complexes (171).",
      "Format": "pdb",
      "Reference": "https://www.pdbbind-plus.org.cn/reference",
      "link": "https://www.pdbbind-plus.org.cn/",
      "_source_file": "Sheet1.json",
      "_source_sheet": "Sheet1",
      "_source_directory": "drug_dataset_json_data"
    }
  ]
}